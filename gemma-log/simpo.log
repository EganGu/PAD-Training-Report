nohup: ignoring input
[2025-03-28 13:41:48,926] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0328 13:41:50.291000 53731 site-packages/torch/distributed/run.py:792] 
W0328 13:41:50.291000 53731 site-packages/torch/distributed/run.py:792] *****************************************
W0328 13:41:50.291000 53731 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0328 13:41:50.291000 53731 site-packages/torch/distributed/run.py:792] *****************************************
[2025-03-28 13:41:55,394] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-28 13:41:55,394] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-28 13:41:57,240] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-03-28 13:41:57,240] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-28 13:41:57,240] [INFO] [comm.py:658:init_distributed] cdb=None
2025-03-28 13:41:57 - INFO - __main__ - Model parameters ModelArguments(base_model_revision=None, model_name_or_path='/zju_0038/yggu/huggingface/google/gemma-2-2b-it', model_revision='main', model_code_revision=None, torch_dtype=None, tokenizer_name_or_path=None, trust_remote_code=False, attn_implementation='eager', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, bnb_4bit_quant_storage='uint8')
2025-03-28 13:41:57 - INFO - __main__ - Data parameters DataArguments(chat_template=None, dataset_mixer={'/zju_0038/yggu/huggingface/pad-gemma-2-n4': 1.0}, text_column='text', dataset_splits=['train', 'test'], dataset_configs=None, preprocessing_num_workers=12, truncation_side=None, auto_insert_empty_system_msg=True, local_dataset=False)
2025-03-28 13:41:57 - INFO - __main__ - Training/evaluation parameters SimPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
alpha=0.5,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=10,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
dataset_num_proc=12,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_dropout=True,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=100,
eval_strategy=steps,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gamma=3,
gamma_beta_ratio=0.5,
generate_during_eval=False,
gradient_accumulation_steps=32,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=simpo-exps,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
is_encoder_decoder=None,
jit_mode_eval=False,
label_names=None,
label_pad_token_id=-100,
label_smoothing=0,
label_smoothing_factor=0.0,
learning_rate=8e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=outputs/gemma-2-2b-it-simpo/runs/Mar28_13-41-57_3j2blv0q5ut5a-0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=5,
logging_strategy=steps,
loss_type=simpo,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_batch_token_size=100000000.0,
max_completion_length=None,
max_grad_norm=1.0,
max_length=2048,
max_prompt_length=1800,
max_steps=-1,
max_target_length=None,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=outputs/gemma-2-2b-it-simpo,
overwrite_output_dir=False,
padding_value=None,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=gemma-2-2b-it-simpo,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=100,
save_strategy=steps,
save_total_limit=20,
seed=42,
sft_weight=0.0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tp_size=0,
tpu_metrics_debug=False,
tpu_num_cores=None,
truncation_mode=keep_end,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.1,
warmup_steps=0,
weight_decay=0.0,
)
2025-03-28 13:41:57 - INFO - __main__ - Training on the following splits: ['train : 55321', 'test : 1130']
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2058] 2025-03-28 13:41:57,394 >> loading file chat_template.jinja
[rank1]:[W328 13:41:58.918798330 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W328 13:41:58.541824594 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-03-28 13:41:59 - INFO - __main__ - Prompt sample 41905 of the raw training set:

<bos><start_of_turn>user
Generate three potential slogans for an auctioneering company that specializes in selling rare and antique items from around the world. The slogans must be catchy, concise, and evoke a sense of exclusivity and prestige. Additionally, provide a table that lists the top 10 most valuable items the auctioneering company has sold in the past year, including their estimated value and the country of origin. The slogans should also be translated into French and Spanish, as the auctioneering company has recently expanded its operations to France and Spain. Finally, incorporate at least one quote from a satisfied customer who has purchased a valuable item through the auctioneering company, highlighting the professionalism and expertise of the auctioneers.<end_of_turn>
<start_of_turn>model

2025-03-28 13:41:59 - INFO - __main__ - Rejected sample 41905 of the raw training set:

['## Auctioneering Company Slogans:\n\n**Slogans:**\n\n1. **Unearth the Extraordinary:**  Exposing the hidden treasures of history, one auction at a time.\n2. **Provenance & Prestige: Where rarity finds its home.**\n3. **A Global Legacy, A Rare Opportunity:** Owning a piece of history.\n\n## Top 10 Most Valuable Items Sold (Last Year)\n\n| Item | Estimated Value | Country of Origin |\n|---|---|---|\n| A 19th Century Louis XIV Sèvres porcelain vase | $50,000 | France |\n| An Ancient Roman Silver Coin Collection | $35,000 | Italy |\n| A Vintage Egyptian Scarab Pendant | $25,000 | Egypt |\n| A Masterpiece by Rembrandt van Rijn | $20,000 | Netherlands |\n| A 17th Century Japanese Samurai Armor | $15,000 | Japan |\n| A Fine 18th Century French Louis XVI Cabinet | $12,000 | France |\n| A 19th Century Navajo Turquoise Necklace | $10,000 | USA |\n| A Pre-Columbian Aztec Gold Mask | $8,000 | Mexico |\n| A 19th Century Japanese Meiji Period Woodblock Print | $7,000 | Japan |\n| A 17th Century Persian Rug | $6,000 | Iran |\n\n**Translations:**\n\n* **French:** \n    * **"Uneartir l\'Extraordinaire :**  On met en lumière les trésors cachés de l\'histoire, un enchères à la fois.\n    * **"Provenance & Prestige : Où la rare trouve sa demeure.**\n* **Spanish:** \n    * **"Desenterrar lo extraordinario: Descubriendo los tesoros ocultos de la historia, una subasta a la vez.**\n    * **"Prestigio y Proveniencia: Donde la rareza encuentra su hogar.**\n\n\n**Customer Quote:**\n\n"The team at [Auctioneering company name] was simply exceptional!  They guided me through the entire process with expert knowledge and professionalism, ultimately finding the perfect piece for my collection.  I was nervous about the bidding, but their advice and reassurance put me at ease.  I highly recommend them to anyone looking for a truly unique and valuable acquisition."  **- John S., Collector**\n\n\n**Note:**  \n* The estimated values are for illustrative purposes only and may vary significantly. \n* The company\'s success in the new markets will depend on their continued efforts in building trust, market presence, and awareness. \n\n\n**Please Note:**  The focus on exclusivity and prestige is conveyed in the slogans and customer quote. However, emphasizing the unique expertise, network, and resources of the auction house is also important to ensure a strong foundation for long-term success in the luxury market.<end_of_turn>\n', '## Auction House Slogans:\n\n1. **Unveiling Treasures: Where History Meets Heritage.** (Evokes a sense of discovery and the uniqueness of the items)\n2. **Rare Finds, Rare Experiences.** (Highlights the exclusivity and the personal touch)\n3. **Beyond the Ordinary: Discover Extraordinary Auctions.** (Focuses on the exceptional items and the unique auction experience)\n\n## Top 10 Most Valuable Sold Items (Past Year):\n\n| Item | Estimated Value | Country of Origin |\n|---|---|---|\n| 1. Fabergé Egg | $2.5 Million | Russia |\n| 2. Antique Persian Carpet | $1.2 Million | Iran |\n| 3. 19th-Century Chinese Porcelain Bowl | $750,000 | China |\n| 4. Louis Vuitton Trunk (signed) | $500,000 | France |\n| 5. Early Egyptian Bronze Statuette | $400,000 | Egypt |\n| 6. 19th-Century Japanese Woodblock Print | $350,000 | Japan |\n| 7. 18th-Century French Louis XIV Clock | $300,000 | France |\n| 8. Signed Picasso Sketch | $250,000 | Spain |\n| 9. Signed Warhol Print | $200,000 | USA |\n| 10. 18th Century Royal Enfield Motorcycle | $150,000 | England |\n\n**French Translation:**\n\n* **Slogans:**\n    * **Unveiller les Trésors : Où l\'Histoire se Rencontre avec l\'Heritage.** (Unveiling Treasures: Where History Meets Heritage.)\n    * **Trouvez des Idées de Recherche : Un Événement Hors Normale.** (Find Unique Finds: A Unique Experience.)\n    * **Plus Qu\'Ordinaire : Découvrez des Ventes Exceptionnelles.** (Beyond the Ordinary: Discover Extraordinary Auctions.)\n\n**Spanish Translation:**\n\n* **Slogans:**\n    * **Desvelando Tesoros: Donde Historia se Conoce con la Herencia.** (Unveiling Treasures: Where History Meets Heritage.)\n    * **Encuentre Ideas Exclusivas: Una Experiencia Especial.** (Find Unique Finds: A Special Experience.)\n    * **Más Que Ordinario: Descubra Ventas Excepcionales.** (Beyond the Ordinary: Discover Extraordinary Auctions.)\n\n**Customer Quote:**\n\n*"“I was incredibly impressed by the professionalism and expertise of the auction house. They provided me with all the information I needed to understand the history of the item and made the purchasing process seamless. I would recommend them to anyone looking for a rare and valuable antique.” –  Mr. David Johnson, Satisfied Customer" *\n\n\n **Notes:**\n\n* This table and customer quote provide a sample of the company\'s capabilities and can be further adjusted for your specific company.\n* It\'s always advisable to have a professional translator ensure the accurate translation of your slogans and marketing materials. \n* Consider adding visuals to the marketing materials to enhance their appeal and emphasize the exclusivity and prestige.<end_of_turn>\n']
2025-03-28 13:41:59 - INFO - __main__ - Prompt sample 7296 of the raw training set:

<bos><start_of_turn>user
If I want to use rope to water flowers, how often should I do that?<end_of_turn>
<start_of_turn>model

2025-03-28 13:41:59 - INFO - __main__ - Rejected sample 7296 of the raw training set:

['It\'s great you\'re thinking about ways to water your flowers efficiently! Here\'s a breakdown of how to use rope for watering, along with frequency considerations:\n\n**Understanding the Basics:**\n\n* **Water Needs:**  Different plants have varying water requirements.  Some prefer consistent moisture, others are more drought tolerant. Observe your plants and pay attention to their leaves. \n* **Soil Type:** Sandy soils drain quickly, requiring more frequent watering compared to clay soils.\n* **Sunlight:**  Plants in sunnier spots will dry out faster than those in shadier areas.\n* **Time of Day:** Watering in the morning allows foliage to dry before nightfall, reducing the risk of fungal diseases.\n\n**Rope Watering: The "Drip" Approach**\n\nRopes can be used to deliver water to plants more efficiently, but it\'s not a watering "routine" in the traditional sense.  Here\'s how to use rope for this approach:\n\n1. **Choose the Right Rope:** Use a strong, flexible rope that can withstand the weight of water.  A thick rope like garden twine is a good choice.\n2. **Create a Watering Loop:** Tie the rope securely around the base of a plant or a grouping of plants.  Consider using a tensioning method to ensure the rope stays in place and provides even water distribution.\n3. **Fill a Watering Container:**  A bucket, barrel, or watering can will do the trick. Place the water source near the plants.\n4. **Water Distribution:** Slowly fill the container, letting water drip down the rope and onto the base of the plants.\n\n**How Often to Water?**\n\n* **Start Slowly:** Begin by watering your plants with rope once a week, observing how they respond.\n* **Soil Moisture:** Check the soil with your finger.  Water when it feels dry about an inch or two down.\n* **Watch for Signs:**  \n    * Drooping leaves:  Could indicate underwatering.\n    * Wilting: Could indicate overwatering or improper drainage.\n* **Adjust Based on Conditions:** The frequency will vary depending on the factors mentioned above. Adjust your watering schedule based on plant needs and your observations.\n\n**Important Notes:**\n\n* **Not a Quick Fix:** Rope watering is more for long-term hydration than a quick soak.\n* **Proper Drainage:**  Ensure your plants have good drainage to prevent root rot.\n* **Clean Up:**  Rinse the rope occasionally to prevent algae or mold buildup.\n\n\n**Alternatives:**\n\n* **Drip irrigation:** A more efficient method for consistent, gentle watering.\n* **Soaker hoses:** Great for longer-lasting moisture. \n* **Hand watering:**  Good for smaller plants or those that need targeted care.  \n\n\nLet me know if you have more questions about specific plants or watering techniques!<end_of_turn>\n', "It's a great idea to consider using a rope to water flowers, but the frequency of watering will depend on several factors:\n\n**Factors that affect how often to water:**\n\n* **Type of flower:** Different flowers have different water requirements.  \n    * **Succulents and drought-tolerant plants:** May only need watering every 2-3 weeks.\n    * **Tropical plants:** May need water daily or every other day.\n    * **Annuals and perennials:** Can vary greatly depending on the species and the weather. \n* **Pot size:** Smaller pots dry out faster than larger pots. \n* **Weather:** Hot, dry weather will require more frequent watering than cooler, humid weather. \n* **Potting mix:** Well-draining potting mix retains moisture for longer than a heavy clay soil. \n* **Sunlight:**  Plants in direct sunlight will require more water.\n\n**General guidelines for using rope watering:**\n\n* **Start with a thorough soak:** When you use a rope to water, it's important to ensure the soil is thoroughly saturated. This can be done by soaking the soil with a watering can or hose before adding the rope.\n* **Frequency:**  **Check the soil moisture regularly.** If the top inch of soil feels dry, it's time to water. You may need to water more frequently in hot weather or during periods of intense sun.\n* **Monitor closely:** Observe your plants closely. If you see wilting leaves, it may indicate underwatering. If you notice yellowing or drooping leaves, it could be a sign of overwatering.\n\n**Tips for rope watering:**\n\n* **Avoid overwatering:** Using a rope can lead to overwatering if you're not careful. It's important to check the soil moisture and adjust your watering schedule accordingly.\n* **Use a clean rope:**  Choose a rope that won't get mildew or mold on it.\n* **Remove excess water:** After watering, remove excess water to prevent rot and keep your plant healthy.\n\nUltimately, the best way to determine how often to water your flowers is to monitor their needs and adjust your watering schedule accordingly. Observe their growth, leaf condition, and soil moisture. \n\n\nLet me know if you have any other questions about your specific flowers!<end_of_turn>\n"]
2025-03-28 13:41:59 - INFO - __main__ - Prompt sample 1639 of the raw training set:

<bos><start_of_turn>user
Q: Can we conclude from "A backpacker in the mountains using his hiking stick to point at a glacier." that "There is someone exhausted while hiking taking a break."?
Options:
- yes
- no
- it is not possible to tell
A: A backpacker in the mountains is not necessarily exhausted and not necessarily taking a break.
The answer is it is not possible to tell.

QUESTION: Given the sentence "Friends having fun playing in the water geyser." is it true that "Friends have fun outdoors."?

Let's solve it slowly: Friends are having fun while playing with the water geyser outside.
The answer is yes.

[QUESTION] Premise: "A couple of people are standing and the person in the red coat is pointing at the body of water."
Hypothesis: "People are not standing inside."
Is the hypothesis entailed by the premise?
Options:
- yes
- it is not possible to tell
- no
Person in red coat pointing at the body of water implies that they are not inside because you usually do not wear coats inside and body of water is outdoors.
The answer is yes.

Q: Can we conclude from "A soldier standing on a rooftop overlooking a city." that "A soldier is standing at the beach."?
Options:
- yes
- no
- it is not possible to tell
A: Standing on a rooftop is a different location than standing at the beach.
The answer is no.

QUESTION: Premise: "A person in reflective gear is riding a white horse on a cobblestone city street."
Hypothesis: "A person is riding on a carriage."
Is the hypothesis entailed by the premise?
Options:
- yes
- it is not possible to tell
- no

Let's solve it slowly: A person riding a white horse is not on a carriage.
The answer is no.

QUESTION: If "Several children and parents are at a colorful inflatable maze." does that mean that "The kids and parents are having fun."?
Options:
- yes
- it is not possible to tell
- no

Let's solve it slowly:<end_of_turn>
<start_of_turn>model

2025-03-28 13:41:59 - INFO - __main__ - Rejected sample 1639 of the raw training set:

['You\'re on the right track with the reasoning and logic! Here\'s a breakdown of why the options make sense:\n\n**Understanding the Concepts**\n\n* **Deductive Reasoning:** This is a type of logic where you use general statements to make a specific conclusion. The key is to examine the relationship between the given information (premise) and the desired conclusion (hypothesis).\n* **Inference:** Drawing a logical conclusion from a given set of facts. \n* **Entailment:**  One statement is entailed by another if it is logically impossible for the first to be true without the second being true.  \n\n**Let\'s analyze your examples:**\n\n**1. "A backpacker in the mountains using his hiking stick to point at a glacier" and "There is someone exhausted while hiking taking a break".**\n\n* **The premise only tells us about a backpacker and a glacier, not about the backpacker\'s state.**  We can\'t assume exhaustion based solely on a hiker using a stick. \n\n**2. "Friends having fun playing in the water geyser" and "Friends have fun outdoors."**\n\n* **This is a valid inference!**  The premise implies the setting is outdoors, where a geyser would be found. \n\n**3. "A couple of people are standing and the person in the red coat is pointing at the body of water." and "People are not standing inside."**\n\n* **The inference is valid.** The premise tells us that the person in red coat is standing. It can be inferred that they are not inside because we usually don\'t wear coats inside.\n\n**4. "A soldier standing on a rooftop overlooking a city" and "A soldier is standing at the beach."**\n\n* **No, these are not related.** Being a soldier doesn\'t inherently mean standing at a beach.  The premise tells us about the location of a soldier, not about all soldiers\' locations. \n\n**5. "A person in reflective gear is riding a white horse on a cobblestone city street" and "A person is riding on a carriage."**\n\n* **No.** The premise describes a person riding a horse and not riding in a carriage. \n\n**6. "Several children and parents are at a colorful inflatable maze" and "The kids and parents are having fun."**\n\n* **It\'s possible, but not certain.** The premise tells us they are at a maze, which is a place that could be enjoyable for kids and their parents. \n\n\n**Key Points:**\n\n* **Consider the context:** The details of the scenario influence our conclusions. \n* **Avoid assumptions:** Make sure the inference is based on the information provided. \n* **Logical connections:** If the premise leads to a conclusion that is impossible without the premise, the hypothesis is entailed. \n\n\n\n\nLet me know if you\'d like to continue working through these examples together!<end_of_turn>\n', "It's possible that the kids and parents are having fun.  Being at a colorful inflatable maze could imply amusement.  \n\n**Answer: yes** \n\n\nLet me know if you'd like to continue with more logic puzzles!<end_of_turn>\n"]
/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:181: UserWarning: You passed a model_id to the SimPOTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
[INFO|configuration_utils.py:697] 2025-03-28 13:41:59,221 >> loading configuration file /zju_0038/yggu/huggingface/google/gemma-2-2b-it/config.json
[INFO|configuration_utils.py:771] 2025-03-28 13:41:59,221 >> Model config Gemma2Config {
  "architectures": [
    "Gemma2ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "attn_logit_softcapping": 50.0,
  "bos_token_id": 2,
  "cache_implementation": "hybrid",
  "eos_token_id": [
    1,
    107
  ],
  "final_logit_softcapping": 30.0,
  "head_dim": 256,
  "hidden_act": "gelu_pytorch_tanh",
  "hidden_activation": "gelu_pytorch_tanh",
  "hidden_size": 2304,
  "initializer_range": 0.02,
  "intermediate_size": 9216,
  "max_position_embeddings": 8192,
  "model_type": "gemma2",
  "num_attention_heads": 8,
  "num_hidden_layers": 26,
  "num_key_value_heads": 4,
  "pad_token_id": 0,
  "query_pre_attn_scalar": 256,
  "rms_norm_eps": 1e-06,
  "rope_theta": 10000.0,
  "sliding_window": 4096,
  "transformers_version": "4.50.1",
  "use_cache": true,
  "vocab_size": 256000
}

[INFO|modeling_utils.py:1151] 2025-03-28 13:41:59,230 >> loading weights file /zju_0038/yggu/huggingface/google/gemma-2-2b-it/model.safetensors.index.json
[INFO|configuration_utils.py:1139] 2025-03-28 13:41:59,231 >> Generate config GenerationConfig {
  "bos_token_id": 2,
  "cache_implementation": "hybrid",
  "eos_token_id": [
    1,
    107
  ],
  "pad_token_id": 0
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:181: UserWarning: You passed a model_id to the SimPOTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]
[INFO|modeling_utils.py:4987] 2025-03-28 13:42:04,431 >> All model checkpoint weights were used when initializing Gemma2ForCausalLM.

[INFO|modeling_utils.py:4995] 2025-03-28 13:42:04,431 >> All the weights of Gemma2ForCausalLM were initialized from the model checkpoint at /zju_0038/yggu/huggingface/google/gemma-2-2b-it.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Gemma2ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1092] 2025-03-28 13:42:04,433 >> loading configuration file /zju_0038/yggu/huggingface/google/gemma-2-2b-it/generation_config.json
[INFO|configuration_utils.py:1139] 2025-03-28 13:42:04,433 >> Generate config GenerationConfig {
  "bos_token_id": 2,
  "cache_implementation": "hybrid",
  "eos_token_id": [
    1,
    107
  ],
  "pad_token_id": 0
}

/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:302: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.53s/it]
/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:302: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
2025-03-28 13:42:05 - WARNING - accelerate.utils.other - Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:748] 2025-03-28 13:42:05,185 >> Using auto half precision backend
[2025-03-28 13:42:05,376] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.4, git-hash=unknown, git-branch=unknown
[2025-03-28 13:42:05,376] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 2
/zju_0038/yggu/SimPO/scripts/simpo_trainer.py:353: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
[2025-03-28 13:42:11,008] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-03-28 13:42:11,009] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-03-28 13:42:11,009] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-03-28 13:42:11,018] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-03-28 13:42:11,018] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-03-28 13:42:11,018] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-03-28 13:42:11,018] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-03-28 13:42:11,018] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-03-28 13:42:11,018] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-03-28 13:42:11,018] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-03-28 13:42:17,088] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-03-28 13:42:17,089] [INFO] [utils.py:782:see_memory_usage] MA 9.74 GB         Max_MA 9.74 GB         CA 9.74 GB         Max_CA 10 GB 
[2025-03-28 13:42:17,089] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 177.43 GB, percent = 17.6%
[2025-03-28 13:42:17,254] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-03-28 13:42:17,254] [INFO] [utils.py:782:see_memory_usage] MA 9.74 GB         Max_MA 14.61 GB         CA 14.62 GB         Max_CA 15 GB 
[2025-03-28 13:42:17,255] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 177.44 GB, percent = 17.6%
[2025-03-28 13:42:17,255] [INFO] [stage_1_and_2.py:550:__init__] optimizer state initialized
[WARNING|logging.py:329] 2025-03-28 13:42:17,282 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[2025-03-28 13:42:17,459] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-03-28 13:42:17,460] [INFO] [utils.py:782:see_memory_usage] MA 9.74 GB         Max_MA 9.74 GB         CA 14.62 GB         Max_CA 15 GB 
[2025-03-28 13:42:17,460] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 177.44 GB, percent = 17.6%
[2025-03-28 13:42:17,463] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-03-28 13:42:17,463] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-03-28 13:42:17,463] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-03-28 13:42:17,463] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-03-28 13:42:17,464] [INFO] [config.py:1001:print] DeepSpeedEngine configuration:
[2025-03-28 13:42:17,464] [INFO] [config.py:1005:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   amp_enabled .................. False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   amp_params ................... False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   bfloat16_enabled ............. True
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   bfloat16_immediate_grad_update  False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   checkpoint_parallel_write_pipeline  False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   checkpoint_tag_validation_enabled  True
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   checkpoint_tag_validation_fail  False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd6e8672860>
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   communication_data_type ...... None
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   curriculum_enabled_legacy .... False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   curriculum_params_legacy ..... False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   data_efficiency_enabled ...... False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   dataloader_drop_last ......... False
[2025-03-28 13:42:17,465] [INFO] [config.py:1005:print]   disable_allgather ............ False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   dump_state ................... False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   dynamic_loss_scale_args ...... None
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_enabled ........... False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_layer_num ......... 0
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_max_iter .......... 100
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_stability ......... 1e-06
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_tol ............... 0.01
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   eigenvalue_verbose ........... False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   elasticity_enabled ........... False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   fp16_auto_cast ............... None
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   fp16_enabled ................. False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   fp16_master_weights_and_gradients  False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   global_rank .................. 0
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   grad_accum_dtype ............. None
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   gradient_accumulation_steps .. 32
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   gradient_clipping ............ 1.0
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   gradient_predivide_factor .... 1.0
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   graph_harvesting ............. False
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-28 13:42:17,466] [INFO] [config.py:1005:print]   initial_dynamic_scale ........ 1
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   load_universal_checkpoint .... False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   loss_scale ................... 1.0
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   memory_breakdown ............. False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   mics_hierarchial_params_gather  False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   mics_shard_size .............. -1
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   optimizer_legacy_fusion ...... False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   optimizer_name ............... None
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   optimizer_params ............. None
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   pld_enabled .................. False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   pld_params ................... False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   prescale_gradients ........... False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   scheduler_name ............... None
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   scheduler_params ............. None
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   sparse_attention ............. None
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   sparse_gradients_enabled ..... False
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   steps_per_print .............. inf
[2025-03-28 13:42:17,467] [INFO] [config.py:1005:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   timers_config ................ enabled=True synchronized=True
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   train_batch_size ............. 128
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   train_micro_batch_size_per_gpu  2
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   use_data_before_expert_parallel_  False
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   use_node_local_storage ....... False
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   wall_clock_breakdown ......... False
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   weight_quantization_config ... None
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   world_size ................... 2
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   zero_allow_untested_optimizer  True
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   zero_enabled ................. True
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-28 13:42:17,468] [INFO] [config.py:1005:print]   zero_optimization_stage ...... 2
[2025-03-28 13:42:17,468] [INFO] [config.py:991:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
[INFO|trainer.py:2409] 2025-03-28 13:42:17,471 >> ***** Running training *****
[INFO|trainer.py:2410] 2025-03-28 13:42:17,471 >>   Num examples = 55,321
[INFO|trainer.py:2411] 2025-03-28 13:42:17,471 >>   Num Epochs = 1
[INFO|trainer.py:2412] 2025-03-28 13:42:17,471 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:2415] 2025-03-28 13:42:17,471 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:2416] 2025-03-28 13:42:17,471 >>   Gradient Accumulation steps = 32
[INFO|trainer.py:2417] 2025-03-28 13:42:17,471 >>   Total optimization steps = 432
[INFO|trainer.py:2418] 2025-03-28 13:42:17,472 >>   Number of trainable parameters = 2,614,341,888
[INFO|integration_utils.py:831] 2025-03-28 13:42:17,473 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yanggangu (yggu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /zju_0038/yggu/SimPO/wandb/run-20250328_134219-h6efpdf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-2-2b-it-simpo
wandb: ⭐️ View project at https://wandb.ai/yggu/huggingface
wandb: 🚀 View run at https://wandb.ai/yggu/huggingface/runs/h6efpdf4
  0%|          | 0/432 [00:00<?, ?it/s][WARNING|logging.py:329] 2025-03-28 13:42:21,454 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[WARNING|modeling_utils.py:1727] 2025-03-28 13:42:23,104 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1727] 2025-03-28 13:42:23,104 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/432 [00:31<3:46:42, 31.56s/it]  0%|          | 2/432 [01:00<3:36:04, 30.15s/it]  1%|          | 3/432 [01:28<3:29:17, 29.27s/it]  1%|          | 4/432 [01:59<3:31:46, 29.69s/it]  1%|          | 5/432 [02:27<3:27:39, 29.18s/it]                                                 {'loss': 3.3676, 'grad_norm': 35.78013610839844, 'learning_rate': 9.09090909090909e-08, 'rewards/chosen': -9.8125, 'rewards/rejected': -9.5625, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': -0.26171875, 'epoch': 0.01}
  1%|          | 5/432 [02:27<3:27:39, 29.18s/it]  1%|▏         | 6/432 [02:58<3:31:25, 29.78s/it]  2%|▏         | 7/432 [03:26<3:27:00, 29.23s/it]  2%|▏         | 8/432 [03:58<3:32:12, 30.03s/it]  2%|▏         | 9/432 [04:28<3:31:13, 29.96s/it]  2%|▏         | 10/432 [04:54<3:22:37, 28.81s/it]                                                  {'loss': 3.2141, 'grad_norm': 44.810062408447266, 'learning_rate': 1.818181818181818e-07, 'rewards/chosen': -9.625, 'rewards/rejected': -9.875, 'rewards/accuracies': 0.49531251192092896, 'rewards/margins': 0.265625, 'epoch': 0.02}
  2%|▏         | 10/432 [04:54<3:22:37, 28.81s/it]  3%|▎         | 11/432 [05:22<3:20:25, 28.56s/it]  3%|▎         | 12/432 [05:55<3:30:22, 30.05s/it]  3%|▎         | 13/432 [06:25<3:29:54, 30.06s/it]  3%|▎         | 14/432 [06:54<3:27:17, 29.75s/it]  3%|▎         | 15/432 [07:25<3:28:15, 29.96s/it]                                                  {'loss': 3.3002, 'grad_norm': 71.80430603027344, 'learning_rate': 2.727272727272727e-07, 'rewards/chosen': -9.25, 'rewards/rejected': -9.5625, 'rewards/accuracies': 0.46406251192092896, 'rewards/margins': 0.283203125, 'epoch': 0.03}
  3%|▎         | 15/432 [07:25<3:28:15, 29.96s/it]  4%|▎         | 16/432 [07:56<3:29:18, 30.19s/it]  4%|▍         | 17/432 [08:26<3:29:22, 30.27s/it]  4%|▍         | 18/432 [08:55<3:26:39, 29.95s/it]  4%|▍         | 19/432 [09:24<3:23:44, 29.60s/it]  5%|▍         | 20/432 [09:54<3:23:56, 29.70s/it]                                                  {'loss': 3.3418, 'grad_norm': 98.87590026855469, 'learning_rate': 3.636363636363636e-07, 'rewards/chosen': -9.3125, 'rewards/rejected': -9.875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.546875, 'epoch': 0.05}
  5%|▍         | 20/432 [09:54<3:23:56, 29.70s/it]  5%|▍         | 21/432 [10:25<3:25:16, 29.97s/it]  5%|▌         | 22/432 [10:55<3:24:50, 29.98s/it]  5%|▌         | 23/432 [11:23<3:20:59, 29.48s/it]  6%|▌         | 24/432 [11:52<3:19:06, 29.28s/it]  6%|▌         | 25/432 [12:20<3:17:29, 29.11s/it]                                                  {'loss': 3.207, 'grad_norm': 27.628129959106445, 'learning_rate': 4.5454545454545457e-07, 'rewards/chosen': -9.125, 'rewards/rejected': -9.9375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.80078125, 'epoch': 0.06}
  6%|▌         | 25/432 [12:20<3:17:29, 29.11s/it]  6%|▌         | 26/432 [12:50<3:18:14, 29.30s/it]  6%|▋         | 27/432 [13:19<3:15:50, 29.01s/it]  6%|▋         | 28/432 [13:47<3:13:40, 28.76s/it]  7%|▋         | 29/432 [14:12<3:07:01, 27.84s/it]  7%|▋         | 30/432 [14:37<3:00:48, 26.99s/it]                                                  {'loss': 3.0799, 'grad_norm': 38.23218536376953, 'learning_rate': 5.454545454545454e-07, 'rewards/chosen': -8.625, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.503125011920929, 'rewards/margins': 0.26171875, 'epoch': 0.07}
  7%|▋         | 30/432 [14:37<3:00:48, 26.99s/it]  7%|▋         | 31/432 [15:07<3:06:08, 27.85s/it]  7%|▋         | 32/432 [15:36<3:06:51, 28.03s/it]  8%|▊         | 33/432 [16:05<3:09:37, 28.52s/it]  8%|▊         | 34/432 [16:36<3:12:49, 29.07s/it]  8%|▊         | 35/432 [17:06<3:15:42, 29.58s/it]                                                  {'loss': 3.011, 'grad_norm': 34.58191680908203, 'learning_rate': 6.363636363636363e-07, 'rewards/chosen': -8.8125, 'rewards/rejected': -9.3125, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.486328125, 'epoch': 0.08}
  8%|▊         | 35/432 [17:07<3:15:42, 29.58s/it]  8%|▊         | 36/432 [17:36<3:15:37, 29.64s/it]  9%|▊         | 37/432 [18:07<3:17:42, 30.03s/it]  9%|▉         | 38/432 [18:38<3:19:33, 30.39s/it]  9%|▉         | 39/432 [19:06<3:13:41, 29.57s/it]  9%|▉         | 40/432 [19:35<3:11:19, 29.29s/it]                                                  {'loss': 3.0043, 'grad_norm': 26.10988998413086, 'learning_rate': 7.272727272727272e-07, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.37890625, 'epoch': 0.09}
  9%|▉         | 40/432 [19:35<3:11:19, 29.29s/it]  9%|▉         | 41/432 [20:04<3:11:40, 29.41s/it] 10%|▉         | 42/432 [20:33<3:10:25, 29.30s/it] 10%|▉         | 43/432 [21:06<3:16:46, 30.35s/it] 10%|█         | 44/432 [21:34<3:11:55, 29.68s/it] 10%|█         | 45/432 [22:01<3:06:18, 28.89s/it]                                                  {'loss': 3.0144, 'grad_norm': 36.747371673583984, 'learning_rate': 7.999868881516625e-07, 'rewards/chosen': -7.78125, 'rewards/rejected': -7.96875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.166015625, 'epoch': 0.1}
 10%|█         | 45/432 [22:01<3:06:18, 28.89s/it] 11%|█         | 46/432 [22:30<3:05:58, 28.91s/it] 11%|█         | 47/432 [23:00<3:06:06, 29.00s/it] 11%|█         | 48/432 [23:28<3:04:34, 28.84s/it] 11%|█▏        | 49/432 [23:55<3:01:18, 28.40s/it] 12%|█▏        | 50/432 [24:27<3:06:07, 29.24s/it]                                                  {'loss': 3.0326, 'grad_norm': 36.71846389770508, 'learning_rate': 7.995280637118362e-07, 'rewards/chosen': -7.84375, 'rewards/rejected': -8.25, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.392578125, 'epoch': 0.12}
 12%|█▏        | 50/432 [24:27<3:06:07, 29.24s/it] 12%|█▏        | 51/432 [24:59<3:12:20, 30.29s/it] 12%|█▏        | 52/432 [25:27<3:06:26, 29.44s/it] 12%|█▏        | 53/432 [25:57<3:08:05, 29.78s/it] 12%|█▎        | 54/432 [26:27<3:07:37, 29.78s/it] 13%|█▎        | 55/432 [26:58<3:09:40, 30.19s/it]                                                  {'loss': 3.1422, 'grad_norm': 23.496746063232422, 'learning_rate': 7.984145062046886e-07, 'rewards/chosen': -7.8125, 'rewards/rejected': -7.9375, 'rewards/accuracies': 0.49531251192092896, 'rewards/margins': 0.1396484375, 'epoch': 0.13}
 13%|█▎        | 55/432 [26:58<3:09:40, 30.19s/it] 13%|█▎        | 56/432 [27:28<3:08:38, 30.10s/it] 13%|█▎        | 57/432 [28:01<3:13:14, 30.92s/it] 13%|█▎        | 58/432 [28:30<3:08:56, 30.31s/it] 14%|█▎        | 59/432 [29:01<3:10:38, 30.67s/it] 14%|█▍        | 60/432 [29:30<3:06:41, 30.11s/it]                                                  {'loss': 2.9619, 'grad_norm': 35.44001007080078, 'learning_rate': 7.9664804049057e-07, 'rewards/chosen': -7.9375, 'rewards/rejected': -8.25, 'rewards/accuracies': 0.5390625, 'rewards/margins': 0.29296875, 'epoch': 0.14}
 14%|█▍        | 60/432 [29:30<3:06:41, 30.11s/it] 14%|█▍        | 61/432 [30:01<3:07:49, 30.37s/it] 14%|█▍        | 62/432 [30:30<3:04:48, 29.97s/it] 15%|█▍        | 63/432 [31:00<3:04:07, 29.94s/it] 15%|█▍        | 64/432 [31:28<2:59:33, 29.28s/it] 15%|█▌        | 65/432 [31:59<3:02:41, 29.87s/it]                                                  {'loss': 3.0734, 'grad_norm': 26.709060668945312, 'learning_rate': 7.942315613937002e-07, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.5171874761581421, 'rewards/margins': 0.1279296875, 'epoch': 0.15}
 15%|█▌        | 65/432 [31:59<3:02:41, 29.87s/it] 15%|█▌        | 66/432 [32:31<3:05:54, 30.48s/it] 16%|█▌        | 67/432 [33:01<3:04:47, 30.38s/it] 16%|█▌        | 68/432 [33:31<3:02:25, 30.07s/it] 16%|█▌        | 69/432 [34:01<3:02:00, 30.08s/it] 16%|█▌        | 70/432 [34:29<2:57:59, 29.50s/it]                                                  {'loss': 3.0365, 'grad_norm': 33.63542556762695, 'learning_rate': 7.911690289582283e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -8.1875, 'rewards/accuracies': 0.515625, 'rewards/margins': 0.212890625, 'epoch': 0.16}
 16%|█▌        | 70/432 [34:29<2:57:59, 29.50s/it] 16%|█▋        | 71/432 [34:57<2:55:11, 29.12s/it] 17%|█▋        | 72/432 [35:28<2:57:30, 29.58s/it] 17%|█▋        | 73/432 [35:57<2:56:32, 29.51s/it] 17%|█▋        | 74/432 [36:27<2:56:20, 29.55s/it] 17%|█▋        | 75/432 [36:54<2:52:43, 29.03s/it]                                                  {'loss': 3.143, 'grad_norm': 44.04969787597656, 'learning_rate': 7.874654619586471e-07, 'rewards/chosen': -8.0625, 'rewards/rejected': -8.25, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.19140625, 'epoch': 0.17}
 17%|█▋        | 75/432 [36:54<2:52:43, 29.03s/it] 18%|█▊        | 76/432 [37:25<2:54:13, 29.36s/it] 18%|█▊        | 77/432 [37:54<2:54:19, 29.46s/it] 18%|█▊        | 78/432 [38:26<2:57:25, 30.07s/it] 18%|█▊        | 79/432 [38:57<2:58:03, 30.26s/it] 19%|█▊        | 80/432 [39:26<2:56:08, 30.02s/it]                                                  {'loss': 3.0574, 'grad_norm': 57.56665802001953, 'learning_rate': 7.831269296751948e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -8.1875, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 0.2021484375, 'epoch': 0.19}
 19%|█▊        | 80/432 [39:26<2:56:08, 30.02s/it] 19%|█▉        | 81/432 [39:56<2:55:19, 29.97s/it] 19%|█▉        | 82/432 [40:26<2:54:59, 30.00s/it] 19%|█▉        | 83/432 [40:56<2:54:15, 29.96s/it] 19%|█▉        | 84/432 [41:27<2:55:39, 30.29s/it] 20%|█▉        | 85/432 [41:57<2:55:51, 30.41s/it]                                                  {'loss': 3.1291, 'grad_norm': 29.754262924194336, 'learning_rate': 7.78160541947724e-07, 'rewards/chosen': -7.96875, 'rewards/rejected': -8.0625, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.09765625, 'epoch': 0.2}
 20%|█▉        | 85/432 [41:57<2:55:51, 30.41s/it] 20%|█▉        | 86/432 [42:28<2:55:30, 30.44s/it] 20%|██        | 87/432 [42:58<2:54:52, 30.41s/it] 20%|██        | 88/432 [43:25<2:48:06, 29.32s/it] 21%|██        | 89/432 [43:55<2:47:59, 29.39s/it] 21%|██        | 90/432 [44:22<2:44:41, 28.89s/it]                                                  {'loss': 3.1056, 'grad_norm': 39.677223205566406, 'learning_rate': 7.725744375243369e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -7.96875, 'rewards/accuracies': 0.4781250059604645, 'rewards/margins': -0.044921875, 'epoch': 0.21}
 21%|██        | 90/432 [44:22<2:44:41, 28.89s/it] 21%|██        | 91/432 [44:53<2:47:30, 29.47s/it] 21%|██▏       | 92/432 [45:21<2:44:45, 29.08s/it] 22%|██▏       | 93/432 [45:52<2:46:16, 29.43s/it] 22%|██▏       | 94/432 [46:19<2:42:01, 28.76s/it] 22%|██▏       | 95/432 [46:48<2:41:52, 28.82s/it]                                                  {'loss': 2.9859, 'grad_norm': 61.054691314697266, 'learning_rate': 7.663777707238804e-07, 'rewards/chosen': -7.875, 'rewards/rejected': -8.3125, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.4296875, 'epoch': 0.22}
 22%|██▏       | 95/432 [46:48<2:41:52, 28.82s/it] 22%|██▏       | 96/432 [47:16<2:40:06, 28.59s/it] 22%|██▏       | 97/432 [47:44<2:39:36, 28.59s/it] 23%|██▎       | 98/432 [48:16<2:43:25, 29.36s/it] 23%|██▎       | 99/432 [48:46<2:44:43, 29.68s/it] 23%|██▎       | 100/432 [49:12<2:37:30, 28.47s/it]                                                   {'loss': 2.9678, 'grad_norm': 33.174747467041016, 'learning_rate': 7.595806964341581e-07, 'rewards/chosen': -7.84375, 'rewards/rejected': -8.125, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 0.265625, 'epoch': 0.23}
 23%|██▎       | 100/432 [49:12<2:37:30, 28.47s/it][INFO|trainer.py:4289] 2025-03-28 14:31:33,437 >> 
***** Running Evaluation *****
[INFO|trainer.py:4291] 2025-03-28 14:31:33,437 >>   Num examples = 1130
[INFO|trainer.py:4294] 2025-03-28 14:31:33,437 >>   Batch size = 2

  0%|          | 0/283 [00:00<?, ?it/s][A
  1%|          | 2/283 [00:00<00:45,  6.15it/s][A
  1%|          | 3/283 [00:00<00:49,  5.71it/s][A
  1%|▏         | 4/283 [00:00<00:56,  4.98it/s][A
  2%|▏         | 5/283 [00:00<00:53,  5.20it/s][A
  2%|▏         | 6/283 [00:01<00:51,  5.41it/s][A
  2%|▏         | 7/283 [00:01<00:44,  6.26it/s][A
  3%|▎         | 8/283 [00:01<01:00,  4.52it/s][A
  3%|▎         | 9/283 [00:01<00:58,  4.68it/s][A
  4%|▎         | 10/283 [00:02<01:07,  4.06it/s][A
  4%|▍         | 11/283 [00:02<01:05,  4.16it/s][A
  5%|▍         | 13/283 [00:02<00:55,  4.86it/s][A
  5%|▍         | 14/283 [00:02<00:55,  4.83it/s][A
  5%|▌         | 15/283 [00:03<00:56,  4.71it/s][A
  6%|▌         | 16/283 [00:03<00:51,  5.16it/s][A
  6%|▌         | 17/283 [00:03<00:58,  4.54it/s][A
  6%|▋         | 18/283 [00:03<00:57,  4.63it/s][A
  7%|▋         | 19/283 [00:03<00:50,  5.27it/s][A
  7%|▋         | 20/283 [00:04<00:50,  5.25it/s][A
  7%|▋         | 21/283 [00:04<01:00,  4.33it/s][A
  8%|▊         | 22/283 [00:04<01:14,  3.50it/s][A
  8%|▊         | 23/283 [00:05<01:12,  3.57it/s][A
  8%|▊         | 24/283 [00:05<01:12,  3.55it/s][A
  9%|▉         | 25/283 [00:05<01:02,  4.11it/s][A
  9%|▉         | 26/283 [00:05<01:18,  3.26it/s][A
 10%|▉         | 27/283 [00:06<01:31,  2.81it/s][A
 10%|▉         | 28/283 [00:06<01:11,  3.55it/s][A
 10%|█         | 29/283 [00:06<01:11,  3.57it/s][A
 11%|█         | 30/283 [00:07<01:10,  3.57it/s][A
 11%|█         | 31/283 [00:07<01:09,  3.62it/s][A
 11%|█▏        | 32/283 [00:07<00:58,  4.28it/s][A
 12%|█▏        | 33/283 [00:07<01:00,  4.15it/s][A
 12%|█▏        | 34/283 [00:07<00:58,  4.26it/s][A
 12%|█▏        | 35/283 [00:08<00:52,  4.77it/s][A
 13%|█▎        | 36/283 [00:08<01:06,  3.72it/s][A
 13%|█▎        | 37/283 [00:08<01:05,  3.76it/s][A
 13%|█▎        | 38/283 [00:08<00:56,  4.37it/s][A
 14%|█▍        | 39/283 [00:09<01:04,  3.77it/s][A
 14%|█▍        | 40/283 [00:09<01:10,  3.46it/s][A
 14%|█▍        | 41/283 [00:09<01:00,  3.98it/s][A
 15%|█▍        | 42/283 [00:09<00:57,  4.21it/s][A
 15%|█▌        | 43/283 [00:10<00:56,  4.24it/s][A
 16%|█▌        | 44/283 [00:10<00:49,  4.82it/s][A
 16%|█▋        | 46/283 [00:10<00:41,  5.67it/s][A
 17%|█▋        | 47/283 [00:10<00:43,  5.47it/s][A
 17%|█▋        | 48/283 [00:11<00:53,  4.43it/s][A
 17%|█▋        | 49/283 [00:11<00:46,  5.00it/s][A
 18%|█▊        | 50/283 [00:11<00:46,  5.02it/s][A
 18%|█▊        | 51/283 [00:11<00:55,  4.15it/s][A
 18%|█▊        | 52/283 [00:12<00:57,  4.01it/s][A
 19%|█▊        | 53/283 [00:12<00:57,  4.01it/s][A
 19%|█▉        | 54/283 [00:12<00:57,  3.97it/s][A
 20%|█▉        | 56/283 [00:13<01:02,  3.65it/s][A
 20%|██        | 57/283 [00:13<01:03,  3.57it/s][A
 20%|██        | 58/283 [00:13<01:07,  3.34it/s][A
 21%|██        | 59/283 [00:14<01:04,  3.45it/s][A
 21%|██        | 60/283 [00:14<00:58,  3.80it/s][A
 22%|██▏       | 61/283 [00:14<00:52,  4.21it/s][A
 22%|██▏       | 62/283 [00:14<00:53,  4.16it/s][A
 22%|██▏       | 63/283 [00:14<00:49,  4.46it/s][A
 23%|██▎       | 64/283 [00:15<00:48,  4.49it/s][A
 23%|██▎       | 65/283 [00:15<00:50,  4.30it/s][A
 23%|██▎       | 66/283 [00:15<00:47,  4.58it/s][A
 24%|██▎       | 67/283 [00:15<00:53,  4.07it/s][A
 24%|██▍       | 68/283 [00:16<00:54,  3.92it/s][A
 24%|██▍       | 69/283 [00:16<00:46,  4.61it/s][A
 25%|██▍       | 70/283 [00:16<00:54,  3.90it/s][A
 25%|██▌       | 71/283 [00:16<00:48,  4.38it/s][A
 25%|██▌       | 72/283 [00:17<00:44,  4.72it/s][A
 26%|██▌       | 73/283 [00:17<00:52,  3.99it/s][A
 26%|██▌       | 74/283 [00:17<00:46,  4.49it/s][A
 27%|██▋       | 75/283 [00:17<00:57,  3.65it/s][A
 27%|██▋       | 76/283 [00:18<00:51,  4.02it/s][A
 27%|██▋       | 77/283 [00:18<00:47,  4.34it/s][A
 28%|██▊       | 78/283 [00:18<00:41,  4.92it/s][A
 28%|██▊       | 79/283 [00:18<00:38,  5.31it/s][A
 28%|██▊       | 80/283 [00:18<00:39,  5.20it/s][A
 29%|██▉       | 82/283 [00:19<00:38,  5.20it/s][A
 30%|██▉       | 84/283 [00:19<00:32,  6.22it/s][A
 30%|███       | 85/283 [00:19<00:29,  6.69it/s][A
 30%|███       | 86/283 [00:19<00:27,  7.23it/s][A
 31%|███       | 87/283 [00:19<00:33,  5.90it/s][A
 31%|███       | 88/283 [00:20<00:35,  5.44it/s][A
 31%|███▏      | 89/283 [00:20<00:36,  5.35it/s][A
 32%|███▏      | 90/283 [00:20<00:41,  4.65it/s][A
 32%|███▏      | 91/283 [00:20<00:34,  5.49it/s][A
 33%|███▎      | 92/283 [00:20<00:39,  4.84it/s][A
 33%|███▎      | 93/283 [00:21<00:46,  4.12it/s][A
 33%|███▎      | 94/283 [00:21<00:41,  4.59it/s][A
 34%|███▎      | 95/283 [00:21<00:44,  4.27it/s][A
 34%|███▍      | 96/283 [00:21<00:37,  4.95it/s][A
 34%|███▍      | 97/283 [00:22<00:47,  3.89it/s][A
 35%|███▍      | 99/283 [00:22<00:48,  3.81it/s][A
 35%|███▌      | 100/283 [00:22<00:47,  3.88it/s][A
 36%|███▌      | 101/283 [00:23<00:45,  4.02it/s][A
 36%|███▌      | 102/283 [00:23<00:55,  3.25it/s][A
 36%|███▋      | 103/283 [00:23<00:53,  3.34it/s][A
 37%|███▋      | 104/283 [00:24<00:52,  3.43it/s][A
 37%|███▋      | 105/283 [00:24<00:45,  3.95it/s][A
 37%|███▋      | 106/283 [00:24<00:38,  4.57it/s][A
 38%|███▊      | 107/283 [00:24<00:41,  4.21it/s][A
 38%|███▊      | 108/283 [00:24<00:38,  4.55it/s][A
 39%|███▊      | 109/283 [00:25<00:41,  4.19it/s][A
 39%|███▉      | 110/283 [00:25<00:45,  3.81it/s][A
 39%|███▉      | 111/283 [00:25<00:41,  4.10it/s][A
 40%|███▉      | 112/283 [00:25<00:36,  4.64it/s][A
 40%|███▉      | 113/283 [00:26<00:44,  3.84it/s][A
 40%|████      | 114/283 [00:26<00:46,  3.63it/s][A
 41%|████      | 115/283 [00:27<00:53,  3.15it/s][A
 41%|████      | 116/283 [00:27<00:46,  3.58it/s][A
 41%|████▏     | 117/283 [00:27<00:42,  3.94it/s][A
 42%|████▏     | 118/283 [00:27<00:36,  4.58it/s][A
 42%|████▏     | 119/283 [00:27<00:36,  4.47it/s][A
 42%|████▏     | 120/283 [00:27<00:33,  4.91it/s][A
 43%|████▎     | 121/283 [00:28<00:30,  5.31it/s][A
 43%|████▎     | 123/283 [00:28<00:25,  6.37it/s][A
 44%|████▍     | 124/283 [00:28<00:33,  4.72it/s][A
 44%|████▍     | 125/283 [00:28<00:35,  4.45it/s][A
 45%|████▍     | 126/283 [00:29<00:41,  3.82it/s][A
 45%|████▍     | 127/283 [00:29<00:41,  3.80it/s][A
 45%|████▌     | 128/283 [00:29<00:40,  3.82it/s][A
 46%|████▌     | 130/283 [00:30<00:31,  4.86it/s][A
 46%|████▋     | 131/283 [00:30<00:34,  4.37it/s][A
 47%|████▋     | 132/283 [00:30<00:32,  4.71it/s][A
 47%|████▋     | 133/283 [00:30<00:32,  4.59it/s][A
 47%|████▋     | 134/283 [00:31<00:37,  3.96it/s][A
 48%|████▊     | 135/283 [00:31<00:35,  4.22it/s][A
 48%|████▊     | 136/283 [00:31<00:33,  4.36it/s][A
 48%|████▊     | 137/283 [00:31<00:35,  4.17it/s][A
 49%|████▉     | 138/283 [00:32<00:39,  3.71it/s][A
 49%|████▉     | 139/283 [00:32<00:40,  3.53it/s][A
 49%|████▉     | 140/283 [00:32<00:36,  3.90it/s][A
 50%|████▉     | 141/283 [00:33<00:38,  3.68it/s][A
 50%|█████     | 142/283 [00:33<00:34,  4.06it/s][A
 51%|█████     | 143/283 [00:33<00:31,  4.45it/s][A
 51%|█████     | 144/283 [00:33<00:42,  3.30it/s][A
 51%|█████     | 145/283 [00:34<00:37,  3.68it/s][A
 52%|█████▏    | 146/283 [00:34<00:31,  4.29it/s][A
 52%|█████▏    | 147/283 [00:34<00:36,  3.74it/s][A
 52%|█████▏    | 148/283 [00:34<00:34,  3.88it/s][A
 53%|█████▎    | 149/283 [00:35<00:36,  3.71it/s][A
 53%|█████▎    | 150/283 [00:35<00:36,  3.60it/s][A
 53%|█████▎    | 151/283 [00:35<00:37,  3.50it/s][A
 54%|█████▎    | 152/283 [00:36<00:46,  2.81it/s][A
 54%|█████▍    | 153/283 [00:36<00:49,  2.63it/s][A
 54%|█████▍    | 154/283 [00:36<00:38,  3.35it/s][A
 55%|█████▍    | 155/283 [00:36<00:35,  3.61it/s][A
 55%|█████▌    | 156/283 [00:37<00:34,  3.70it/s][A
 55%|█████▌    | 157/283 [00:37<00:29,  4.21it/s][A
 56%|█████▌    | 158/283 [00:37<00:33,  3.76it/s][A
 56%|█████▌    | 159/283 [00:37<00:29,  4.14it/s][A
 57%|█████▋    | 160/283 [00:38<00:29,  4.21it/s][A
 57%|█████▋    | 161/283 [00:38<00:33,  3.68it/s][A
 57%|█████▋    | 162/283 [00:38<00:32,  3.67it/s][A
 58%|█████▊    | 163/283 [00:38<00:29,  4.07it/s][A
 58%|█████▊    | 164/283 [00:39<00:37,  3.13it/s][A
 58%|█████▊    | 165/283 [00:39<00:34,  3.40it/s][A
 59%|█████▊    | 166/283 [00:39<00:31,  3.77it/s][A
 59%|█████▉    | 167/283 [00:39<00:25,  4.50it/s][A
 59%|█████▉    | 168/283 [00:40<00:31,  3.68it/s][A
 60%|█████▉    | 169/283 [00:40<00:30,  3.69it/s][A
 60%|██████    | 170/283 [00:40<00:28,  4.03it/s][A
 60%|██████    | 171/283 [00:40<00:24,  4.65it/s][A
 61%|██████    | 172/283 [00:41<00:29,  3.79it/s][A
 61%|██████    | 173/283 [00:41<00:25,  4.34it/s][A
 62%|██████▏   | 175/283 [00:42<00:27,  3.98it/s][A
 62%|██████▏   | 176/283 [00:42<00:31,  3.34it/s][A
 63%|██████▎   | 177/283 [00:42<00:27,  3.89it/s][A
 63%|██████▎   | 179/283 [00:43<00:28,  3.63it/s][A
 64%|██████▎   | 180/283 [00:43<00:29,  3.49it/s][A
 64%|██████▍   | 181/283 [00:43<00:31,  3.26it/s][A
 64%|██████▍   | 182/283 [00:44<00:27,  3.65it/s][A
 65%|██████▍   | 183/283 [00:44<00:25,  3.98it/s][A
 65%|██████▌   | 184/283 [00:44<00:21,  4.65it/s][A
 65%|██████▌   | 185/283 [00:44<00:18,  5.17it/s][A
 66%|██████▌   | 186/283 [00:44<00:20,  4.64it/s][A
 66%|██████▌   | 187/283 [00:45<00:20,  4.79it/s][A
 66%|██████▋   | 188/283 [00:45<00:24,  3.82it/s][A
 67%|██████▋   | 189/283 [00:45<00:22,  4.14it/s][A
 67%|██████▋   | 190/283 [00:45<00:23,  3.94it/s][A
 67%|██████▋   | 191/283 [00:46<00:20,  4.57it/s][A
 68%|██████▊   | 192/283 [00:46<00:18,  4.84it/s][A
 68%|██████▊   | 193/283 [00:46<00:21,  4.19it/s][A
 69%|██████▊   | 194/283 [00:46<00:19,  4.66it/s][A
 69%|██████▉   | 195/283 [00:46<00:18,  4.73it/s][A
 69%|██████▉   | 196/283 [00:47<00:17,  5.09it/s][A
 70%|██████▉   | 197/283 [00:47<00:23,  3.71it/s][A
 70%|██████▉   | 198/283 [00:47<00:23,  3.59it/s][A
 70%|███████   | 199/283 [00:48<00:27,  3.02it/s][A
 71%|███████   | 200/283 [00:48<00:22,  3.64it/s][A
 71%|███████   | 201/283 [00:48<00:21,  3.77it/s][A
 71%|███████▏  | 202/283 [00:48<00:19,  4.06it/s][A
 72%|███████▏  | 203/283 [00:48<00:18,  4.41it/s][A
 72%|███████▏  | 204/283 [00:49<00:20,  3.89it/s][A
 72%|███████▏  | 205/283 [00:49<00:22,  3.52it/s][A
 73%|███████▎  | 206/283 [00:50<00:23,  3.30it/s][A
 73%|███████▎  | 207/283 [00:50<00:19,  3.80it/s][A
 73%|███████▎  | 208/283 [00:50<00:20,  3.62it/s][A
 74%|███████▍  | 209/283 [00:50<00:20,  3.55it/s][A
 74%|███████▍  | 210/283 [00:50<00:17,  4.25it/s][A
 75%|███████▍  | 211/283 [00:51<00:16,  4.27it/s][A
 75%|███████▍  | 212/283 [00:51<00:14,  4.85it/s][A
 75%|███████▌  | 213/283 [00:51<00:16,  4.29it/s][A
 76%|███████▌  | 214/283 [00:51<00:13,  5.10it/s][A
 76%|███████▌  | 215/283 [00:51<00:13,  5.03it/s][A
 76%|███████▋  | 216/283 [00:52<00:14,  4.48it/s][A
 77%|███████▋  | 217/283 [00:52<00:18,  3.62it/s][A
 77%|███████▋  | 218/283 [00:52<00:17,  3.81it/s][A
 77%|███████▋  | 219/283 [00:53<00:16,  3.82it/s][A
 78%|███████▊  | 220/283 [00:53<00:18,  3.42it/s][A
 78%|███████▊  | 221/283 [00:53<00:19,  3.12it/s][A
 78%|███████▊  | 222/283 [00:54<00:17,  3.56it/s][A
 79%|███████▉  | 223/283 [00:54<00:13,  4.30it/s][A
 79%|███████▉  | 224/283 [00:54<00:14,  4.17it/s][A
 80%|███████▉  | 225/283 [00:54<00:18,  3.17it/s][A
 80%|███████▉  | 226/283 [00:55<00:16,  3.40it/s][A
 80%|████████  | 227/283 [00:55<00:14,  3.93it/s][A
 81%|████████  | 228/283 [00:55<00:12,  4.39it/s][A
 81%|████████  | 229/283 [00:55<00:12,  4.26it/s][A
 81%|████████▏ | 230/283 [00:55<00:12,  4.24it/s][A
 82%|████████▏ | 231/283 [00:56<00:10,  4.89it/s][A
 82%|████████▏ | 232/283 [00:56<00:10,  4.73it/s][A
 82%|████████▏ | 233/283 [00:56<00:13,  3.83it/s][A
 83%|████████▎ | 234/283 [00:56<00:11,  4.28it/s][A
 83%|████████▎ | 235/283 [00:57<00:12,  3.99it/s][A
 83%|████████▎ | 236/283 [00:57<00:13,  3.49it/s][A
 84%|████████▎ | 237/283 [00:57<00:12,  3.72it/s][A
 84%|████████▍ | 238/283 [00:58<00:13,  3.34it/s][A
 84%|████████▍ | 239/283 [00:58<00:12,  3.48it/s][A
 85%|████████▍ | 240/283 [00:58<00:10,  3.99it/s][A
 85%|████████▌ | 241/283 [00:58<00:12,  3.40it/s][A
 86%|████████▌ | 242/283 [00:59<00:10,  3.99it/s][A
 86%|████████▌ | 243/283 [00:59<00:09,  4.11it/s][A
 87%|████████▋ | 245/283 [00:59<00:09,  3.96it/s][A
 87%|████████▋ | 246/283 [01:00<00:09,  3.97it/s][A
 87%|████████▋ | 247/283 [01:00<00:09,  3.82it/s][A
 88%|████████▊ | 249/283 [01:00<00:07,  4.52it/s][A
 88%|████████▊ | 250/283 [01:01<00:08,  3.72it/s][A
 89%|████████▊ | 251/283 [01:01<00:07,  4.15it/s][A
 89%|████████▉ | 252/283 [01:01<00:07,  3.93it/s][A
 89%|████████▉ | 253/283 [01:01<00:08,  3.72it/s][A
 90%|████████▉ | 254/283 [01:02<00:06,  4.31it/s][A
 90%|█████████ | 255/283 [01:02<00:08,  3.40it/s][A
 90%|█████████ | 256/283 [01:02<00:07,  3.72it/s][A
 91%|█████████ | 257/283 [01:02<00:07,  3.53it/s][A
 91%|█████████ | 258/283 [01:03<00:06,  4.14it/s][A
 92%|█████████▏| 259/283 [01:03<00:05,  4.72it/s][A
 92%|█████████▏| 260/283 [01:03<00:05,  4.57it/s][A
 93%|█████████▎| 262/283 [01:04<00:04,  4.33it/s][A
 93%|█████████▎| 263/283 [01:04<00:03,  5.03it/s][A
 93%|█████████▎| 264/283 [01:04<00:04,  4.73it/s][A
 94%|█████████▎| 265/283 [01:04<00:03,  4.94it/s][A
 94%|█████████▍| 266/283 [01:04<00:03,  5.51it/s][A
 94%|█████████▍| 267/283 [01:04<00:03,  4.65it/s][A
 95%|█████████▍| 268/283 [01:05<00:03,  4.74it/s][A
 95%|█████████▌| 269/283 [01:05<00:03,  4.41it/s][A
 95%|█████████▌| 270/283 [01:05<00:02,  4.41it/s][A
 96%|█████████▌| 271/283 [01:05<00:02,  4.99it/s][A
 96%|█████████▌| 272/283 [01:06<00:02,  4.13it/s][A
 96%|█████████▋| 273/283 [01:06<00:02,  3.36it/s][A
 97%|█████████▋| 274/283 [01:06<00:02,  3.26it/s][A
 98%|█████████▊| 276/283 [01:07<00:01,  4.11it/s][A
 98%|█████████▊| 277/283 [01:07<00:01,  4.55it/s][A
 98%|█████████▊| 278/283 [01:07<00:01,  4.40it/s][A
 99%|█████████▊| 279/283 [01:07<00:00,  4.25it/s][A
 99%|█████████▉| 280/283 [01:08<00:00,  4.25it/s][A
 99%|█████████▉| 281/283 [01:08<00:00,  4.21it/s][A
100%|█████████▉| 282/283 [01:08<00:00,  4.87it/s][A
100%|██████████| 283/283 [01:08<00:00,  4.33it/s][A                                                   
                                                 [A{'eval_loss': 3.0170681476593018, 'eval_runtime': 69.8781, 'eval_samples_per_second': 16.171, 'eval_steps_per_second': 4.05, 'eval_rewards/chosen': -7.75, 'eval_rewards/rejected': -7.9375, 'eval_rewards/accuracies': 0.5088339447975159, 'eval_rewards/margins': 0.1923828125, 'epoch': 0.23}
 23%|██▎       | 100/432 [50:22<2:37:30, 28.47s/it]
100%|██████████| 283/283 [01:09<00:00,  4.33it/s][A
                                                 [A[INFO|trainer.py:3966] 2025-03-28 14:32:46,069 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo/checkpoint-100
[INFO|configuration_utils.py:423] 2025-03-28 14:32:46,077 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-100/config.json
[INFO|configuration_utils.py:908] 2025-03-28 14:32:46,082 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-100/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 14:32:52,503 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/checkpoint-100/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 14:32:52,511 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 14:32:52,515 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/checkpoint-100/special_tokens_map.json
[2025-03-28 14:32:53,174] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[2025-03-28 14:32:53,186] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/mp_rank_00_model_states.pt
[2025-03-28 14:32:53,187] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/mp_rank_00_model_states.pt...
[2025-03-28 14:32:58,763] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/mp_rank_00_model_states.pt.
[2025-03-28 14:32:58,765] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-28 14:33:15,921] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-28 14:33:15,934] [INFO] [engine.py:3645:_save_zero_checkpoint] zero checkpoint saved outputs/gemma-2-2b-it-simpo/checkpoint-100/global_step100/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-28 14:33:15,935] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
 23%|██▎       | 101/432 [51:23<5:26:45, 59.23s/it] 24%|██▎       | 102/432 [51:53<4:37:32, 50.46s/it] 24%|██▍       | 103/432 [52:23<4:03:48, 44.46s/it] 24%|██▍       | 104/432 [52:53<3:39:56, 40.23s/it] 24%|██▍       | 105/432 [53:24<3:23:06, 37.27s/it]                                                   {'loss': 3.0676, 'grad_norm': 102.6648178100586, 'learning_rate': 7.521943534704442e-07, 'rewards/chosen': -7.875, 'rewards/rejected': -8.125, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.2275390625, 'epoch': 0.24}
 24%|██▍       | 105/432 [53:24<3:23:06, 37.27s/it] 25%|██▍       | 106/432 [53:52<3:07:29, 34.51s/it] 25%|██▍       | 107/432 [54:21<2:58:39, 32.98s/it] 25%|██▌       | 108/432 [54:50<2:50:35, 31.59s/it] 25%|██▌       | 109/432 [55:15<2:40:10, 29.75s/it] 25%|██▌       | 110/432 [55:45<2:39:11, 29.66s/it]                                                   {'loss': 3.08, 'grad_norm': 34.77695083618164, 'learning_rate': 7.442308463215701e-07, 'rewards/chosen': -7.9375, 'rewards/rejected': -8.0, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.08544921875, 'epoch': 0.25}
 25%|██▌       | 110/432 [55:45<2:39:11, 29.66s/it] 26%|██▌       | 111/432 [56:14<2:38:05, 29.55s/it] 26%|██▌       | 112/432 [56:40<2:32:49, 28.66s/it] 26%|██▌       | 113/432 [57:12<2:37:39, 29.65s/it] 26%|██▋       | 114/432 [57:42<2:36:39, 29.56s/it] 27%|██▋       | 115/432 [58:11<2:36:24, 29.60s/it]                                                   {'loss': 3.1079, 'grad_norm': 77.12818145751953, 'learning_rate': 7.357032253134969e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -8.1875, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 0.177734375, 'epoch': 0.27}
 27%|██▋       | 115/432 [58:11<2:36:24, 29.60s/it] 27%|██▋       | 116/432 [58:40<2:34:18, 29.30s/it] 27%|██▋       | 117/432 [59:10<2:34:11, 29.37s/it] 27%|██▋       | 118/432 [59:39<2:33:57, 29.42s/it] 28%|██▊       | 119/432 [1:00:08<2:31:59, 29.14s/it] 28%|██▊       | 120/432 [1:00:39<2:34:53, 29.79s/it]                                                     {'loss': 3.0469, 'grad_norm': 27.836809158325195, 'learning_rate': 7.266254652228843e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -8.25, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.2373046875, 'epoch': 0.28}
 28%|██▊       | 120/432 [1:00:39<2:34:53, 29.79s/it] 28%|██▊       | 121/432 [1:01:09<2:35:02, 29.91s/it] 28%|██▊       | 122/432 [1:01:36<2:30:36, 29.15s/it] 28%|██▊       | 123/432 [1:02:05<2:29:04, 28.95s/it] 29%|██▊       | 124/432 [1:02:32<2:25:01, 28.25s/it] 29%|██▉       | 125/432 [1:03:02<2:27:15, 28.78s/it]                                                     {'loss': 3.0785, 'grad_norm': 39.312992095947266, 'learning_rate': 7.170124423756988e-07, 'rewards/chosen': -8.0625, 'rewards/rejected': -8.375, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.326171875, 'epoch': 0.29}
 29%|██▉       | 125/432 [1:03:02<2:27:15, 28.78s/it] 29%|██▉       | 126/432 [1:03:31<2:28:14, 29.07s/it] 29%|██▉       | 127/432 [1:03:58<2:23:46, 28.28s/it] 30%|██▉       | 128/432 [1:04:30<2:29:22, 29.48s/it] 30%|██▉       | 129/432 [1:04:58<2:26:23, 28.99s/it] 30%|███       | 130/432 [1:05:26<2:25:01, 28.81s/it]                                                     {'loss': 3.0289, 'grad_norm': 38.255672454833984, 'learning_rate': 7.068799102683944e-07, 'rewards/chosen': -7.90625, 'rewards/rejected': -8.1875, 'rewards/accuracies': 0.546875, 'rewards/margins': 0.294921875, 'epoch': 0.3}
 30%|███       | 130/432 [1:05:26<2:25:01, 28.81s/it] 30%|███       | 131/432 [1:05:53<2:21:29, 28.20s/it] 31%|███       | 132/432 [1:06:23<2:23:05, 28.62s/it] 31%|███       | 133/432 [1:06:54<2:26:53, 29.48s/it] 31%|███       | 134/432 [1:07:25<2:28:36, 29.92s/it] 31%|███▏      | 135/432 [1:07:54<2:26:09, 29.53s/it]                                                     {'loss': 2.9599, 'grad_norm': 30.964069366455078, 'learning_rate': 6.962444737516159e-07, 'rewards/chosen': -8.0625, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 0.392578125, 'epoch': 0.31}
 31%|███▏      | 135/432 [1:07:54<2:26:09, 29.53s/it] 31%|███▏      | 136/432 [1:08:23<2:25:35, 29.51s/it] 32%|███▏      | 137/432 [1:08:55<2:28:24, 30.19s/it] 32%|███▏      | 138/432 [1:09:22<2:23:51, 29.36s/it] 32%|███▏      | 139/432 [1:09:53<2:25:29, 29.79s/it] 32%|███▏      | 140/432 [1:10:21<2:21:54, 29.16s/it]                                                     {'loss': 2.9991, 'grad_norm': 30.91008186340332, 'learning_rate': 6.851235618187317e-07, 'rewards/chosen': -8.4375, 'rewards/rejected': -9.0625, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.59375, 'epoch': 0.32}
 32%|███▏      | 140/432 [1:10:21<2:21:54, 29.16s/it] 33%|███▎      | 141/432 [1:10:51<2:23:15, 29.54s/it] 33%|███▎      | 142/432 [1:11:21<2:22:25, 29.47s/it] 33%|███▎      | 143/432 [1:11:49<2:20:45, 29.22s/it] 33%|███▎      | 144/432 [1:12:18<2:19:14, 29.01s/it] 34%|███▎      | 145/432 [1:12:51<2:24:31, 30.21s/it]                                                     {'loss': 3.1263, 'grad_norm': 29.821975708007812, 'learning_rate': 6.735353990437895e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.33984375, 'epoch': 0.34}
 34%|███▎      | 145/432 [1:12:51<2:24:31, 30.21s/it] 34%|███▍      | 146/432 [1:13:23<2:27:33, 30.96s/it] 34%|███▍      | 147/432 [1:13:56<2:29:36, 31.49s/it] 34%|███▍      | 148/432 [1:14:25<2:25:00, 30.64s/it] 34%|███▍      | 149/432 [1:14:57<2:26:30, 31.06s/it] 35%|███▍      | 150/432 [1:15:26<2:22:34, 30.34s/it]                                                     {'loss': 3.0507, 'grad_norm': 26.549251556396484, 'learning_rate': 6.61498975715701e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.19140625, 'epoch': 0.35}
 35%|███▍      | 150/432 [1:15:26<2:22:34, 30.34s/it] 35%|███▍      | 151/432 [1:15:54<2:19:13, 29.73s/it] 35%|███▌      | 152/432 [1:16:24<2:19:26, 29.88s/it] 35%|███▌      | 153/432 [1:16:53<2:17:22, 29.54s/it] 36%|███▌      | 154/432 [1:17:25<2:20:32, 30.33s/it] 36%|███▌      | 155/432 [1:17:55<2:20:07, 30.35s/it]                                                     {'loss': 2.9706, 'grad_norm': 35.218135833740234, 'learning_rate': 6.490340167175995e-07, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 0.271484375, 'epoch': 0.36}
 36%|███▌      | 155/432 [1:17:55<2:20:07, 30.35s/it] 36%|███▌      | 156/432 [1:18:23<2:15:40, 29.49s/it] 36%|███▋      | 157/432 [1:18:52<2:14:01, 29.24s/it] 37%|███▋      | 158/432 [1:19:23<2:16:05, 29.80s/it] 37%|███▋      | 159/432 [1:19:53<2:15:53, 29.87s/it] 37%|███▋      | 160/432 [1:20:18<2:09:44, 28.62s/it]                                                     {'loss': 3.0437, 'grad_norm': 37.307674407958984, 'learning_rate': 6.36160949202369e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.375, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.142578125, 'epoch': 0.37}
 37%|███▋      | 160/432 [1:20:18<2:09:44, 28.62s/it] 37%|███▋      | 161/432 [1:20:48<2:10:38, 28.92s/it] 38%|███▊      | 162/432 [1:21:16<2:09:26, 28.77s/it] 38%|███▊      | 163/432 [1:21:42<2:04:47, 27.84s/it] 38%|███▊      | 164/432 [1:22:09<2:03:16, 27.60s/it] 38%|███▊      | 165/432 [1:22:38<2:04:30, 27.98s/it]                                                     {'loss': 3.0761, 'grad_norm': 37.394954681396484, 'learning_rate': 6.229008691173174e-07, 'rewards/chosen': -8.5625, 'rewards/rejected': -9.0, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 0.400390625, 'epoch': 0.38}
 38%|███▊      | 165/432 [1:22:38<2:04:30, 27.98s/it] 38%|███▊      | 166/432 [1:23:07<2:05:44, 28.36s/it] 39%|███▊      | 167/432 [1:23:35<2:04:20, 28.15s/it] 39%|███▉      | 168/432 [1:24:02<2:02:17, 27.79s/it] 39%|███▉      | 169/432 [1:24:32<2:05:15, 28.58s/it] 39%|███▉      | 170/432 [1:25:03<2:07:03, 29.10s/it]                                                     {'loss': 3.0333, 'grad_norm': 56.12724304199219, 'learning_rate': 6.09275506632852e-07, 'rewards/chosen': -8.1875, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.551562488079071, 'rewards/margins': 0.271484375, 'epoch': 0.39}
 39%|███▉      | 170/432 [1:25:03<2:07:03, 29.10s/it] 40%|███▉      | 171/432 [1:25:30<2:04:35, 28.64s/it] 40%|███▉      | 172/432 [1:25:59<2:03:48, 28.57s/it] 40%|████      | 173/432 [1:26:26<2:01:24, 28.13s/it] 40%|████      | 174/432 [1:26:56<2:03:50, 28.80s/it] 41%|████      | 175/432 [1:27:25<2:03:51, 28.91s/it]                                                     {'loss': 2.9615, 'grad_norm': 35.607887268066406, 'learning_rate': 5.953071905318121e-07, 'rewards/chosen': -8.0, 'rewards/rejected': -8.3125, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.328125, 'epoch': 0.4}
 41%|████      | 175/432 [1:27:25<2:03:51, 28.91s/it] 41%|████      | 176/432 [1:27:52<2:01:02, 28.37s/it] 41%|████      | 177/432 [1:28:21<2:00:33, 28.37s/it] 41%|████      | 178/432 [1:28:50<2:01:21, 28.67s/it] 41%|████▏     | 179/432 [1:29:21<2:03:48, 29.36s/it] 42%|████▏     | 180/432 [1:29:53<2:06:11, 30.05s/it]                                                     {'loss': 3.0034, 'grad_norm': 40.26563262939453, 'learning_rate': 5.810188116178155e-07, 'rewards/chosen': -8.125, 'rewards/rejected': -8.3125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.185546875, 'epoch': 0.42}
 42%|████▏     | 180/432 [1:29:53<2:06:11, 30.05s/it] 42%|████▏     | 181/432 [1:30:21<2:03:17, 29.47s/it] 42%|████▏     | 182/432 [1:30:52<2:04:31, 29.89s/it] 42%|████▏     | 183/432 [1:31:21<2:03:48, 29.83s/it] 43%|████▎     | 184/432 [1:31:52<2:04:07, 30.03s/it] 43%|████▎     | 185/432 [1:32:24<2:06:44, 30.79s/it]                                                     {'loss': 2.8947, 'grad_norm': 30.99555778503418, 'learning_rate': 5.664337852025837e-07, 'rewards/chosen': -8.0625, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.515625, 'epoch': 0.43}
 43%|████▎     | 185/432 [1:32:24<2:06:44, 30.79s/it] 43%|████▎     | 186/432 [1:32:53<2:03:15, 30.06s/it] 43%|████▎     | 187/432 [1:33:24<2:04:02, 30.38s/it] 44%|████▎     | 188/432 [1:33:51<1:59:34, 29.41s/it] 44%|████▍     | 189/432 [1:34:20<1:58:00, 29.14s/it] 44%|████▍     | 190/432 [1:34:50<1:59:13, 29.56s/it]                                                     {'loss': 2.9491, 'grad_norm': 24.453248977661133, 'learning_rate': 5.515760127337227e-07, 'rewards/chosen': -8.125, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 0.34375, 'epoch': 0.44}
 44%|████▍     | 190/432 [1:34:50<1:59:13, 29.56s/it] 44%|████▍     | 191/432 [1:35:20<1:58:38, 29.54s/it] 44%|████▍     | 192/432 [1:35:50<1:59:42, 29.93s/it] 45%|████▍     | 193/432 [1:36:21<1:59:24, 29.98s/it] 45%|████▍     | 194/432 [1:36:50<1:58:13, 29.80s/it] 45%|████▌     | 195/432 [1:37:21<1:59:15, 30.19s/it]                                                     {'loss': 3.0406, 'grad_norm': 38.320220947265625, 'learning_rate': 5.364698426258384e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 0.3046875, 'epoch': 0.45}
 45%|████▌     | 195/432 [1:37:21<1:59:15, 30.19s/it] 45%|████▌     | 196/432 [1:37:54<2:01:45, 30.95s/it] 46%|████▌     | 197/432 [1:38:22<1:57:54, 30.11s/it] 46%|████▌     | 198/432 [1:38:50<1:54:38, 29.40s/it] 46%|████▌     | 199/432 [1:39:19<1:54:42, 29.54s/it] 46%|████▋     | 200/432 [1:39:50<1:55:27, 29.86s/it]                                                     {'loss': 2.9912, 'grad_norm': 25.736068725585938, 'learning_rate': 5.211400303591802e-07, 'rewards/chosen': -8.1875, 'rewards/rejected': -8.25, 'rewards/accuracies': 0.4781250059604645, 'rewards/margins': 0.07568359375, 'epoch': 0.46}
 46%|████▋     | 200/432 [1:39:50<1:55:27, 29.86s/it][INFO|trainer.py:4289] 2025-03-28 15:22:11,912 >> 
***** Running Evaluation *****
[INFO|trainer.py:4291] 2025-03-28 15:22:11,912 >>   Num examples = 1130
[INFO|trainer.py:4294] 2025-03-28 15:22:11,912 >>   Batch size = 2

  0%|          | 0/283 [00:00<?, ?it/s][A
  1%|          | 2/283 [00:00<00:45,  6.18it/s][A
  1%|          | 3/283 [00:00<00:48,  5.72it/s][A
  1%|▏         | 4/283 [00:00<00:55,  4.99it/s][A
  2%|▏         | 5/283 [00:00<00:53,  5.21it/s][A
  2%|▏         | 6/283 [00:01<00:51,  5.42it/s][A
  2%|▏         | 7/283 [00:01<00:44,  6.26it/s][A
  3%|▎         | 8/283 [00:01<01:00,  4.52it/s][A
  3%|▎         | 9/283 [00:01<00:58,  4.68it/s][A
  4%|▎         | 10/283 [00:02<01:07,  4.05it/s][A
  4%|▍         | 11/283 [00:02<01:05,  4.15it/s][A
  5%|▍         | 13/283 [00:02<00:55,  4.85it/s][A
  5%|▍         | 14/283 [00:02<00:55,  4.82it/s][A
  5%|▌         | 15/283 [00:03<00:56,  4.70it/s][A
  6%|▌         | 16/283 [00:03<00:51,  5.15it/s][A
  6%|▌         | 17/283 [00:03<00:58,  4.54it/s][A
  6%|▋         | 18/283 [00:03<00:57,  4.64it/s][A
  7%|▋         | 19/283 [00:03<00:50,  5.27it/s][A
  7%|▋         | 20/283 [00:04<00:50,  5.24it/s][A
  7%|▋         | 21/283 [00:04<01:00,  4.33it/s][A
  8%|▊         | 22/283 [00:04<01:14,  3.50it/s][A
  8%|▊         | 23/283 [00:05<01:12,  3.56it/s][A
  8%|▊         | 24/283 [00:05<01:12,  3.55it/s][A
  9%|▉         | 25/283 [00:05<01:02,  4.10it/s][A
  9%|▉         | 26/283 [00:05<01:18,  3.26it/s][A
 10%|▉         | 27/283 [00:06<01:31,  2.81it/s][A
 10%|▉         | 28/283 [00:06<01:11,  3.55it/s][A
 10%|█         | 29/283 [00:06<01:11,  3.57it/s][A
 11%|█         | 30/283 [00:07<01:10,  3.57it/s][A
 11%|█         | 31/283 [00:07<01:09,  3.62it/s][A
 11%|█▏        | 32/283 [00:07<00:58,  4.28it/s][A
 12%|█▏        | 33/283 [00:07<01:00,  4.15it/s][A
 12%|█▏        | 34/283 [00:07<00:58,  4.26it/s][A
 12%|█▏        | 35/283 [00:08<00:52,  4.76it/s][A
 13%|█▎        | 36/283 [00:08<01:06,  3.72it/s][A
 13%|█▎        | 37/283 [00:08<01:05,  3.75it/s][A
 13%|█▎        | 38/283 [00:08<00:56,  4.37it/s][A
 14%|█▍        | 39/283 [00:09<01:05,  3.75it/s][A
 14%|█▍        | 40/283 [00:09<01:10,  3.46it/s][A
 14%|█▍        | 41/283 [00:09<01:00,  3.97it/s][A
 15%|█▍        | 42/283 [00:09<00:57,  4.20it/s][A
 15%|█▌        | 43/283 [00:10<00:56,  4.23it/s][A
 16%|█▌        | 44/283 [00:10<00:49,  4.80it/s][A
 16%|█▋        | 46/283 [00:10<00:41,  5.66it/s][A
 17%|█▋        | 47/283 [00:10<00:43,  5.45it/s][A
 17%|█▋        | 48/283 [00:11<00:53,  4.42it/s][A
 17%|█▋        | 49/283 [00:11<00:46,  4.99it/s][A
 18%|█▊        | 50/283 [00:11<00:46,  5.00it/s][A
 18%|█▊        | 51/283 [00:11<00:55,  4.14it/s][A
 18%|█▊        | 52/283 [00:12<00:57,  4.01it/s][A
 19%|█▊        | 53/283 [00:12<00:57,  4.00it/s][A
 19%|█▉        | 54/283 [00:12<00:57,  3.96it/s][A
 20%|█▉        | 56/283 [00:13<01:02,  3.64it/s][A
 20%|██        | 57/283 [00:13<01:03,  3.57it/s][A
 20%|██        | 58/283 [00:13<01:07,  3.33it/s][A
 21%|██        | 59/283 [00:14<01:05,  3.45it/s][A
 21%|██        | 60/283 [00:14<00:58,  3.80it/s][A
 22%|██▏       | 61/283 [00:14<00:52,  4.21it/s][A
 22%|██▏       | 62/283 [00:14<00:53,  4.16it/s][A
 22%|██▏       | 63/283 [00:14<00:49,  4.45it/s][A
 23%|██▎       | 64/283 [00:15<00:48,  4.48it/s][A
 23%|██▎       | 65/283 [00:15<00:50,  4.30it/s][A
 23%|██▎       | 66/283 [00:15<00:47,  4.58it/s][A
 24%|██▎       | 67/283 [00:15<00:52,  4.08it/s][A
 24%|██▍       | 68/283 [00:16<00:54,  3.94it/s][A
 24%|██▍       | 69/283 [00:16<00:46,  4.63it/s][A
 25%|██▍       | 70/283 [00:16<00:54,  3.91it/s][A
 25%|██▌       | 71/283 [00:16<00:48,  4.39it/s][A
 25%|██▌       | 72/283 [00:17<00:44,  4.72it/s][A
 26%|██▌       | 73/283 [00:17<00:52,  3.99it/s][A
 26%|██▌       | 74/283 [00:17<00:46,  4.49it/s][A
 27%|██▋       | 75/283 [00:17<00:57,  3.64it/s][A
 27%|██▋       | 76/283 [00:18<00:51,  4.00it/s][A
 27%|██▋       | 77/283 [00:18<00:47,  4.31it/s][A
 28%|██▊       | 78/283 [00:18<00:41,  4.89it/s][A
 28%|██▊       | 79/283 [00:18<00:38,  5.28it/s][A
 28%|██▊       | 80/283 [00:18<00:39,  5.17it/s][A
 29%|██▉       | 82/283 [00:19<00:38,  5.18it/s][A
 30%|██▉       | 84/283 [00:19<00:32,  6.20it/s][A
 30%|███       | 85/283 [00:19<00:29,  6.68it/s][A
 30%|███       | 86/283 [00:19<00:27,  7.22it/s][A
 31%|███       | 87/283 [00:19<00:33,  5.89it/s][A
 31%|███       | 88/283 [00:20<00:35,  5.43it/s][A
 31%|███▏      | 89/283 [00:20<00:36,  5.34it/s][A
 32%|███▏      | 90/283 [00:20<00:41,  4.64it/s][A
 32%|███▏      | 91/283 [00:20<00:35,  5.48it/s][A
 33%|███▎      | 92/283 [00:20<00:39,  4.84it/s][A
 33%|███▎      | 93/283 [00:21<00:46,  4.11it/s][A
 33%|███▎      | 94/283 [00:21<00:41,  4.57it/s][A
 34%|███▎      | 95/283 [00:21<00:44,  4.26it/s][A
 34%|███▍      | 96/283 [00:21<00:37,  4.94it/s][A
 34%|███▍      | 97/283 [00:22<00:47,  3.88it/s][A
 35%|███▍      | 99/283 [00:22<00:48,  3.80it/s][A
 35%|███▌      | 100/283 [00:23<00:47,  3.87it/s][A
 36%|███▌      | 101/283 [00:23<00:45,  4.03it/s][A
 36%|███▌      | 102/283 [00:23<00:55,  3.25it/s][A
 36%|███▋      | 103/283 [00:23<00:53,  3.34it/s][A
 37%|███▋      | 104/283 [00:24<00:52,  3.42it/s][A
 37%|███▋      | 105/283 [00:24<00:45,  3.94it/s][A
 37%|███▋      | 106/283 [00:24<00:38,  4.55it/s][A
 38%|███▊      | 107/283 [00:24<00:41,  4.20it/s][A
 38%|███▊      | 108/283 [00:25<00:38,  4.55it/s][A
 39%|███▊      | 109/283 [00:25<00:41,  4.19it/s][A
 39%|███▉      | 110/283 [00:25<00:45,  3.82it/s][A
 39%|███▉      | 111/283 [00:25<00:41,  4.10it/s][A
 40%|███▉      | 112/283 [00:25<00:36,  4.64it/s][A
 40%|███▉      | 113/283 [00:26<00:44,  3.85it/s][A
 40%|████      | 114/283 [00:26<00:46,  3.63it/s][A
 41%|████      | 115/283 [00:27<00:53,  3.15it/s][A
 41%|████      | 116/283 [00:27<00:46,  3.58it/s][A
 41%|████▏     | 117/283 [00:27<00:42,  3.93it/s][A
 42%|████▏     | 118/283 [00:27<00:36,  4.57it/s][A
 42%|████▏     | 119/283 [00:27<00:36,  4.46it/s][A
 42%|████▏     | 120/283 [00:27<00:33,  4.89it/s][A
 43%|████▎     | 121/283 [00:28<00:30,  5.29it/s][A
 43%|████▎     | 123/283 [00:28<00:25,  6.35it/s][A
 44%|████▍     | 124/283 [00:28<00:33,  4.69it/s][A
 44%|████▍     | 125/283 [00:29<00:35,  4.43it/s][A
 45%|████▍     | 126/283 [00:29<00:41,  3.80it/s][A
 45%|████▍     | 127/283 [00:29<00:41,  3.79it/s][A
 45%|████▌     | 128/283 [00:29<00:40,  3.81it/s][A
 46%|████▌     | 130/283 [00:30<00:31,  4.84it/s][A
 46%|████▋     | 131/283 [00:30<00:34,  4.35it/s][A
 47%|████▋     | 132/283 [00:30<00:32,  4.70it/s][A
 47%|████▋     | 133/283 [00:30<00:32,  4.58it/s][A
 47%|████▋     | 134/283 [00:31<00:37,  3.94it/s][A
 48%|████▊     | 135/283 [00:31<00:35,  4.20it/s][A
 48%|████▊     | 136/283 [00:31<00:33,  4.35it/s][A
 48%|████▊     | 137/283 [00:31<00:35,  4.16it/s][A
 49%|████▉     | 138/283 [00:32<00:39,  3.70it/s][A
 49%|████▉     | 139/283 [00:32<00:40,  3.52it/s][A
 49%|████▉     | 140/283 [00:32<00:36,  3.88it/s][A
 50%|████▉     | 141/283 [00:33<00:38,  3.67it/s][A
 50%|█████     | 142/283 [00:33<00:34,  4.05it/s][A
 51%|█████     | 143/283 [00:33<00:31,  4.44it/s][A
 51%|█████     | 144/283 [00:33<00:42,  3.29it/s][A
 51%|█████     | 145/283 [00:34<00:37,  3.67it/s][A
 52%|█████▏    | 146/283 [00:34<00:32,  4.28it/s][A
 52%|█████▏    | 147/283 [00:34<00:36,  3.73it/s][A
 52%|█████▏    | 148/283 [00:34<00:34,  3.87it/s][A
 53%|█████▎    | 149/283 [00:35<00:36,  3.71it/s][A
 53%|█████▎    | 150/283 [00:35<00:36,  3.61it/s][A
 53%|█████▎    | 151/283 [00:35<00:37,  3.50it/s][A
 54%|█████▎    | 152/283 [00:36<00:46,  2.81it/s][A
 54%|█████▍    | 153/283 [00:36<00:49,  2.63it/s][A
 54%|█████▍    | 154/283 [00:36<00:38,  3.33it/s][A
 55%|█████▍    | 155/283 [00:37<00:35,  3.61it/s][A
 55%|█████▌    | 156/283 [00:37<00:34,  3.70it/s][A
 55%|█████▌    | 157/283 [00:37<00:30,  4.20it/s][A
 56%|█████▌    | 158/283 [00:37<00:33,  3.76it/s][A
 56%|█████▌    | 159/283 [00:37<00:29,  4.14it/s][A
 57%|█████▋    | 160/283 [00:38<00:29,  4.21it/s][A
 57%|█████▋    | 161/283 [00:38<00:33,  3.68it/s][A
 57%|█████▋    | 162/283 [00:38<00:33,  3.66it/s][A
 58%|█████▊    | 163/283 [00:38<00:29,  4.06it/s][A
 58%|█████▊    | 164/283 [00:39<00:38,  3.12it/s][A
 58%|█████▊    | 165/283 [00:39<00:34,  3.39it/s][A
 59%|█████▊    | 166/283 [00:39<00:31,  3.76it/s][A
 59%|█████▉    | 167/283 [00:40<00:25,  4.49it/s][A
 59%|█████▉    | 168/283 [00:40<00:31,  3.66it/s][A
 60%|█████▉    | 169/283 [00:40<00:30,  3.68it/s][A
 60%|██████    | 170/283 [00:40<00:28,  4.02it/s][A
 60%|██████    | 171/283 [00:41<00:24,  4.64it/s][A
 61%|██████    | 172/283 [00:41<00:29,  3.77it/s][A
 61%|██████    | 173/283 [00:41<00:25,  4.31it/s][A
 62%|██████▏   | 175/283 [00:42<00:27,  3.96it/s][A
 62%|██████▏   | 176/283 [00:42<00:32,  3.34it/s][A
 63%|██████▎   | 177/283 [00:42<00:27,  3.88it/s][A
 63%|██████▎   | 179/283 [00:43<00:28,  3.63it/s][A
 64%|██████▎   | 180/283 [00:43<00:29,  3.49it/s][A
 64%|██████▍   | 181/283 [00:43<00:31,  3.25it/s][A
 64%|██████▍   | 182/283 [00:44<00:27,  3.64it/s][A
 65%|██████▍   | 183/283 [00:44<00:25,  3.96it/s][A
 65%|██████▌   | 184/283 [00:44<00:21,  4.63it/s][A
 65%|██████▌   | 185/283 [00:44<00:19,  5.15it/s][A
 66%|██████▌   | 186/283 [00:44<00:20,  4.63it/s][A
 66%|██████▌   | 187/283 [00:45<00:20,  4.79it/s][A
 66%|██████▋   | 188/283 [00:45<00:24,  3.82it/s][A
 67%|██████▋   | 189/283 [00:45<00:22,  4.14it/s][A
 67%|██████▋   | 190/283 [00:45<00:23,  3.93it/s][A
 67%|██████▋   | 191/283 [00:46<00:20,  4.56it/s][A
 68%|██████▊   | 192/283 [00:46<00:18,  4.83it/s][A
 68%|██████▊   | 193/283 [00:46<00:21,  4.20it/s][A
 69%|██████▊   | 194/283 [00:46<00:19,  4.67it/s][A
 69%|██████▉   | 195/283 [00:46<00:18,  4.75it/s][A
 69%|██████▉   | 196/283 [00:47<00:17,  5.09it/s][A
 70%|██████▉   | 197/283 [00:47<00:23,  3.69it/s][A
 70%|██████▉   | 198/283 [00:47<00:23,  3.58it/s][A
 70%|███████   | 199/283 [00:48<00:27,  3.00it/s][A
 71%|███████   | 200/283 [00:48<00:22,  3.62it/s][A
 71%|███████   | 201/283 [00:48<00:21,  3.76it/s][A
 71%|███████▏  | 202/283 [00:48<00:19,  4.05it/s][A
 72%|███████▏  | 203/283 [00:49<00:18,  4.41it/s][A
 72%|███████▏  | 204/283 [00:49<00:20,  3.88it/s][A
 72%|███████▏  | 205/283 [00:49<00:22,  3.52it/s][A
 73%|███████▎  | 206/283 [00:50<00:23,  3.29it/s][A
 73%|███████▎  | 207/283 [00:50<00:20,  3.79it/s][A
 73%|███████▎  | 208/283 [00:50<00:20,  3.62it/s][A
 74%|███████▍  | 209/283 [00:50<00:20,  3.55it/s][A
 74%|███████▍  | 210/283 [00:51<00:17,  4.24it/s][A
 75%|███████▍  | 211/283 [00:51<00:16,  4.27it/s][A
 75%|███████▍  | 212/283 [00:51<00:14,  4.86it/s][A
 75%|███████▌  | 213/283 [00:51<00:16,  4.28it/s][A
 76%|███████▌  | 214/283 [00:51<00:13,  5.09it/s][A
 76%|███████▌  | 215/283 [00:51<00:13,  5.03it/s][A
 76%|███████▋  | 216/283 [00:52<00:14,  4.49it/s][A
 77%|███████▋  | 217/283 [00:52<00:18,  3.63it/s][A
 77%|███████▋  | 218/283 [00:52<00:17,  3.80it/s][A
 77%|███████▋  | 219/283 [00:53<00:16,  3.82it/s][A
 78%|███████▊  | 220/283 [00:53<00:18,  3.42it/s][A
 78%|███████▊  | 221/283 [00:53<00:19,  3.11it/s][A
 78%|███████▊  | 222/283 [00:54<00:17,  3.55it/s][A
 79%|███████▉  | 223/283 [00:54<00:13,  4.29it/s][A
 79%|███████▉  | 224/283 [00:54<00:14,  4.16it/s][A
 80%|███████▉  | 225/283 [00:54<00:18,  3.16it/s][A
 80%|███████▉  | 226/283 [00:55<00:16,  3.39it/s][A
 80%|████████  | 227/283 [00:55<00:14,  3.91it/s][A
 81%|████████  | 228/283 [00:55<00:12,  4.38it/s][A
 81%|████████  | 229/283 [00:55<00:12,  4.26it/s][A
 81%|████████▏ | 230/283 [00:56<00:12,  4.23it/s][A
 82%|████████▏ | 231/283 [00:56<00:10,  4.89it/s][A
 82%|████████▏ | 232/283 [00:56<00:10,  4.73it/s][A
 82%|████████▏ | 233/283 [00:56<00:13,  3.83it/s][A
 83%|████████▎ | 234/283 [00:56<00:11,  4.28it/s][A
 83%|████████▎ | 235/283 [00:57<00:12,  3.99it/s][A
 83%|████████▎ | 236/283 [00:57<00:13,  3.48it/s][A
 84%|████████▎ | 237/283 [00:57<00:12,  3.71it/s][A
 84%|████████▍ | 238/283 [00:58<00:13,  3.33it/s][A
 84%|████████▍ | 239/283 [00:58<00:12,  3.46it/s][A
 85%|████████▍ | 240/283 [00:58<00:10,  3.97it/s][A
 85%|████████▌ | 241/283 [00:59<00:12,  3.39it/s][A
 86%|████████▌ | 242/283 [00:59<00:10,  3.98it/s][A
 86%|████████▌ | 243/283 [00:59<00:09,  4.09it/s][A
 87%|████████▋ | 245/283 [00:59<00:09,  3.96it/s][A
 87%|████████▋ | 246/283 [01:00<00:09,  3.97it/s][A
 87%|████████▋ | 247/283 [01:00<00:09,  3.81it/s][A
 88%|████████▊ | 249/283 [01:00<00:07,  4.52it/s][A
 88%|████████▊ | 250/283 [01:01<00:08,  3.71it/s][A
 89%|████████▊ | 251/283 [01:01<00:07,  4.14it/s][A
 89%|████████▉ | 252/283 [01:01<00:07,  3.92it/s][A
 89%|████████▉ | 253/283 [01:01<00:08,  3.71it/s][A
 90%|████████▉ | 254/283 [01:02<00:06,  4.30it/s][A
 90%|█████████ | 255/283 [01:02<00:08,  3.40it/s][A
 90%|█████████ | 256/283 [01:02<00:07,  3.72it/s][A
 91%|█████████ | 257/283 [01:03<00:07,  3.53it/s][A
 91%|█████████ | 258/283 [01:03<00:06,  4.14it/s][A
 92%|█████████▏| 259/283 [01:03<00:05,  4.71it/s][A
 92%|█████████▏| 260/283 [01:03<00:05,  4.57it/s][A
 93%|█████████▎| 262/283 [01:04<00:04,  4.34it/s][A
 93%|█████████▎| 263/283 [01:04<00:03,  5.03it/s][A
 93%|█████████▎| 264/283 [01:04<00:04,  4.73it/s][A
 94%|█████████▎| 265/283 [01:04<00:03,  4.94it/s][A
 94%|█████████▍| 266/283 [01:04<00:03,  5.50it/s][A
 94%|█████████▍| 267/283 [01:05<00:03,  4.65it/s][A
 95%|█████████▍| 268/283 [01:05<00:03,  4.73it/s][A
 95%|█████████▌| 269/283 [01:05<00:03,  4.41it/s][A
 95%|█████████▌| 270/283 [01:05<00:02,  4.41it/s][A
 96%|█████████▌| 271/283 [01:05<00:02,  5.00it/s][A
 96%|█████████▌| 272/283 [01:06<00:02,  4.15it/s][A
 96%|█████████▋| 273/283 [01:06<00:02,  3.38it/s][A
 97%|█████████▋| 274/283 [01:06<00:02,  3.27it/s][A
 98%|█████████▊| 276/283 [01:07<00:01,  4.12it/s][A
 98%|█████████▊| 277/283 [01:07<00:01,  4.56it/s][A
 98%|█████████▊| 278/283 [01:07<00:01,  4.41it/s][A
 99%|█████████▊| 279/283 [01:07<00:00,  4.26it/s][A
 99%|█████████▉| 280/283 [01:08<00:00,  4.25it/s][A
 99%|█████████▉| 281/283 [01:08<00:00,  4.21it/s][A
100%|█████████▉| 282/283 [01:08<00:00,  4.87it/s][A
100%|██████████| 283/283 [01:08<00:00,  4.33it/s][A                                                     
                                                 [A{'eval_loss': 2.9562506675720215, 'eval_runtime': 69.2651, 'eval_samples_per_second': 16.314, 'eval_steps_per_second': 4.086, 'eval_rewards/chosen': -8.25, 'eval_rewards/rejected': -8.5, 'eval_rewards/accuracies': 0.5247349739074707, 'eval_rewards/margins': 0.271484375, 'epoch': 0.46}
 46%|████▋     | 200/432 [1:40:59<1:55:27, 29.86s/it]
100%|██████████| 283/283 [01:09<00:00,  4.33it/s][A
                                                 [A[INFO|trainer.py:3966] 2025-03-28 15:23:23,858 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo/checkpoint-200
[INFO|configuration_utils.py:423] 2025-03-28 15:23:23,868 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-200/config.json
[INFO|configuration_utils.py:908] 2025-03-28 15:23:23,874 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-200/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 15:23:30,552 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/checkpoint-200/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 15:23:30,557 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 15:23:30,562 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/checkpoint-200/special_tokens_map.json
[2025-03-28 15:23:31,178] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!
[2025-03-28 15:23:31,192] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/mp_rank_00_model_states.pt
[2025-03-28 15:23:31,192] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/mp_rank_00_model_states.pt...
[2025-03-28 15:23:36,628] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/mp_rank_00_model_states.pt.
[2025-03-28 15:23:36,630] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-28 15:23:53,513] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-28 15:23:53,541] [INFO] [engine.py:3645:_save_zero_checkpoint] zero checkpoint saved outputs/gemma-2-2b-it-simpo/checkpoint-200/global_step200/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-28 15:23:53,541] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!
 47%|████▋     | 201/432 [1:42:02<3:52:21, 60.35s/it] 47%|████▋     | 202/432 [1:42:34<3:18:55, 51.89s/it] 47%|████▋     | 203/432 [1:43:04<2:53:12, 45.38s/it] 47%|████▋     | 204/432 [1:43:32<2:33:03, 40.28s/it] 47%|████▋     | 205/432 [1:44:01<2:18:49, 36.69s/it]                                                     {'loss': 3.0301, 'grad_norm': 58.7804069519043, 'learning_rate': 5.056116979111972e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.1103515625, 'epoch': 0.47}
 47%|████▋     | 205/432 [1:44:01<2:18:49, 36.69s/it] 48%|████▊     | 206/432 [1:44:28<2:07:43, 33.91s/it] 48%|████▊     | 207/432 [1:44:58<2:03:13, 32.86s/it] 48%|████▊     | 208/432 [1:45:25<1:55:46, 31.01s/it] 48%|████▊     | 209/432 [1:45:58<1:57:10, 31.53s/it] 49%|████▊     | 210/432 [1:46:25<1:51:30, 30.14s/it]                                                     {'loss': 3.0303, 'grad_norm': 25.932764053344727, 'learning_rate': 4.899102925874918e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.5, 'rewards/accuracies': 0.5531250238418579, 'rewards/margins': 0.296875, 'epoch': 0.49}
 49%|████▊     | 210/432 [1:46:25<1:51:30, 30.14s/it] 49%|████▉     | 211/432 [1:46:52<1:47:44, 29.25s/it] 49%|████▉     | 212/432 [1:47:19<1:45:11, 28.69s/it] 49%|████▉     | 213/432 [1:47:50<1:46:57, 29.30s/it] 50%|████▉     | 214/432 [1:48:18<1:44:41, 28.81s/it] 50%|████▉     | 215/432 [1:48:48<1:45:17, 29.11s/it]                                                     {'loss': 2.981, 'grad_norm': 36.71040725708008, 'learning_rate': 4.740615453196368e-07, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.298828125, 'epoch': 0.5}
 50%|████▉     | 215/432 [1:48:48<1:45:17, 29.11s/it] 50%|█████     | 216/432 [1:49:18<1:45:54, 29.42s/it] 50%|█████     | 217/432 [1:49:47<1:44:58, 29.30s/it] 50%|█████     | 218/432 [1:50:15<1:43:50, 29.11s/it] 51%|█████     | 219/432 [1:50:44<1:42:20, 28.83s/it] 51%|█████     | 220/432 [1:51:12<1:41:13, 28.65s/it]                                                     {'loss': 3.0152, 'grad_norm': 43.19742965698242, 'learning_rate': 4.580914284981961e-07, 'rewards/chosen': -8.1875, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.5406249761581421, 'rewards/margins': 0.404296875, 'epoch': 0.51}
 51%|█████     | 220/432 [1:51:12<1:41:13, 28.65s/it] 51%|█████     | 221/432 [1:51:43<1:43:52, 29.54s/it] 51%|█████▏    | 222/432 [1:52:11<1:41:26, 28.99s/it] 52%|█████▏    | 223/432 [1:52:39<1:39:59, 28.70s/it] 52%|█████▏    | 224/432 [1:53:08<1:40:04, 28.87s/it] 52%|█████▏    | 225/432 [1:53:34<1:36:14, 27.89s/it]                                                     {'loss': 2.9026, 'grad_norm': 35.51205062866211, 'learning_rate': 4.420261134100496e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 0.357421875, 'epoch': 0.52}
 52%|█████▏    | 225/432 [1:53:34<1:36:14, 27.89s/it] 52%|█████▏    | 226/432 [1:54:04<1:37:29, 28.39s/it] 53%|█████▎    | 227/432 [1:54:32<1:36:57, 28.38s/it] 53%|█████▎    | 228/432 [1:55:03<1:38:46, 29.05s/it] 53%|█████▎    | 229/432 [1:55:30<1:36:59, 28.67s/it] 53%|█████▎    | 230/432 [1:56:01<1:38:59, 29.40s/it]                                                     {'loss': 2.997, 'grad_norm': 31.024158477783203, 'learning_rate': 4.2589192734977433e-07, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 0.2373046875, 'epoch': 0.53}
 53%|█████▎    | 230/432 [1:56:01<1:38:59, 29.40s/it] 53%|█████▎    | 231/432 [1:56:30<1:37:36, 29.14s/it] 54%|█████▎    | 232/432 [1:56:57<1:35:21, 28.61s/it] 54%|█████▍    | 233/432 [1:57:26<1:35:17, 28.73s/it] 54%|█████▍    | 234/432 [1:57:58<1:37:30, 29.55s/it] 54%|█████▍    | 235/432 [1:58:25<1:34:52, 28.90s/it]                                                     {'loss': 2.9986, 'grad_norm': 35.71238327026367, 'learning_rate': 4.0971531047536524e-07, 'rewards/chosen': -8.75, 'rewards/rejected': -8.875, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 0.119140625, 'epoch': 0.54}
 54%|█████▍    | 235/432 [1:58:25<1:34:52, 28.90s/it] 55%|█████▍    | 236/432 [1:58:55<1:35:00, 29.08s/it] 55%|█████▍    | 237/432 [1:59:26<1:36:45, 29.77s/it] 55%|█████▌    | 238/432 [1:59:54<1:34:30, 29.23s/it] 55%|█████▌    | 239/432 [2:00:23<1:33:56, 29.21s/it] 56%|█████▌    | 240/432 [2:00:55<1:36:07, 30.04s/it]                                                     {'loss': 2.9209, 'grad_norm': 27.128032684326172, 'learning_rate': 3.935227724789994e-07, 'rewards/chosen': -8.5625, 'rewards/rejected': -9.0, 'rewards/accuracies': 0.5546875, 'rewards/margins': 0.4375, 'epoch': 0.56}
 56%|█████▌    | 240/432 [2:00:55<1:36:07, 30.04s/it] 56%|█████▌    | 241/432 [2:01:28<1:38:08, 30.83s/it] 56%|█████▌    | 242/432 [2:01:59<1:37:43, 30.86s/it] 56%|█████▋    | 243/432 [2:02:29<1:36:10, 30.53s/it] 56%|█████▋    | 244/432 [2:02:59<1:35:47, 30.57s/it] 57%|█████▋    | 245/432 [2:03:30<1:35:27, 30.63s/it]                                                     {'loss': 2.8927, 'grad_norm': 32.92567825317383, 'learning_rate': 3.773408491438494e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.8125, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.443359375, 'epoch': 0.57}
 57%|█████▋    | 245/432 [2:03:30<1:35:27, 30.63s/it] 57%|█████▋    | 246/432 [2:04:01<1:34:55, 30.62s/it] 57%|█████▋    | 247/432 [2:04:27<1:30:37, 29.39s/it] 57%|█████▋    | 248/432 [2:05:00<1:33:33, 30.51s/it] 58%|█████▊    | 249/432 [2:05:27<1:29:45, 29.43s/it] 58%|█████▊    | 250/432 [2:05:59<1:31:24, 30.13s/it]                                                     {'loss': 3.0826, 'grad_norm': 114.36122131347656, 'learning_rate': 3.6119605885814075e-07, 'rewards/chosen': -8.625, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5390625, 'rewards/margins': 0.059326171875, 'epoch': 0.58}
 58%|█████▊    | 250/432 [2:05:59<1:31:24, 30.13s/it] 58%|█████▊    | 251/432 [2:06:28<1:29:49, 29.78s/it] 58%|█████▊    | 252/432 [2:06:57<1:28:53, 29.63s/it] 59%|█████▊    | 253/432 [2:07:28<1:29:12, 29.90s/it] 59%|█████▉    | 254/432 [2:07:56<1:27:38, 29.54s/it] 59%|█████▉    | 255/432 [2:08:27<1:28:13, 29.91s/it]                                                     {'loss': 2.8734, 'grad_norm': 29.78987693786621, 'learning_rate': 3.45114859157714e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.384765625, 'epoch': 0.59}
 59%|█████▉    | 255/432 [2:08:27<1:28:13, 29.91s/it] 59%|█████▉    | 256/432 [2:08:57<1:27:39, 29.89s/it] 59%|█████▉    | 257/432 [2:09:24<1:25:01, 29.15s/it] 60%|█████▉    | 258/432 [2:09:53<1:24:06, 29.00s/it] 60%|█████▉    | 259/432 [2:10:21<1:23:03, 28.80s/it] 60%|██████    | 260/432 [2:10:50<1:22:12, 28.68s/it]                                                     {'loss': 2.9217, 'grad_norm': 35.26496124267578, 'learning_rate': 3.291236033683109e-07, 'rewards/chosen': -8.8125, 'rewards/rejected': -9.125, 'rewards/accuracies': 0.515625, 'rewards/margins': 0.349609375, 'epoch': 0.6}
 60%|██████    | 260/432 [2:10:50<1:22:12, 28.68s/it] 60%|██████    | 261/432 [2:11:22<1:24:21, 29.60s/it] 61%|██████    | 262/432 [2:11:51<1:23:58, 29.64s/it] 61%|██████    | 263/432 [2:12:18<1:21:11, 28.82s/it] 61%|██████    | 264/432 [2:12:47<1:20:22, 28.70s/it] 61%|██████▏   | 265/432 [2:13:15<1:20:00, 28.74s/it]                                                     {'loss': 3.0727, 'grad_norm': 32.34450149536133, 'learning_rate': 3.1324849741863696e-07, 'rewards/chosen': -8.5, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.44140625, 'epoch': 0.61}
 61%|██████▏   | 265/432 [2:13:15<1:20:00, 28.74s/it] 62%|██████▏   | 266/432 [2:13:45<1:20:22, 29.05s/it] 62%|██████▏   | 267/432 [2:14:13<1:19:08, 28.78s/it] 62%|██████▏   | 268/432 [2:14:43<1:19:17, 29.01s/it] 62%|██████▏   | 269/432 [2:15:11<1:18:11, 28.78s/it] 62%|██████▎   | 270/432 [2:15:39<1:16:47, 28.44s/it]                                                     {'loss': 2.9481, 'grad_norm': 30.4603328704834, 'learning_rate': 2.9751555689497105e-07, 'rewards/chosen': -8.375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.365234375, 'epoch': 0.62}
 62%|██████▎   | 270/432 [2:15:39<1:16:47, 28.44s/it] 63%|██████▎   | 271/432 [2:16:05<1:14:42, 27.84s/it] 63%|██████▎   | 272/432 [2:16:35<1:16:08, 28.56s/it] 63%|██████▎   | 273/432 [2:17:06<1:17:22, 29.20s/it] 63%|██████▎   | 274/432 [2:17:33<1:14:38, 28.35s/it] 64%|██████▎   | 275/432 [2:18:02<1:14:56, 28.64s/it]                                                     {'loss': 2.9762, 'grad_norm': 23.538806915283203, 'learning_rate': 2.819505644077047e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.565625011920929, 'rewards/margins': 0.4453125, 'epoch': 0.64}
 64%|██████▎   | 275/432 [2:18:02<1:14:56, 28.64s/it] 64%|██████▍   | 276/432 [2:18:30<1:14:02, 28.48s/it] 64%|██████▍   | 277/432 [2:18:59<1:13:57, 28.63s/it] 64%|██████▍   | 278/432 [2:19:31<1:16:20, 29.74s/it] 65%|██████▍   | 279/432 [2:20:01<1:15:46, 29.72s/it] 65%|██████▍   | 280/432 [2:20:32<1:16:13, 30.09s/it]                                                     {'loss': 2.9855, 'grad_norm': 65.39196014404297, 'learning_rate': 2.665790273396718e-07, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.64453125, 'epoch': 0.65}
 65%|██████▍   | 280/432 [2:20:32<1:16:13, 30.09s/it] 65%|██████▌   | 281/432 [2:20:59<1:13:50, 29.34s/it] 65%|██████▌   | 282/432 [2:21:28<1:13:04, 29.23s/it] 66%|██████▌   | 283/432 [2:21:58<1:12:46, 29.30s/it] 66%|██████▌   | 284/432 [2:22:27<1:12:28, 29.38s/it] 66%|██████▌   | 285/432 [2:22:58<1:12:48, 29.72s/it]                                                     {'loss': 3.0021, 'grad_norm': 61.51302719116211, 'learning_rate': 2.5142613604551344e-07, 'rewards/chosen': -8.6875, 'rewards/rejected': -8.875, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.177734375, 'epoch': 0.66}
 66%|██████▌   | 285/432 [2:22:58<1:12:48, 29.72s/it] 66%|██████▌   | 286/432 [2:23:28<1:12:53, 29.95s/it] 66%|██████▋   | 287/432 [2:23:57<1:11:29, 29.58s/it] 67%|██████▋   | 288/432 [2:24:24<1:08:38, 28.60s/it] 67%|██████▋   | 289/432 [2:24:52<1:08:07, 28.58s/it] 67%|██████▋   | 290/432 [2:25:20<1:07:30, 28.52s/it]                                                     {'loss': 3.0026, 'grad_norm': 47.46554946899414, 'learning_rate': 2.3651672257057762e-07, 'rewards/chosen': -8.4375, 'rewards/rejected': -9.1875, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 0.703125, 'epoch': 0.67}
 67%|██████▋   | 290/432 [2:25:20<1:07:30, 28.52s/it] 67%|██████▋   | 291/432 [2:25:49<1:07:06, 28.56s/it] 68%|██████▊   | 292/432 [2:26:20<1:08:09, 29.21s/it] 68%|██████▊   | 293/432 [2:26:47<1:06:07, 28.54s/it] 68%|██████▊   | 294/432 [2:27:21<1:09:28, 30.21s/it] 68%|██████▊   | 295/432 [2:27:49<1:07:33, 29.59s/it]                                                     {'loss': 2.9055, 'grad_norm': 44.40229415893555, 'learning_rate': 2.2187521995700312e-07, 'rewards/chosen': -8.4375, 'rewards/rejected': -9.0, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.59375, 'epoch': 0.68}
 68%|██████▊   | 295/432 [2:27:49<1:07:33, 29.59s/it] 69%|██████▊   | 296/432 [2:28:21<1:08:49, 30.36s/it] 69%|██████▉   | 297/432 [2:28:49<1:06:28, 29.55s/it] 69%|██████▉   | 298/432 [2:29:18<1:05:37, 29.38s/it] 69%|██████▉   | 299/432 [2:29:45<1:03:34, 28.68s/it] 69%|██████▉   | 300/432 [2:30:14<1:03:09, 28.71s/it]                                                     {'loss': 3.0608, 'grad_norm': 32.740840911865234, 'learning_rate': 2.0752562220367795e-07, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 0.326171875, 'epoch': 0.69}
 69%|██████▉   | 300/432 [2:30:14<1:03:09, 28.71s/it][INFO|trainer.py:4289] 2025-03-28 16:12:35,459 >> 
***** Running Evaluation *****
[INFO|trainer.py:4291] 2025-03-28 16:12:35,459 >>   Num examples = 1130
[INFO|trainer.py:4294] 2025-03-28 16:12:35,459 >>   Batch size = 2

  0%|          | 0/283 [00:00<?, ?it/s][A
  1%|          | 2/283 [00:00<00:45,  6.14it/s][A
  1%|          | 3/283 [00:00<00:49,  5.71it/s][A
  1%|▏         | 4/283 [00:00<00:58,  4.81it/s][A
  2%|▏         | 5/283 [00:00<00:54,  5.07it/s][A
  2%|▏         | 6/283 [00:01<00:52,  5.31it/s][A
  2%|▏         | 7/283 [00:01<00:44,  6.17it/s][A
  3%|▎         | 8/283 [00:01<01:01,  4.48it/s][A
  3%|▎         | 9/283 [00:01<00:58,  4.65it/s][A
  4%|▎         | 10/283 [00:02<01:07,  4.04it/s][A
  4%|▍         | 11/283 [00:02<01:05,  4.13it/s][A
  5%|▍         | 13/283 [00:02<00:55,  4.84it/s][A
  5%|▍         | 14/283 [00:02<00:55,  4.81it/s][A
  5%|▌         | 15/283 [00:03<00:57,  4.69it/s][A
  6%|▌         | 16/283 [00:03<00:52,  5.13it/s][A
  6%|▌         | 17/283 [00:03<00:58,  4.54it/s][A
  6%|▋         | 18/283 [00:03<00:57,  4.63it/s][A
  7%|▋         | 19/283 [00:03<00:50,  5.27it/s][A
  7%|▋         | 20/283 [00:04<00:50,  5.25it/s][A
  7%|▋         | 21/283 [00:04<01:00,  4.33it/s][A
  8%|▊         | 22/283 [00:04<01:14,  3.49it/s][A
  8%|▊         | 23/283 [00:05<01:13,  3.56it/s][A
  8%|▊         | 24/283 [00:05<01:13,  3.54it/s][A
  9%|▉         | 25/283 [00:05<01:03,  4.09it/s][A
  9%|▉         | 26/283 [00:05<01:19,  3.25it/s][A
 10%|▉         | 27/283 [00:06<01:31,  2.81it/s][A
 10%|▉         | 28/283 [00:06<01:11,  3.55it/s][A
 10%|█         | 29/283 [00:06<01:11,  3.57it/s][A
 11%|█         | 30/283 [00:07<01:10,  3.57it/s][A
 11%|█         | 31/283 [00:07<01:09,  3.62it/s][A
 11%|█▏        | 32/283 [00:07<00:58,  4.28it/s][A
 12%|█▏        | 33/283 [00:07<01:00,  4.15it/s][A
 12%|█▏        | 34/283 [00:07<00:58,  4.26it/s][A
 12%|█▏        | 35/283 [00:08<00:52,  4.77it/s][A
 13%|█▎        | 36/283 [00:08<01:06,  3.73it/s][A
 13%|█▎        | 37/283 [00:08<01:05,  3.75it/s][A
 13%|█▎        | 38/283 [00:08<00:56,  4.37it/s][A
 14%|█▍        | 39/283 [00:09<01:04,  3.76it/s][A
 14%|█▍        | 40/283 [00:09<01:10,  3.46it/s][A
 14%|█▍        | 41/283 [00:09<01:01,  3.97it/s][A
 15%|█▍        | 42/283 [00:10<00:57,  4.20it/s][A
 15%|█▌        | 43/283 [00:10<00:56,  4.23it/s][A
 16%|█▌        | 44/283 [00:10<00:49,  4.81it/s][A
 16%|█▋        | 46/283 [00:10<00:41,  5.66it/s][A
 17%|█▋        | 47/283 [00:10<00:43,  5.46it/s][A
 17%|█▋        | 48/283 [00:11<00:53,  4.42it/s][A
 17%|█▋        | 49/283 [00:11<00:46,  4.99it/s][A
 18%|█▊        | 50/283 [00:11<00:46,  5.00it/s][A
 18%|█▊        | 51/283 [00:11<00:56,  4.14it/s][A
 18%|█▊        | 52/283 [00:12<00:57,  4.00it/s][A
 19%|█▊        | 53/283 [00:12<00:57,  3.98it/s][A
 19%|█▉        | 54/283 [00:12<00:57,  3.95it/s][A
 20%|█▉        | 56/283 [00:13<01:02,  3.64it/s][A
 20%|██        | 57/283 [00:13<01:03,  3.56it/s][A
 20%|██        | 58/283 [00:13<01:07,  3.32it/s][A
 21%|██        | 59/283 [00:14<01:05,  3.43it/s][A
 21%|██        | 60/283 [00:14<00:58,  3.78it/s][A
 22%|██▏       | 61/283 [00:14<00:52,  4.20it/s][A
 22%|██▏       | 62/283 [00:14<00:53,  4.14it/s][A
 22%|██▏       | 63/283 [00:15<00:49,  4.43it/s][A
 23%|██▎       | 64/283 [00:15<00:49,  4.47it/s][A
 23%|██▎       | 65/283 [00:15<00:50,  4.29it/s][A
 23%|██▎       | 66/283 [00:15<00:47,  4.57it/s][A
 24%|██▎       | 67/283 [00:15<00:53,  4.07it/s][A
 24%|██▍       | 68/283 [00:16<00:54,  3.93it/s][A
 24%|██▍       | 69/283 [00:16<00:46,  4.63it/s][A
 25%|██▍       | 70/283 [00:16<00:54,  3.91it/s][A
 25%|██▌       | 71/283 [00:16<00:48,  4.39it/s][A
 25%|██▌       | 72/283 [00:17<00:44,  4.70it/s][A
 26%|██▌       | 73/283 [00:17<00:52,  3.98it/s][A
 26%|██▌       | 74/283 [00:17<00:46,  4.49it/s][A
 27%|██▋       | 75/283 [00:17<00:57,  3.64it/s][A
 27%|██▋       | 76/283 [00:18<00:51,  4.01it/s][A
 27%|██▋       | 77/283 [00:18<00:47,  4.33it/s][A
 28%|██▊       | 78/283 [00:18<00:41,  4.91it/s][A
 28%|██▊       | 79/283 [00:18<00:38,  5.29it/s][A
 28%|██▊       | 80/283 [00:18<00:39,  5.17it/s][A
 29%|██▉       | 82/283 [00:19<00:38,  5.18it/s][A
 30%|██▉       | 84/283 [00:19<00:32,  6.20it/s][A
 30%|███       | 85/283 [00:19<00:29,  6.68it/s][A
 30%|███       | 86/283 [00:19<00:27,  7.22it/s][A
 31%|███       | 87/283 [00:19<00:33,  5.87it/s][A
 31%|███       | 88/283 [00:20<00:35,  5.42it/s][A
 31%|███▏      | 89/283 [00:20<00:36,  5.33it/s][A
 32%|███▏      | 90/283 [00:20<00:41,  4.63it/s][A
 32%|███▏      | 91/283 [00:20<00:35,  5.47it/s][A
 33%|███▎      | 92/283 [00:20<00:39,  4.83it/s][A
 33%|███▎      | 93/283 [00:21<00:46,  4.10it/s][A
 33%|███▎      | 94/283 [00:21<00:41,  4.57it/s][A
 34%|███▎      | 95/283 [00:21<00:44,  4.26it/s][A
 34%|███▍      | 96/283 [00:21<00:37,  4.94it/s][A
 34%|███▍      | 97/283 [00:22<00:47,  3.88it/s][A
 35%|███▍      | 99/283 [00:22<00:48,  3.79it/s][A
 35%|███▌      | 100/283 [00:23<00:47,  3.86it/s][A
 36%|███▌      | 101/283 [00:23<00:45,  4.02it/s][A
 36%|███▌      | 102/283 [00:23<00:55,  3.25it/s][A
 36%|███▋      | 103/283 [00:24<00:53,  3.34it/s][A
 37%|███▋      | 104/283 [00:24<00:52,  3.43it/s][A
 37%|███▋      | 105/283 [00:24<00:45,  3.95it/s][A
 37%|███▋      | 106/283 [00:24<00:38,  4.56it/s][A
 38%|███▊      | 107/283 [00:24<00:41,  4.20it/s][A
 38%|███▊      | 108/283 [00:25<00:38,  4.54it/s][A
 39%|███▊      | 109/283 [00:25<00:41,  4.17it/s][A
 39%|███▉      | 110/283 [00:25<00:45,  3.81it/s][A
 39%|███▉      | 111/283 [00:25<00:42,  4.09it/s][A
 40%|███▉      | 112/283 [00:26<00:36,  4.64it/s][A
 40%|███▉      | 113/283 [00:26<00:44,  3.85it/s][A
 40%|████      | 114/283 [00:26<00:46,  3.62it/s][A
 41%|████      | 115/283 [00:27<00:53,  3.14it/s][A
 41%|████      | 116/283 [00:27<00:46,  3.58it/s][A
 41%|████▏     | 117/283 [00:27<00:42,  3.92it/s][A
 42%|████▏     | 118/283 [00:27<00:36,  4.56it/s][A
 42%|████▏     | 119/283 [00:27<00:36,  4.45it/s][A
 42%|████▏     | 120/283 [00:28<00:33,  4.88it/s][A
 43%|████▎     | 121/283 [00:28<00:30,  5.29it/s][A
 43%|████▎     | 123/283 [00:28<00:25,  6.33it/s][A
 44%|████▍     | 124/283 [00:28<00:33,  4.70it/s][A
 44%|████▍     | 125/283 [00:29<00:35,  4.44it/s][A
 45%|████▍     | 126/283 [00:29<00:41,  3.81it/s][A
 45%|████▍     | 127/283 [00:29<00:41,  3.79it/s][A
 45%|████▌     | 128/283 [00:29<00:40,  3.81it/s][A
 46%|████▌     | 130/283 [00:30<00:31,  4.85it/s][A
 46%|████▋     | 131/283 [00:30<00:34,  4.35it/s][A
 47%|████▋     | 132/283 [00:30<00:32,  4.70it/s][A
 47%|████▋     | 133/283 [00:30<00:32,  4.59it/s][A
 47%|████▋     | 134/283 [00:31<00:37,  3.94it/s][A
 48%|████▊     | 135/283 [00:31<00:35,  4.21it/s][A
 48%|████▊     | 136/283 [00:31<00:33,  4.36it/s][A
 48%|████▊     | 137/283 [00:31<00:35,  4.17it/s][A
 49%|████▉     | 138/283 [00:32<00:39,  3.70it/s][A
 49%|████▉     | 139/283 [00:32<00:40,  3.52it/s][A
 49%|████▉     | 140/283 [00:32<00:36,  3.89it/s][A
 50%|████▉     | 141/283 [00:33<00:38,  3.67it/s][A
 50%|█████     | 142/283 [00:33<00:34,  4.05it/s][A
 51%|█████     | 143/283 [00:33<00:31,  4.44it/s][A
 51%|█████     | 144/283 [00:33<00:42,  3.30it/s][A
 51%|█████     | 145/283 [00:34<00:37,  3.68it/s][A
 52%|█████▏    | 146/283 [00:34<00:31,  4.28it/s][A
 52%|█████▏    | 147/283 [00:34<00:36,  3.73it/s][A
 52%|█████▏    | 148/283 [00:34<00:34,  3.86it/s][A
 53%|█████▎    | 149/283 [00:35<00:36,  3.71it/s][A
 53%|█████▎    | 150/283 [00:35<00:36,  3.60it/s][A
 53%|█████▎    | 151/283 [00:35<00:37,  3.49it/s][A
 54%|█████▎    | 152/283 [00:36<00:46,  2.81it/s][A
 54%|█████▍    | 153/283 [00:36<00:49,  2.63it/s][A
 54%|█████▍    | 154/283 [00:36<00:38,  3.35it/s][A
 55%|█████▍    | 155/283 [00:37<00:35,  3.61it/s][A
 55%|█████▌    | 156/283 [00:37<00:34,  3.69it/s][A
 55%|█████▌    | 157/283 [00:37<00:30,  4.19it/s][A
 56%|█████▌    | 158/283 [00:37<00:33,  3.76it/s][A
 56%|█████▌    | 159/283 [00:37<00:29,  4.14it/s][A
 57%|█████▋    | 160/283 [00:38<00:29,  4.20it/s][A
 57%|█████▋    | 161/283 [00:38<00:33,  3.68it/s][A
 57%|█████▋    | 162/283 [00:38<00:32,  3.67it/s][A
 58%|█████▊    | 163/283 [00:39<00:29,  4.07it/s][A
 58%|█████▊    | 164/283 [00:39<00:38,  3.13it/s][A
 58%|█████▊    | 165/283 [00:39<00:34,  3.40it/s][A
 59%|█████▊    | 166/283 [00:39<00:31,  3.76it/s][A
 59%|█████▉    | 167/283 [00:40<00:25,  4.49it/s][A
 59%|█████▉    | 168/283 [00:40<00:31,  3.66it/s][A
 60%|█████▉    | 169/283 [00:40<00:30,  3.68it/s][A
 60%|██████    | 170/283 [00:40<00:28,  4.02it/s][A
 60%|██████    | 171/283 [00:41<00:24,  4.65it/s][A
 61%|██████    | 172/283 [00:41<00:29,  3.77it/s][A
 61%|██████    | 173/283 [00:41<00:25,  4.32it/s][A
 62%|██████▏   | 175/283 [00:42<00:27,  3.96it/s][A
 62%|██████▏   | 176/283 [00:42<00:32,  3.34it/s][A
 63%|██████▎   | 177/283 [00:42<00:27,  3.88it/s][A
 63%|██████▎   | 179/283 [00:43<00:28,  3.63it/s][A
 64%|██████▎   | 180/283 [00:43<00:29,  3.49it/s][A
 64%|██████▍   | 181/283 [00:44<00:31,  3.26it/s][A
 64%|██████▍   | 182/283 [00:44<00:27,  3.65it/s][A
 65%|██████▍   | 183/283 [00:44<00:25,  3.97it/s][A
 65%|██████▌   | 184/283 [00:44<00:21,  4.64it/s][A
 65%|██████▌   | 185/283 [00:44<00:18,  5.17it/s][A
 66%|██████▌   | 186/283 [00:44<00:21,  4.62it/s][A
 66%|██████▌   | 187/283 [00:45<00:20,  4.78it/s][A
 66%|██████▋   | 188/283 [00:45<00:24,  3.81it/s][A
 67%|██████▋   | 189/283 [00:45<00:22,  4.13it/s][A
 67%|██████▋   | 190/283 [00:46<00:23,  3.93it/s][A
 67%|██████▋   | 191/283 [00:46<00:20,  4.56it/s][A
 68%|██████▊   | 192/283 [00:46<00:18,  4.83it/s][A
 68%|██████▊   | 193/283 [00:46<00:21,  4.19it/s][A
 69%|██████▊   | 194/283 [00:46<00:19,  4.67it/s][A
 69%|██████▉   | 195/283 [00:46<00:18,  4.75it/s][A
 69%|██████▉   | 196/283 [00:47<00:17,  5.09it/s][A
 70%|██████▉   | 197/283 [00:47<00:23,  3.71it/s][A
 70%|██████▉   | 198/283 [00:47<00:23,  3.59it/s][A
 70%|███████   | 199/283 [00:48<00:27,  3.02it/s][A
 71%|███████   | 200/283 [00:48<00:22,  3.64it/s][A
 71%|███████   | 201/283 [00:48<00:21,  3.78it/s][A
 71%|███████▏  | 202/283 [00:48<00:19,  4.07it/s][A
 72%|███████▏  | 203/283 [00:49<00:18,  4.42it/s][A
 72%|███████▏  | 204/283 [00:49<00:20,  3.88it/s][A
 72%|███████▏  | 205/283 [00:49<00:22,  3.52it/s][A
 73%|███████▎  | 206/283 [00:50<00:23,  3.29it/s][A
 73%|███████▎  | 207/283 [00:50<00:20,  3.79it/s][A
 73%|███████▎  | 208/283 [00:50<00:20,  3.62it/s][A
 74%|███████▍  | 209/283 [00:50<00:20,  3.54it/s][A
 74%|███████▍  | 210/283 [00:51<00:17,  4.24it/s][A
 75%|███████▍  | 211/283 [00:51<00:16,  4.27it/s][A
 75%|███████▍  | 212/283 [00:51<00:14,  4.86it/s][A
 75%|███████▌  | 213/283 [00:51<00:16,  4.28it/s][A
 76%|███████▌  | 214/283 [00:51<00:13,  5.09it/s][A
 76%|███████▌  | 215/283 [00:52<00:13,  5.03it/s][A
 76%|███████▋  | 216/283 [00:52<00:14,  4.48it/s][A
 77%|███████▋  | 217/283 [00:52<00:18,  3.62it/s][A
 77%|███████▋  | 218/283 [00:52<00:17,  3.80it/s][A
 77%|███████▋  | 219/283 [00:53<00:16,  3.82it/s][A
 78%|███████▊  | 220/283 [00:53<00:18,  3.42it/s][A
 78%|███████▊  | 221/283 [00:53<00:19,  3.11it/s][A
 78%|███████▊  | 222/283 [00:54<00:17,  3.55it/s][A
 79%|███████▉  | 223/283 [00:54<00:13,  4.29it/s][A
 79%|███████▉  | 224/283 [00:54<00:14,  4.16it/s][A
 80%|███████▉  | 225/283 [00:55<00:18,  3.15it/s][A
 80%|███████▉  | 226/283 [00:55<00:16,  3.39it/s][A
 80%|████████  | 227/283 [00:55<00:14,  3.92it/s][A
 81%|████████  | 228/283 [00:55<00:12,  4.38it/s][A
 81%|████████  | 229/283 [00:55<00:12,  4.25it/s][A
 81%|████████▏ | 230/283 [00:56<00:12,  4.23it/s][A
 82%|████████▏ | 231/283 [00:56<00:10,  4.89it/s][A
 82%|████████▏ | 232/283 [00:56<00:10,  4.73it/s][A
 82%|████████▏ | 233/283 [00:56<00:13,  3.83it/s][A
 83%|████████▎ | 234/283 [00:56<00:11,  4.28it/s][A
 83%|████████▎ | 235/283 [00:57<00:12,  3.99it/s][A
 83%|████████▎ | 236/283 [00:57<00:13,  3.48it/s][A
 84%|████████▎ | 237/283 [00:57<00:12,  3.71it/s][A
 84%|████████▍ | 238/283 [00:58<00:13,  3.34it/s][A
 84%|████████▍ | 239/283 [00:58<00:12,  3.47it/s][A
 85%|████████▍ | 240/283 [00:58<00:10,  3.98it/s][A
 85%|████████▌ | 241/283 [00:59<00:12,  3.39it/s][A
 86%|████████▌ | 242/283 [00:59<00:10,  3.98it/s][A
 86%|████████▌ | 243/283 [00:59<00:09,  4.10it/s][A
 87%|████████▋ | 245/283 [00:59<00:09,  3.96it/s][A
 87%|████████▋ | 246/283 [01:00<00:09,  3.97it/s][A
 87%|████████▋ | 247/283 [01:00<00:09,  3.82it/s][A
 88%|████████▊ | 249/283 [01:00<00:07,  4.52it/s][A
 88%|████████▊ | 250/283 [01:01<00:08,  3.72it/s][A
 89%|████████▊ | 251/283 [01:01<00:07,  4.14it/s][A
 89%|████████▉ | 252/283 [01:01<00:07,  3.92it/s][A
 89%|████████▉ | 253/283 [01:02<00:08,  3.71it/s][A
 90%|████████▉ | 254/283 [01:02<00:06,  4.29it/s][A
 90%|█████████ | 255/283 [01:02<00:08,  3.39it/s][A
 90%|█████████ | 256/283 [01:02<00:07,  3.71it/s][A
 91%|█████████ | 257/283 [01:03<00:07,  3.52it/s][A
 91%|█████████ | 258/283 [01:03<00:06,  4.13it/s][A
 92%|█████████▏| 259/283 [01:03<00:05,  4.70it/s][A
 92%|█████████▏| 260/283 [01:03<00:05,  4.56it/s][A
 93%|█████████▎| 262/283 [01:04<00:04,  4.33it/s][A
 93%|█████████▎| 263/283 [01:04<00:03,  5.02it/s][A
 93%|█████████▎| 264/283 [01:04<00:04,  4.72it/s][A
 94%|█████████▎| 265/283 [01:04<00:03,  4.92it/s][A
 94%|█████████▍| 266/283 [01:04<00:03,  5.45it/s][A
 94%|█████████▍| 267/283 [01:05<00:03,  4.62it/s][A
 95%|█████████▍| 268/283 [01:05<00:03,  4.71it/s][A
 95%|█████████▌| 269/283 [01:05<00:03,  4.40it/s][A
 95%|█████████▌| 270/283 [01:05<00:02,  4.40it/s][A
 96%|█████████▌| 271/283 [01:05<00:02,  4.99it/s][A
 96%|█████████▌| 272/283 [01:06<00:02,  4.14it/s][A
 96%|█████████▋| 273/283 [01:06<00:02,  3.37it/s][A
 97%|█████████▋| 274/283 [01:07<00:02,  3.27it/s][A
 98%|█████████▊| 276/283 [01:07<00:01,  4.11it/s][A
 98%|█████████▊| 277/283 [01:07<00:01,  4.56it/s][A
 98%|█████████▊| 278/283 [01:07<00:01,  4.41it/s][A
 99%|█████████▊| 279/283 [01:08<00:00,  4.26it/s][A
 99%|█████████▉| 280/283 [01:08<00:00,  4.25it/s][A
 99%|█████████▉| 281/283 [01:08<00:00,  4.22it/s][A
100%|█████████▉| 282/283 [01:08<00:00,  4.88it/s][A
100%|██████████| 283/283 [01:08<00:00,  4.33it/s][A                                                     
                                                 [A{'eval_loss': 2.9313409328460693, 'eval_runtime': 69.293, 'eval_samples_per_second': 16.308, 'eval_steps_per_second': 4.084, 'eval_rewards/chosen': -8.3125, 'eval_rewards/rejected': -8.625, 'eval_rewards/accuracies': 0.528268575668335, 'eval_rewards/margins': 0.3203125, 'epoch': 0.69}
 69%|██████▉   | 300/432 [2:31:23<1:03:09, 28.71s/it]
100%|██████████| 283/283 [01:09<00:00,  4.33it/s][A
                                                 [A[INFO|trainer.py:3966] 2025-03-28 16:13:47,419 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo/checkpoint-300
[INFO|configuration_utils.py:423] 2025-03-28 16:13:47,430 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-300/config.json
[INFO|configuration_utils.py:908] 2025-03-28 16:13:47,437 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-300/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 16:13:54,423 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/checkpoint-300/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 16:13:54,433 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 16:13:54,440 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/checkpoint-300/special_tokens_map.json
[2025-03-28 16:13:55,037] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step300 is about to be saved!
[2025-03-28 16:13:55,044] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/mp_rank_00_model_states.pt
[2025-03-28 16:13:55,044] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/mp_rank_00_model_states.pt...
[2025-03-28 16:14:00,320] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/mp_rank_00_model_states.pt.
[2025-03-28 16:14:00,323] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-28 16:14:17,378] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-28 16:14:17,393] [INFO] [engine.py:3645:_save_zero_checkpoint] zero checkpoint saved outputs/gemma-2-2b-it-simpo/checkpoint-300/global_step300/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-28 16:14:17,394] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step300 is ready now!
 70%|██████▉   | 301/432 [2:32:27<2:10:57, 59.98s/it] 70%|██████▉   | 302/432 [2:32:56<1:49:48, 50.68s/it] 70%|███████   | 303/432 [2:33:25<1:34:58, 44.17s/it] 70%|███████   | 304/432 [2:33:51<1:22:59, 38.90s/it] 71%|███████   | 305/432 [2:34:23<1:17:55, 36.82s/it]                                                     {'loss': 2.9749, 'grad_norm': 33.8170166015625, 'learning_rate': 1.9349144494568562e-07, 'rewards/chosen': -8.125, 'rewards/rejected': -8.375, 'rewards/accuracies': 0.546875, 'rewards/margins': 0.259765625, 'epoch': 0.71}
 71%|███████   | 305/432 [2:34:23<1:17:55, 36.82s/it] 71%|███████   | 306/432 [2:34:53<1:13:06, 34.82s/it] 71%|███████   | 307/432 [2:35:23<1:09:30, 33.37s/it] 71%|███████▏  | 308/432 [2:35:54<1:07:28, 32.65s/it] 72%|███████▏  | 309/432 [2:36:22<1:04:09, 31.30s/it] 72%|███████▏  | 310/432 [2:36:52<1:02:45, 30.87s/it]                                                     {'loss': 2.9625, 'grad_norm': 28.742334365844727, 'learning_rate': 1.7979568691767857e-07, 'rewards/chosen': -8.1875, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.484375, 'epoch': 0.72}
 72%|███████▏  | 310/432 [2:36:52<1:02:45, 30.87s/it] 72%|███████▏  | 311/432 [2:37:25<1:03:24, 31.44s/it] 72%|███████▏  | 312/432 [2:37:54<1:01:27, 30.73s/it] 72%|███████▏  | 313/432 [2:38:22<59:00, 29.76s/it]   73%|███████▎  | 314/432 [2:38:52<58:52, 29.94s/it] 73%|███████▎  | 315/432 [2:39:23<58:49, 30.17s/it]                                                   {'loss': 3.007, 'grad_norm': 29.441617965698242, 'learning_rate': 1.6646079226432988e-07, 'rewards/chosen': -8.5, 'rewards/rejected': -9.0, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.50390625, 'epoch': 0.73}
 73%|███████▎  | 315/432 [2:39:23<58:49, 30.17s/it] 73%|███████▎  | 316/432 [2:39:51<57:16, 29.62s/it] 73%|███████▎  | 317/432 [2:40:20<56:09, 29.30s/it] 74%|███████▎  | 318/432 [2:40:47<54:53, 28.89s/it] 74%|███████▍  | 319/432 [2:41:16<53:55, 28.63s/it] 74%|███████▍  | 320/432 [2:41:45<53:42, 28.77s/it]                                                   {'loss': 2.9662, 'grad_norm': 34.572242736816406, 'learning_rate': 1.5350861375962905e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.578125, 'rewards/margins': 0.453125, 'epoch': 0.74}
 74%|███████▍  | 320/432 [2:41:45<53:42, 28.77s/it] 74%|███████▍  | 321/432 [2:42:14<53:30, 28.92s/it] 75%|███████▍  | 322/432 [2:42:42<52:36, 28.69s/it] 75%|███████▍  | 323/432 [2:43:12<53:04, 29.21s/it] 75%|███████▌  | 324/432 [2:43:41<52:09, 28.98s/it] 75%|███████▌  | 325/432 [2:44:09<51:09, 28.69s/it]                                                   {'loss': 2.9298, 'grad_norm': 31.304603576660156, 'learning_rate': 1.4096037699529598e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.27734375, 'epoch': 0.75}
 75%|███████▌  | 325/432 [2:44:09<51:09, 28.69s/it] 75%|███████▌  | 326/432 [2:44:37<50:34, 28.63s/it] 76%|███████▌  | 327/432 [2:45:05<49:45, 28.44s/it] 76%|███████▌  | 328/432 [2:45:35<50:01, 28.86s/it] 76%|███████▌  | 329/432 [2:46:05<49:56, 29.09s/it] 76%|███████▋  | 330/432 [2:46:32<48:21, 28.45s/it]                                                   {'loss': 3.0153, 'grad_norm': 43.4014892578125, 'learning_rate': 1.2883664559699868e-07, 'rewards/chosen': -8.1875, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.439453125, 'epoch': 0.76}
 76%|███████▋  | 330/432 [2:46:32<48:21, 28.45s/it] 77%|███████▋  | 331/432 [2:47:03<49:22, 29.33s/it] 77%|███████▋  | 332/432 [2:47:34<49:31, 29.72s/it] 77%|███████▋  | 333/432 [2:48:03<48:53, 29.64s/it] 77%|███████▋  | 334/432 [2:48:32<47:58, 29.37s/it] 78%|███████▊  | 335/432 [2:48:59<46:29, 28.76s/it]                                                   {'loss': 2.9795, 'grad_norm': 30.483057022094727, 'learning_rate': 1.17157287525381e-07, 'rewards/chosen': -8.5, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 0.43359375, 'epoch': 0.78}
 78%|███████▊  | 335/432 [2:48:59<46:29, 28.76s/it] 78%|███████▊  | 336/432 [2:49:30<46:59, 29.37s/it] 78%|███████▊  | 337/432 [2:50:00<46:49, 29.57s/it] 78%|███████▊  | 338/432 [2:50:31<46:45, 29.84s/it] 78%|███████▊  | 339/432 [2:50:58<45:16, 29.21s/it] 79%|███████▊  | 340/432 [2:51:25<43:47, 28.56s/it]                                                   {'loss': 2.9545, 'grad_norm': 39.90178298950195, 'learning_rate': 1.0594144251711994e-07, 'rewards/chosen': -8.25, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.458984375, 'epoch': 0.79}
 79%|███████▊  | 340/432 [2:51:25<43:47, 28.56s/it] 79%|███████▉  | 341/432 [2:51:54<43:08, 28.45s/it] 79%|███████▉  | 342/432 [2:52:24<43:30, 29.01s/it] 79%|███████▉  | 343/432 [2:52:53<42:55, 28.94s/it] 80%|███████▉  | 344/432 [2:53:21<42:19, 28.86s/it] 80%|███████▉  | 345/432 [2:53:51<42:05, 29.03s/it]                                                   {'loss': 3.0629, 'grad_norm': 27.83897590637207, 'learning_rate': 9.520749071937353e-08, 'rewards/chosen': -8.3125, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.4906249940395355, 'rewards/margins': 0.263671875, 'epoch': 0.8}
 80%|███████▉  | 345/432 [2:53:51<42:05, 29.03s/it] 80%|████████  | 346/432 [2:54:20<41:45, 29.14s/it] 80%|████████  | 347/432 [2:54:48<40:33, 28.63s/it] 81%|████████  | 348/432 [2:55:15<39:41, 28.36s/it] 81%|████████  | 349/432 [2:55:44<39:08, 28.29s/it] 81%|████████  | 350/432 [2:56:15<40:03, 29.31s/it]                                                   {'loss': 2.9495, 'grad_norm': 36.48843002319336, 'learning_rate': 8.49730225690183e-08, 'rewards/chosen': -8.0625, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.5078125, 'rewards/margins': 0.408203125, 'epoch': 0.81}
 81%|████████  | 350/432 [2:56:15<40:03, 29.31s/it] 81%|████████▏ | 351/432 [2:56:46<40:00, 29.63s/it] 81%|████████▏ | 352/432 [2:57:12<38:22, 28.78s/it] 82%|████████▏ | 353/432 [2:57:43<38:31, 29.26s/it] 82%|████████▏ | 354/432 [2:58:12<38:11, 29.38s/it] 82%|████████▏ | 355/432 [2:58:41<37:27, 29.18s/it]                                                   {'loss': 2.8856, 'grad_norm': 28.372217178344727, 'learning_rate': 7.525480996603581e-08, 'rewards/chosen': -8.25, 'rewards/rejected': -8.875, 'rewards/accuracies': 0.534375011920929, 'rewards/margins': 0.66015625, 'epoch': 0.82}
 82%|████████▏ | 355/432 [2:58:41<37:27, 29.18s/it] 82%|████████▏ | 356/432 [2:59:10<36:47, 29.04s/it] 83%|████████▎ | 357/432 [2:59:40<36:36, 29.29s/it] 83%|████████▎ | 358/432 [3:00:07<35:18, 28.62s/it] 83%|████████▎ | 359/432 [3:00:36<34:59, 28.76s/it] 83%|████████▎ | 360/432 [3:01:03<34:00, 28.34s/it]                                                   {'loss': 3.061, 'grad_norm': 29.241241455078125, 'learning_rate': 6.60687787882916e-08, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.2177734375, 'epoch': 0.83}
 83%|████████▎ | 360/432 [3:01:03<34:00, 28.34s/it] 84%|████████▎ | 361/432 [3:01:30<33:08, 28.01s/it] 84%|████████▍ | 362/432 [3:01:59<32:49, 28.13s/it] 84%|████████▍ | 363/432 [3:02:32<34:03, 29.62s/it] 84%|████████▍ | 364/432 [3:03:01<33:20, 29.42s/it] 84%|████████▍ | 365/432 [3:03:33<33:43, 30.21s/it]                                                   {'loss': 2.9846, 'grad_norm': 24.31685447692871, 'learning_rate': 5.742998279274473e-08, 'rewards/chosen': -8.5, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.5703125, 'rewards/margins': 0.42578125, 'epoch': 0.84}
 84%|████████▍ | 365/432 [3:03:33<33:43, 30.21s/it] 85%|████████▍ | 366/432 [3:04:05<33:47, 30.72s/it] 85%|████████▍ | 367/432 [3:04:35<33:05, 30.55s/it] 85%|████████▌ | 368/432 [3:05:03<31:37, 29.65s/it] 85%|████████▌ | 369/432 [3:05:31<30:48, 29.35s/it] 86%|████████▌ | 370/432 [3:06:01<30:18, 29.33s/it]                                                   {'loss': 3.0628, 'grad_norm': 31.603445053100586, 'learning_rate': 4.9352578945860956e-08, 'rewards/chosen': -8.375, 'rewards/rejected': -8.5, 'rewards/accuracies': 0.515625, 'rewards/margins': 0.146484375, 'epoch': 0.86}
 86%|████████▌ | 370/432 [3:06:01<30:18, 29.33s/it] 86%|████████▌ | 371/432 [3:06:30<29:59, 29.51s/it] 86%|████████▌ | 372/432 [3:07:00<29:23, 29.39s/it] 86%|████████▋ | 373/432 [3:07:28<28:34, 29.06s/it] 87%|████████▋ | 374/432 [3:07:58<28:20, 29.31s/it] 87%|████████▋ | 375/432 [3:08:28<28:12, 29.69s/it]                                                   {'loss': 2.9962, 'grad_norm': 98.62317657470703, 'learning_rate': 4.184980422365538e-08, 'rewards/chosen': -8.25, 'rewards/rejected': -8.5625, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.291015625, 'epoch': 0.87}
 87%|████████▋ | 375/432 [3:08:28<28:12, 29.69s/it] 87%|████████▋ | 376/432 [3:08:58<27:48, 29.79s/it] 87%|████████▋ | 377/432 [3:09:28<27:15, 29.73s/it] 88%|████████▊ | 378/432 [3:09:56<26:20, 29.28s/it] 88%|████████▊ | 379/432 [3:10:27<26:16, 29.74s/it] 88%|████████▊ | 380/432 [3:10:55<25:24, 29.32s/it]                                                   {'loss': 3.0522, 'grad_norm': 40.37099075317383, 'learning_rate': 3.493395391938398e-08, 'rewards/chosen': -8.5, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19921875, 'epoch': 0.88}
 88%|████████▊ | 380/432 [3:10:55<25:24, 29.32s/it] 88%|████████▊ | 381/432 [3:11:26<25:14, 29.70s/it] 88%|████████▊ | 382/432 [3:11:53<24:03, 28.87s/it] 89%|████████▊ | 383/432 [3:12:21<23:18, 28.54s/it] 89%|████████▉ | 384/432 [3:12:50<23:00, 28.76s/it] 89%|████████▉ | 385/432 [3:13:17<22:10, 28.30s/it]                                                   {'loss': 3.0718, 'grad_norm': 29.783645629882812, 'learning_rate': 2.861636149443294e-08, 'rewards/chosen': -8.375, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.267578125, 'epoch': 0.89}
 89%|████████▉ | 385/432 [3:13:17<22:10, 28.30s/it] 89%|████████▉ | 386/432 [3:13:48<22:16, 29.06s/it] 90%|████████▉ | 387/432 [3:14:15<21:27, 28.60s/it] 90%|████████▉ | 388/432 [3:14:46<21:20, 29.11s/it] 90%|█████████ | 389/432 [3:15:13<20:27, 28.56s/it] 90%|█████████ | 390/432 [3:15:42<20:10, 28.82s/it]                                                   {'loss': 2.9704, 'grad_norm': 41.27597427368164, 'learning_rate': 2.290738000542629e-08, 'rewards/chosen': -8.5625, 'rewards/rejected': -8.9375, 'rewards/accuracies': 0.49687498807907104, 'rewards/margins': 0.40234375, 'epoch': 0.9}
 90%|█████████ | 390/432 [3:15:42<20:10, 28.82s/it] 91%|█████████ | 391/432 [3:16:15<20:30, 30.01s/it] 91%|█████████ | 392/432 [3:16:43<19:27, 29.18s/it] 91%|█████████ | 393/432 [3:17:09<18:27, 28.39s/it] 91%|█████████ | 394/432 [3:17:41<18:40, 29.49s/it] 91%|█████████▏| 395/432 [3:18:08<17:44, 28.78s/it]                                                   {'loss': 3.0095, 'grad_norm': 27.748754501342773, 'learning_rate': 1.781636513798692e-08, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.8125, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.384765625, 'epoch': 0.91}
 91%|█████████▏| 395/432 [3:18:08<17:44, 28.78s/it] 92%|█████████▏| 396/432 [3:18:38<17:21, 28.92s/it] 92%|█████████▏| 397/432 [3:19:10<17:26, 29.89s/it] 92%|█████████▏| 398/432 [3:19:39<16:48, 29.66s/it] 92%|█████████▏| 399/432 [3:20:10<16:30, 30.01s/it] 93%|█████████▎| 400/432 [3:20:38<15:46, 29.59s/it]                                                   {'loss': 2.9965, 'grad_norm': 86.30778503417969, 'learning_rate': 1.3351659874955545e-08, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.2373046875, 'epoch': 0.93}
 93%|█████████▎| 400/432 [3:20:38<15:46, 29.59s/it][INFO|trainer.py:4289] 2025-03-28 17:02:59,987 >> 
***** Running Evaluation *****
[INFO|trainer.py:4291] 2025-03-28 17:02:59,987 >>   Num examples = 1130
[INFO|trainer.py:4294] 2025-03-28 17:02:59,987 >>   Batch size = 2

  0%|          | 0/283 [00:00<?, ?it/s][A
  1%|          | 2/283 [00:00<00:45,  6.14it/s][A
  1%|          | 3/283 [00:00<00:49,  5.71it/s][A
  1%|▏         | 4/283 [00:00<00:56,  4.98it/s][A
  2%|▏         | 5/283 [00:00<00:53,  5.19it/s][A
  2%|▏         | 6/283 [00:01<00:51,  5.40it/s][A
  2%|▏         | 7/283 [00:01<00:44,  6.26it/s][A
  3%|▎         | 8/283 [00:01<01:00,  4.52it/s][A
  3%|▎         | 9/283 [00:01<00:58,  4.68it/s][A
  4%|▎         | 10/283 [00:02<01:07,  4.07it/s][A
  4%|▍         | 11/283 [00:02<01:05,  4.16it/s][A
  5%|▍         | 13/283 [00:02<00:55,  4.87it/s][A
  5%|▍         | 14/283 [00:02<00:55,  4.84it/s][A
  5%|▌         | 15/283 [00:03<00:56,  4.72it/s][A
  6%|▌         | 16/283 [00:03<00:51,  5.16it/s][A
  6%|▌         | 17/283 [00:03<00:58,  4.55it/s][A
  6%|▋         | 18/283 [00:03<00:57,  4.64it/s][A
  7%|▋         | 19/283 [00:03<00:49,  5.29it/s][A
  7%|▋         | 20/283 [00:04<00:50,  5.26it/s][A
  7%|▋         | 21/283 [00:04<01:00,  4.34it/s][A
  8%|▊         | 22/283 [00:04<01:14,  3.51it/s][A
  8%|▊         | 23/283 [00:05<01:12,  3.58it/s][A
  8%|▊         | 24/283 [00:05<01:12,  3.56it/s][A
  9%|▉         | 25/283 [00:05<01:02,  4.11it/s][A
  9%|▉         | 26/283 [00:05<01:18,  3.26it/s][A
 10%|▉         | 27/283 [00:06<01:30,  2.82it/s][A
 10%|▉         | 28/283 [00:06<01:11,  3.56it/s][A
 10%|█         | 29/283 [00:06<01:10,  3.58it/s][A
 11%|█         | 30/283 [00:07<01:10,  3.58it/s][A
 11%|█         | 31/283 [00:07<01:09,  3.62it/s][A
 11%|█▏        | 32/283 [00:07<00:58,  4.28it/s][A
 12%|█▏        | 33/283 [00:07<01:00,  4.15it/s][A
 12%|█▏        | 34/283 [00:07<00:58,  4.27it/s][A
 12%|█▏        | 35/283 [00:08<00:51,  4.78it/s][A
 13%|█▎        | 36/283 [00:08<01:08,  3.62it/s][A
 13%|█▎        | 37/283 [00:08<01:06,  3.68it/s][A
 13%|█▎        | 38/283 [00:08<00:57,  4.30it/s][A
 14%|█▍        | 39/283 [00:09<01:05,  3.73it/s][A
 14%|█▍        | 40/283 [00:09<01:10,  3.43it/s][A
 14%|█▍        | 41/283 [00:09<01:01,  3.94it/s][A
 15%|█▍        | 42/283 [00:10<00:57,  4.16it/s][A
 15%|█▌        | 43/283 [00:10<00:56,  4.22it/s][A
 16%|█▌        | 44/283 [00:10<00:49,  4.78it/s][A
 16%|█▋        | 46/283 [00:10<00:41,  5.64it/s][A
 17%|█▋        | 47/283 [00:10<00:43,  5.45it/s][A
 17%|█▋        | 48/283 [00:11<00:53,  4.42it/s][A
 17%|█▋        | 49/283 [00:11<00:46,  4.99it/s][A
 18%|█▊        | 50/283 [00:11<00:46,  5.01it/s][A
 18%|█▊        | 51/283 [00:11<00:56,  4.14it/s][A
 18%|█▊        | 52/283 [00:12<00:57,  4.00it/s][A
 19%|█▊        | 53/283 [00:12<00:57,  4.00it/s][A
 19%|█▉        | 54/283 [00:12<00:57,  3.96it/s][A
 20%|█▉        | 56/283 [00:13<01:02,  3.64it/s][A
 20%|██        | 57/283 [00:13<01:03,  3.56it/s][A
 20%|██        | 58/283 [00:13<01:07,  3.33it/s][A
 21%|██        | 59/283 [00:14<01:05,  3.44it/s][A
 21%|██        | 60/283 [00:14<00:58,  3.80it/s][A
 22%|██▏       | 61/283 [00:14<00:52,  4.22it/s][A
 22%|██▏       | 62/283 [00:14<00:53,  4.16it/s][A
 22%|██▏       | 63/283 [00:14<00:49,  4.46it/s][A
 23%|██▎       | 64/283 [00:15<00:48,  4.49it/s][A
 23%|██▎       | 65/283 [00:15<00:50,  4.30it/s][A
 23%|██▎       | 66/283 [00:15<00:47,  4.57it/s][A
 24%|██▎       | 67/283 [00:15<00:53,  4.07it/s][A
 24%|██▍       | 68/283 [00:16<00:54,  3.93it/s][A
 24%|██▍       | 69/283 [00:16<00:46,  4.62it/s][A
 25%|██▍       | 70/283 [00:16<00:54,  3.91it/s][A
 25%|██▌       | 71/283 [00:16<00:48,  4.38it/s][A
 25%|██▌       | 72/283 [00:17<00:44,  4.71it/s][A
 26%|██▌       | 73/283 [00:17<00:52,  3.98it/s][A
 26%|██▌       | 74/283 [00:17<00:46,  4.49it/s][A
 27%|██▋       | 75/283 [00:17<00:56,  3.65it/s][A
 27%|██▋       | 76/283 [00:18<00:51,  4.02it/s][A
 27%|██▋       | 77/283 [00:18<00:47,  4.35it/s][A
 28%|██▊       | 78/283 [00:18<00:41,  4.92it/s][A
 28%|██▊       | 79/283 [00:18<00:38,  5.32it/s][A
 28%|██▊       | 80/283 [00:18<00:39,  5.20it/s][A
 29%|██▉       | 82/283 [00:19<00:38,  5.20it/s][A
 30%|██▉       | 84/283 [00:19<00:31,  6.23it/s][A
 30%|███       | 85/283 [00:19<00:29,  6.70it/s][A
 30%|███       | 86/283 [00:19<00:27,  7.25it/s][A
 31%|███       | 87/283 [00:19<00:33,  5.90it/s][A
 31%|███       | 88/283 [00:20<00:35,  5.44it/s][A
 31%|███▏      | 89/283 [00:20<00:36,  5.34it/s][A
 32%|███▏      | 90/283 [00:20<00:41,  4.63it/s][A
 32%|███▏      | 91/283 [00:20<00:35,  5.47it/s][A
 33%|███▎      | 92/283 [00:20<00:39,  4.84it/s][A
 33%|███▎      | 93/283 [00:21<00:46,  4.11it/s][A
 33%|███▎      | 94/283 [00:21<00:41,  4.58it/s][A
 34%|███▎      | 95/283 [00:21<00:44,  4.27it/s][A
 34%|███▍      | 96/283 [00:21<00:37,  4.95it/s][A
 34%|███▍      | 97/283 [00:22<00:47,  3.89it/s][A
 35%|███▍      | 99/283 [00:22<00:48,  3.80it/s][A
 35%|███▌      | 100/283 [00:23<00:47,  3.87it/s][A
 36%|███▌      | 101/283 [00:23<00:45,  4.03it/s][A
 36%|███▌      | 102/283 [00:23<00:55,  3.25it/s][A
 36%|███▋      | 103/283 [00:23<00:53,  3.34it/s][A
 37%|███▋      | 104/283 [00:24<00:52,  3.42it/s][A
 37%|███▋      | 105/283 [00:24<00:45,  3.94it/s][A
 37%|███▋      | 106/283 [00:24<00:38,  4.56it/s][A
 38%|███▊      | 107/283 [00:24<00:41,  4.20it/s][A
 38%|███▊      | 108/283 [00:25<00:38,  4.55it/s][A
 39%|███▊      | 109/283 [00:25<00:41,  4.18it/s][A
 39%|███▉      | 110/283 [00:25<00:45,  3.82it/s][A
 39%|███▉      | 111/283 [00:25<00:41,  4.10it/s][A
 40%|███▉      | 112/283 [00:25<00:36,  4.65it/s][A
 40%|███▉      | 113/283 [00:26<00:44,  3.85it/s][A
 40%|████      | 114/283 [00:26<00:46,  3.63it/s][A
 41%|████      | 115/283 [00:27<00:53,  3.15it/s][A
 41%|████      | 116/283 [00:27<00:46,  3.58it/s][A
 41%|████▏     | 117/283 [00:27<00:42,  3.93it/s][A
 42%|████▏     | 118/283 [00:27<00:36,  4.56it/s][A
 42%|████▏     | 119/283 [00:27<00:36,  4.45it/s][A
 42%|████▏     | 120/283 [00:27<00:33,  4.87it/s][A
 43%|████▎     | 121/283 [00:28<00:30,  5.28it/s][A
 43%|████▎     | 123/283 [00:28<00:25,  6.34it/s][A
 44%|████▍     | 124/283 [00:28<00:33,  4.69it/s][A
 44%|████▍     | 125/283 [00:29<00:35,  4.44it/s][A
 45%|████▍     | 126/283 [00:29<00:41,  3.81it/s][A
 45%|████▍     | 127/283 [00:29<00:41,  3.80it/s][A
 45%|████▌     | 128/283 [00:29<00:40,  3.82it/s][A
 46%|████▌     | 130/283 [00:30<00:31,  4.83it/s][A
 46%|████▋     | 131/283 [00:30<00:34,  4.36it/s][A
 47%|████▋     | 132/283 [00:30<00:32,  4.71it/s][A
 47%|████▋     | 133/283 [00:30<00:32,  4.59it/s][A
 47%|████▋     | 134/283 [00:31<00:37,  3.95it/s][A
 48%|████▊     | 135/283 [00:31<00:35,  4.21it/s][A
 48%|████▊     | 136/283 [00:31<00:33,  4.36it/s][A
 48%|████▊     | 137/283 [00:31<00:34,  4.17it/s][A
 49%|████▉     | 138/283 [00:32<00:39,  3.71it/s][A
 49%|████▉     | 139/283 [00:32<00:40,  3.53it/s][A
 49%|████▉     | 140/283 [00:32<00:36,  3.89it/s][A
 50%|████▉     | 141/283 [00:33<00:38,  3.68it/s][A
 50%|█████     | 142/283 [00:33<00:34,  4.06it/s][A
 51%|█████     | 143/283 [00:33<00:31,  4.44it/s][A
 51%|█████     | 144/283 [00:33<00:42,  3.30it/s][A
 51%|█████     | 145/283 [00:34<00:37,  3.68it/s][A
 52%|█████▏    | 146/283 [00:34<00:31,  4.28it/s][A
 52%|█████▏    | 147/283 [00:34<00:36,  3.73it/s][A
 52%|█████▏    | 148/283 [00:34<00:34,  3.88it/s][A
 53%|█████▎    | 149/283 [00:35<00:36,  3.71it/s][A
 53%|█████▎    | 150/283 [00:35<00:36,  3.61it/s][A
 53%|█████▎    | 151/283 [00:35<00:37,  3.50it/s][A
 54%|█████▎    | 152/283 [00:36<00:46,  2.81it/s][A
 54%|█████▍    | 153/283 [00:36<00:49,  2.63it/s][A
 54%|█████▍    | 154/283 [00:36<00:38,  3.35it/s][A
 55%|█████▍    | 155/283 [00:37<00:35,  3.61it/s][A
 55%|█████▌    | 156/283 [00:37<00:34,  3.70it/s][A
 55%|█████▌    | 157/283 [00:37<00:30,  4.19it/s][A
 56%|█████▌    | 158/283 [00:37<00:33,  3.75it/s][A
 56%|█████▌    | 159/283 [00:37<00:29,  4.14it/s][A
 57%|█████▋    | 160/283 [00:38<00:29,  4.20it/s][A
 57%|█████▋    | 161/283 [00:38<00:33,  3.68it/s][A
 57%|█████▋    | 162/283 [00:38<00:33,  3.66it/s][A
 58%|█████▊    | 163/283 [00:38<00:29,  4.06it/s][A
 58%|█████▊    | 164/283 [00:39<00:38,  3.12it/s][A
 58%|█████▊    | 165/283 [00:39<00:34,  3.39it/s][A
 59%|█████▊    | 166/283 [00:39<00:31,  3.76it/s][A
 59%|█████▉    | 167/283 [00:40<00:25,  4.49it/s][A
 59%|█████▉    | 168/283 [00:40<00:31,  3.65it/s][A
 60%|█████▉    | 169/283 [00:40<00:31,  3.67it/s][A
 60%|██████    | 170/283 [00:40<00:28,  4.01it/s][A
 60%|██████    | 171/283 [00:41<00:24,  4.63it/s][A
 61%|██████    | 172/283 [00:41<00:29,  3.76it/s][A
 61%|██████    | 173/283 [00:41<00:25,  4.30it/s][A
 62%|██████▏   | 175/283 [00:42<00:27,  3.96it/s][A
 62%|██████▏   | 176/283 [00:42<00:32,  3.34it/s][A
 63%|██████▎   | 177/283 [00:42<00:27,  3.89it/s][A
 63%|██████▎   | 179/283 [00:43<00:28,  3.64it/s][A
 64%|██████▎   | 180/283 [00:43<00:29,  3.49it/s][A
 64%|██████▍   | 181/283 [00:43<00:31,  3.26it/s][A
 64%|██████▍   | 182/283 [00:44<00:27,  3.64it/s][A
 65%|██████▍   | 183/283 [00:44<00:25,  3.97it/s][A
 65%|██████▌   | 184/283 [00:44<00:21,  4.64it/s][A
 65%|██████▌   | 185/283 [00:44<00:18,  5.17it/s][A
 66%|██████▌   | 186/283 [00:44<00:20,  4.64it/s][A
 66%|██████▌   | 187/283 [00:45<00:20,  4.79it/s][A
 66%|██████▋   | 188/283 [00:45<00:24,  3.82it/s][A
 67%|██████▋   | 189/283 [00:45<00:22,  4.15it/s][A
 67%|██████▋   | 190/283 [00:45<00:23,  3.93it/s][A
 67%|██████▋   | 191/283 [00:46<00:20,  4.56it/s][A
 68%|██████▊   | 192/283 [00:46<00:18,  4.84it/s][A
 68%|██████▊   | 193/283 [00:46<00:21,  4.21it/s][A
 69%|██████▊   | 194/283 [00:46<00:19,  4.67it/s][A
 69%|██████▉   | 195/283 [00:46<00:18,  4.76it/s][A
 69%|██████▉   | 196/283 [00:47<00:17,  5.10it/s][A
 70%|██████▉   | 197/283 [00:47<00:23,  3.70it/s][A
 70%|██████▉   | 198/283 [00:47<00:23,  3.58it/s][A
 70%|███████   | 199/283 [00:48<00:27,  3.02it/s][A
 71%|███████   | 200/283 [00:48<00:22,  3.64it/s][A
 71%|███████   | 201/283 [00:48<00:21,  3.77it/s][A
 71%|███████▏  | 202/283 [00:48<00:19,  4.06it/s][A
 72%|███████▏  | 203/283 [00:49<00:18,  4.42it/s][A
 72%|███████▏  | 204/283 [00:49<00:20,  3.89it/s][A
 72%|███████▏  | 205/283 [00:49<00:22,  3.52it/s][A
 73%|███████▎  | 206/283 [00:50<00:23,  3.29it/s][A
 73%|███████▎  | 207/283 [00:50<00:20,  3.79it/s][A
 73%|███████▎  | 208/283 [00:50<00:20,  3.61it/s][A
 74%|███████▍  | 209/283 [00:50<00:20,  3.53it/s][A
 74%|███████▍  | 210/283 [00:50<00:17,  4.24it/s][A
 75%|███████▍  | 211/283 [00:51<00:16,  4.25it/s][A
 75%|███████▍  | 212/283 [00:51<00:14,  4.82it/s][A
 75%|███████▌  | 213/283 [00:51<00:16,  4.27it/s][A
 76%|███████▌  | 214/283 [00:51<00:13,  5.08it/s][A
 76%|███████▌  | 215/283 [00:51<00:13,  5.03it/s][A
 76%|███████▋  | 216/283 [00:52<00:14,  4.48it/s][A
 77%|███████▋  | 217/283 [00:52<00:18,  3.63it/s][A
 77%|███████▋  | 218/283 [00:52<00:17,  3.80it/s][A
 77%|███████▋  | 219/283 [00:53<00:16,  3.82it/s][A
 78%|███████▊  | 220/283 [00:53<00:18,  3.42it/s][A
 78%|███████▊  | 221/283 [00:53<00:19,  3.12it/s][A
 78%|███████▊  | 222/283 [00:54<00:17,  3.55it/s][A
 79%|███████▉  | 223/283 [00:54<00:13,  4.29it/s][A
 79%|███████▉  | 224/283 [00:54<00:14,  4.16it/s][A
 80%|███████▉  | 225/283 [00:54<00:18,  3.16it/s][A
 80%|███████▉  | 226/283 [00:55<00:16,  3.39it/s][A
 80%|████████  | 227/283 [00:55<00:14,  3.92it/s][A
 81%|████████  | 228/283 [00:55<00:12,  4.38it/s][A
 81%|████████  | 229/283 [00:55<00:12,  4.25it/s][A
 81%|████████▏ | 230/283 [00:56<00:12,  4.23it/s][A
 82%|████████▏ | 231/283 [00:56<00:10,  4.88it/s][A
 82%|████████▏ | 232/283 [00:56<00:10,  4.73it/s][A
 82%|████████▏ | 233/283 [00:56<00:13,  3.84it/s][A
 83%|████████▎ | 234/283 [00:56<00:11,  4.29it/s][A
 83%|████████▎ | 235/283 [00:57<00:12,  3.99it/s][A
 83%|████████▎ | 236/283 [00:57<00:13,  3.49it/s][A
 84%|████████▎ | 237/283 [00:57<00:12,  3.71it/s][A
 84%|████████▍ | 238/283 [00:58<00:13,  3.34it/s][A
 84%|████████▍ | 239/283 [00:58<00:12,  3.47it/s][A
 85%|████████▍ | 240/283 [00:58<00:10,  3.98it/s][A
 85%|████████▌ | 241/283 [00:59<00:12,  3.39it/s][A
 86%|████████▌ | 242/283 [00:59<00:10,  3.98it/s][A
 86%|████████▌ | 243/283 [00:59<00:09,  4.10it/s][A
 87%|████████▋ | 245/283 [00:59<00:09,  3.96it/s][A
 87%|████████▋ | 246/283 [01:00<00:09,  3.97it/s][A
 87%|████████▋ | 247/283 [01:00<00:09,  3.79it/s][A
 88%|████████▊ | 249/283 [01:00<00:07,  4.50it/s][A
 88%|████████▊ | 250/283 [01:01<00:08,  3.70it/s][A
 89%|████████▊ | 251/283 [01:01<00:07,  4.13it/s][A
 89%|████████▉ | 252/283 [01:01<00:07,  3.91it/s][A
 89%|████████▉ | 253/283 [01:01<00:08,  3.69it/s][A
 90%|████████▉ | 254/283 [01:02<00:06,  4.27it/s][A
 90%|█████████ | 255/283 [01:02<00:08,  3.39it/s][A
 90%|█████████ | 256/283 [01:02<00:07,  3.70it/s][A
 91%|█████████ | 257/283 [01:03<00:07,  3.52it/s][A
 91%|█████████ | 258/283 [01:03<00:06,  4.13it/s][A
 92%|█████████▏| 259/283 [01:03<00:05,  4.70it/s][A
 92%|█████████▏| 260/283 [01:03<00:05,  4.56it/s][A
 93%|█████████▎| 262/283 [01:04<00:04,  4.33it/s][A
 93%|█████████▎| 263/283 [01:04<00:03,  5.02it/s][A
 93%|█████████▎| 264/283 [01:04<00:04,  4.72it/s][A
 94%|█████████▎| 265/283 [01:04<00:03,  4.93it/s][A
 94%|█████████▍| 266/283 [01:04<00:03,  5.48it/s][A
 94%|█████████▍| 267/283 [01:05<00:03,  4.64it/s][A
 95%|█████████▍| 268/283 [01:05<00:03,  4.72it/s][A
 95%|█████████▌| 269/283 [01:05<00:03,  4.41it/s][A
 95%|█████████▌| 270/283 [01:05<00:02,  4.41it/s][A
 96%|█████████▌| 271/283 [01:05<00:02,  4.99it/s][A
 96%|█████████▌| 272/283 [01:06<00:02,  4.13it/s][A
 96%|█████████▋| 273/283 [01:06<00:02,  3.36it/s][A
 97%|█████████▋| 274/283 [01:06<00:02,  3.26it/s][A
 98%|█████████▊| 276/283 [01:07<00:01,  4.10it/s][A
 98%|█████████▊| 277/283 [01:07<00:01,  4.54it/s][A
 98%|█████████▊| 278/283 [01:07<00:01,  4.40it/s][A
 99%|█████████▊| 279/283 [01:07<00:00,  4.25it/s][A
 99%|█████████▉| 280/283 [01:08<00:00,  4.24it/s][A
 99%|█████████▉| 281/283 [01:08<00:00,  4.21it/s][A
100%|█████████▉| 282/283 [01:08<00:00,  4.87it/s][A
100%|██████████| 283/283 [01:08<00:00,  4.32it/s][A                                                   
                                                 [A{'eval_loss': 2.9300100803375244, 'eval_runtime': 69.2504, 'eval_samples_per_second': 16.318, 'eval_steps_per_second': 4.087, 'eval_rewards/chosen': -8.3125, 'eval_rewards/rejected': -8.625, 'eval_rewards/accuracies': 0.5265017747879028, 'eval_rewards/margins': 0.314453125, 'epoch': 0.93}
 93%|█████████▎| 400/432 [3:21:47<15:46, 29.59s/it]
100%|██████████| 283/283 [01:09<00:00,  4.32it/s][A
                                                 [A[INFO|trainer.py:3966] 2025-03-28 17:04:11,937 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo/checkpoint-400
[INFO|configuration_utils.py:423] 2025-03-28 17:04:11,941 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-400/config.json
[INFO|configuration_utils.py:908] 2025-03-28 17:04:11,949 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-400/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 17:04:19,493 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/checkpoint-400/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 17:04:19,503 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 17:04:19,509 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/checkpoint-400/special_tokens_map.json
[2025-03-28 17:04:20,214] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step400 is about to be saved!
[2025-03-28 17:04:20,222] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/mp_rank_00_model_states.pt
[2025-03-28 17:04:20,222] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/mp_rank_00_model_states.pt...
[2025-03-28 17:04:25,882] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/mp_rank_00_model_states.pt.
[2025-03-28 17:04:25,883] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-28 17:04:43,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-28 17:04:43,353] [INFO] [engine.py:3645:_save_zero_checkpoint] zero checkpoint saved outputs/gemma-2-2b-it-simpo/checkpoint-400/global_step400/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-28 17:04:43,354] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step400 is ready now!
 93%|█████████▎| 401/432 [3:22:49<31:01, 60.03s/it] 93%|█████████▎| 402/432 [3:23:16<25:02, 50.08s/it] 93%|█████████▎| 403/432 [3:23:44<20:57, 43.36s/it] 94%|█████████▎| 404/432 [3:24:15<18:34, 39.80s/it] 94%|█████████▍| 405/432 [3:24:43<16:12, 36.03s/it]                                                   {'loss': 2.9899, 'grad_norm': 35.07124328613281, 'learning_rate': 9.520580824192803e-09, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.6875, 'rewards/accuracies': 0.5218750238418579, 'rewards/margins': 0.23046875, 'epoch': 0.94}
 94%|█████████▍| 405/432 [3:24:43<16:12, 36.03s/it] 94%|█████████▍| 406/432 [3:25:10<14:29, 33.45s/it] 94%|█████████▍| 407/432 [3:25:42<13:46, 33.05s/it] 94%|█████████▍| 408/432 [3:26:14<13:01, 32.58s/it] 95%|█████████▍| 409/432 [3:26:43<12:07, 31.65s/it] 95%|█████████▍| 410/432 [3:27:12<11:19, 30.89s/it]                                                   {'loss': 2.9524, 'grad_norm': 70.28839874267578, 'learning_rate': 6.329406228370304e-09, 'rewards/chosen': -8.125, 'rewards/rejected': -8.4375, 'rewards/accuracies': 0.559374988079071, 'rewards/margins': 0.33203125, 'epoch': 0.95}
 95%|█████████▍| 410/432 [3:27:12<11:19, 30.89s/it] 95%|█████████▌| 411/432 [3:27:44<10:51, 31.02s/it] 95%|█████████▌| 412/432 [3:28:13<10:11, 30.55s/it] 96%|█████████▌| 413/432 [3:28:42<09:34, 30.23s/it] 96%|█████████▌| 414/432 [3:29:12<09:02, 30.16s/it] 96%|█████████▌| 415/432 [3:29:43<08:33, 30.23s/it]                                                   {'loss': 3.0141, 'grad_norm': 25.61031150817871, 'learning_rate': 3.783365676398676e-09, 'rewards/chosen': -8.4375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.283203125, 'epoch': 0.96}
 96%|█████████▌| 415/432 [3:29:43<08:33, 30.23s/it] 96%|█████████▋| 416/432 [3:30:13<08:03, 30.24s/it] 97%|█████████▋| 417/432 [3:30:41<07:24, 29.61s/it] 97%|█████████▋| 418/432 [3:31:11<06:53, 29.57s/it] 97%|█████████▋| 419/432 [3:31:42<06:29, 29.98s/it] 97%|█████████▋| 420/432 [3:32:12<05:59, 29.98s/it]                                                   {'loss': 2.9773, 'grad_norm': 40.02103042602539, 'learning_rate': 1.8866315333544214e-09, 'rewards/chosen': -8.375, 'rewards/rejected': -8.75, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.388671875, 'epoch': 0.97}
 97%|█████████▋| 420/432 [3:32:12<05:59, 29.98s/it] 97%|█████████▋| 421/432 [3:32:39<05:22, 29.28s/it] 98%|█████████▊| 422/432 [3:33:11<05:00, 30.01s/it] 98%|█████████▊| 423/432 [3:33:39<04:23, 29.32s/it] 98%|█████████▊| 424/432 [3:34:10<03:58, 29.86s/it] 98%|█████████▊| 425/432 [3:34:39<03:26, 29.54s/it]                                                   {'loss': 3.0277, 'grad_norm': 37.74869918823242, 'learning_rate': 6.423121029492496e-10, 'rewards/chosen': -8.5, 'rewards/rejected': -9.0, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.478515625, 'epoch': 0.98}
 98%|█████████▊| 425/432 [3:34:39<03:26, 29.54s/it] 99%|█████████▊| 426/432 [3:35:05<02:51, 28.64s/it] 99%|█████████▉| 427/432 [3:35:35<02:24, 29.00s/it] 99%|█████████▉| 428/432 [3:36:01<01:52, 28.14s/it] 99%|█████████▉| 429/432 [3:36:30<01:24, 28.21s/it]100%|█████████▉| 430/432 [3:37:05<01:00, 30.34s/it]                                                   {'loss': 2.9813, 'grad_norm': 37.72181701660156, 'learning_rate': 5.244653374711916e-11, 'rewards/chosen': -8.5625, 'rewards/rejected': -8.625, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.0654296875, 'epoch': 0.99}
100%|█████████▉| 430/432 [3:37:05<01:00, 30.34s/it]100%|█████████▉| 431/432 [3:37:34<00:29, 29.94s/it]100%|██████████| 432/432 [3:38:01<00:00, 29.20s/it][INFO|trainer.py:3966] 2025-03-28 17:20:26,102 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo/checkpoint-432
[INFO|configuration_utils.py:423] 2025-03-28 17:20:26,106 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-432/config.json
[INFO|configuration_utils.py:908] 2025-03-28 17:20:26,107 >> Configuration saved in outputs/gemma-2-2b-it-simpo/checkpoint-432/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 17:20:33,391 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/checkpoint-432/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 17:20:33,395 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/checkpoint-432/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 17:20:33,396 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/checkpoint-432/special_tokens_map.json
[2025-03-28 17:20:34,217] [INFO] [logging.py:128:log_dist] [Rank 0] [Torch] Checkpoint global_step432 is about to be saved!
[2025-03-28 17:20:34,224] [INFO] [logging.py:128:log_dist] [Rank 0] Saving model checkpoint: outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/mp_rank_00_model_states.pt
[2025-03-28 17:20:34,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/mp_rank_00_model_states.pt...
[2025-03-28 17:20:39,969] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/mp_rank_00_model_states.pt.
[2025-03-28 17:20:39,970] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2025-03-28 17:20:58,267] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2025-03-28 17:20:58,280] [INFO] [engine.py:3645:_save_zero_checkpoint] zero checkpoint saved outputs/gemma-2-2b-it-simpo/checkpoint-432/global_step432/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2025-03-28 17:20:58,280] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step432 is ready now!
[INFO|trainer.py:2665] 2025-03-28 17:20:58,307 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   {'train_runtime': 13120.8355, 'train_samples_per_second': 4.216, 'train_steps_per_second': 0.033, 'train_loss': 3.02392871733065, 'epoch': 1.0}
100%|██████████| 432/432 [3:38:37<00:00, 29.20s/it]100%|██████████| 432/432 [3:38:37<00:00, 30.36s/it]
***** train metrics *****
  epoch                    =     0.9995
  total_flos               =        0GF
  train_loss               =     3.0239
  train_runtime            = 3:38:40.83
  train_samples            =      55321
  train_samples_per_second =      4.216
  train_steps_per_second   =      0.033
2025-03-28 17:20:58 - INFO - __main__ - *** Training complete ***
2025-03-28 17:20:58 - INFO - __main__ - *** Save model ***
[INFO|trainer.py:3966] 2025-03-28 17:21:01,162 >> Saving model checkpoint to outputs/gemma-2-2b-it-simpo
[INFO|configuration_utils.py:423] 2025-03-28 17:21:01,166 >> Configuration saved in outputs/gemma-2-2b-it-simpo/config.json
[INFO|configuration_utils.py:908] 2025-03-28 17:21:01,166 >> Configuration saved in outputs/gemma-2-2b-it-simpo/generation_config.json
[INFO|modeling_utils.py:3594] 2025-03-28 17:21:08,626 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at outputs/gemma-2-2b-it-simpo/model.safetensors.index.json.
[INFO|tokenization_utils_base.py:2510] 2025-03-28 17:21:08,635 >> tokenizer config file saved in outputs/gemma-2-2b-it-simpo/tokenizer_config.json
[INFO|tokenization_utils_base.py:2519] 2025-03-28 17:21:08,636 >> Special tokens file saved in outputs/gemma-2-2b-it-simpo/special_tokens_map.json
2025-03-28 17:21:09 - INFO - __main__ - Model saved to outputs/gemma-2-2b-it-simpo
[INFO|modelcard.py:449] 2025-03-28 17:21:09,409 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'dataset': {'name': '/zju_0038/yggu/huggingface/pad-gemma-2-n4', 'type': '/zju_0038/yggu/huggingface/pad-gemma-2-n4'}}
[INFO|configuration_utils.py:423] 2025-03-28 17:21:09,432 >> Configuration saved in outputs/gemma-2-2b-it-simpo/config.json
2025-03-28 17:21:09 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:4289] 2025-03-28 17:21:09,435 >> 
***** Running Evaluation *****
[INFO|trainer.py:4291] 2025-03-28 17:21:09,435 >>   Num examples = 1130
[INFO|trainer.py:4294] 2025-03-28 17:21:09,435 >>   Batch size = 2
  0%|          | 0/283 [00:00<?, ?it/s]  1%|          | 2/283 [00:00<00:45,  6.19it/s]  1%|          | 3/283 [00:00<00:48,  5.74it/s]  1%|▏         | 4/283 [00:00<00:55,  4.98it/s]  2%|▏         | 5/283 [00:00<00:53,  5.22it/s]  2%|▏         | 6/283 [00:01<00:50,  5.43it/s]  2%|▏         | 7/283 [00:01<00:43,  6.29it/s]  3%|▎         | 8/283 [00:01<01:00,  4.53it/s]  3%|▎         | 9/283 [00:01<00:58,  4.68it/s]  4%|▎         | 10/283 [00:02<01:06,  4.08it/s]  4%|▍         | 11/283 [00:02<01:05,  4.18it/s]  5%|▍         | 13/283 [00:02<00:55,  4.87it/s]  5%|▍         | 14/283 [00:02<00:55,  4.85it/s]  5%|▌         | 15/283 [00:03<00:56,  4.73it/s]  6%|▌         | 16/283 [00:03<00:51,  5.19it/s]  6%|▌         | 17/283 [00:03<00:58,  4.56it/s]  6%|▋         | 18/283 [00:03<00:56,  4.66it/s]  7%|▋         | 19/283 [00:03<00:49,  5.30it/s]  7%|▋         | 20/283 [00:04<00:49,  5.27it/s]  7%|▋         | 21/283 [00:04<01:00,  4.34it/s]  8%|▊         | 22/283 [00:04<01:14,  3.51it/s]  8%|▊         | 23/283 [00:05<01:12,  3.58it/s]  8%|▊         | 24/283 [00:05<01:12,  3.56it/s]  9%|▉         | 25/283 [00:05<01:02,  4.12it/s]  9%|▉         | 26/283 [00:05<01:18,  3.27it/s] 10%|▉         | 27/283 [00:06<01:30,  2.82it/s] 10%|▉         | 28/283 [00:06<01:11,  3.56it/s] 10%|█         | 29/283 [00:06<01:10,  3.58it/s] 11%|█         | 30/283 [00:07<01:11,  3.56it/s] 11%|█         | 31/283 [00:07<01:09,  3.64it/s] 11%|█▏        | 32/283 [00:07<00:58,  4.30it/s] 12%|█▏        | 33/283 [00:07<00:59,  4.17it/s] 12%|█▏        | 34/283 [00:07<00:58,  4.27it/s] 12%|█▏        | 35/283 [00:08<00:52,  4.76it/s] 13%|█▎        | 36/283 [00:08<01:05,  3.74it/s] 13%|█▎        | 37/283 [00:08<01:05,  3.77it/s] 13%|█▎        | 38/283 [00:08<00:55,  4.39it/s] 14%|█▍        | 39/283 [00:09<01:04,  3.78it/s] 14%|█▍        | 40/283 [00:09<01:09,  3.47it/s] 14%|█▍        | 41/283 [00:09<01:00,  3.99it/s] 15%|█▍        | 42/283 [00:09<00:57,  4.23it/s] 15%|█▌        | 43/283 [00:10<00:56,  4.26it/s] 16%|█▌        | 44/283 [00:10<00:49,  4.84it/s] 16%|█▋        | 46/283 [00:10<00:41,  5.68it/s] 17%|█▋        | 47/283 [00:10<00:43,  5.47it/s] 17%|█▋        | 48/283 [00:11<00:53,  4.43it/s] 17%|█▋        | 49/283 [00:11<00:46,  5.00it/s] 18%|█▊        | 50/283 [00:11<00:46,  5.02it/s] 18%|█▊        | 51/283 [00:11<00:55,  4.15it/s] 18%|█▊        | 52/283 [00:12<00:57,  4.01it/s] 19%|█▊        | 53/283 [00:12<00:57,  4.01it/s] 19%|█▉        | 54/283 [00:12<00:57,  3.97it/s] 20%|█▉        | 56/283 [00:13<01:02,  3.65it/s] 20%|██        | 57/283 [00:13<01:03,  3.55it/s] 20%|██        | 58/283 [00:13<01:07,  3.33it/s] 21%|██        | 59/283 [00:14<01:05,  3.45it/s] 21%|██        | 60/283 [00:14<00:58,  3.80it/s] 22%|██▏       | 61/283 [00:14<00:52,  4.23it/s] 22%|██▏       | 62/283 [00:14<00:52,  4.18it/s] 22%|██▏       | 63/283 [00:14<00:49,  4.47it/s] 23%|██▎       | 64/283 [00:15<00:48,  4.50it/s] 23%|██▎       | 65/283 [00:15<00:50,  4.31it/s] 23%|██▎       | 66/283 [00:15<00:47,  4.58it/s] 24%|██▎       | 67/283 [00:15<00:52,  4.08it/s] 24%|██▍       | 68/283 [00:16<00:54,  3.95it/s] 24%|██▍       | 69/283 [00:16<00:46,  4.64it/s] 25%|██▍       | 70/283 [00:16<00:54,  3.92it/s] 25%|██▌       | 71/283 [00:16<00:48,  4.41it/s] 25%|██▌       | 72/283 [00:16<00:44,  4.75it/s] 26%|██▌       | 73/283 [00:17<00:52,  4.00it/s] 26%|██▌       | 74/283 [00:17<00:46,  4.50it/s] 27%|██▋       | 75/283 [00:17<00:56,  3.66it/s] 27%|██▋       | 76/283 [00:18<00:51,  4.03it/s] 27%|██▋       | 77/283 [00:18<00:47,  4.35it/s] 28%|██▊       | 78/283 [00:18<00:41,  4.94it/s] 28%|██▊       | 79/283 [00:18<00:38,  5.32it/s] 28%|██▊       | 80/283 [00:18<00:38,  5.22it/s] 29%|██▉       | 82/283 [00:19<00:38,  5.21it/s] 30%|██▉       | 84/283 [00:19<00:31,  6.23it/s] 30%|███       | 85/283 [00:19<00:29,  6.71it/s] 30%|███       | 86/283 [00:19<00:27,  7.26it/s] 31%|███       | 87/283 [00:19<00:33,  5.90it/s] 31%|███       | 88/283 [00:20<00:35,  5.44it/s] 31%|███▏      | 89/283 [00:20<00:36,  5.36it/s] 32%|███▏      | 90/283 [00:20<00:41,  4.65it/s] 32%|███▏      | 91/283 [00:20<00:35,  5.48it/s] 33%|███▎      | 92/283 [00:20<00:39,  4.82it/s] 33%|███▎      | 93/283 [00:21<00:46,  4.11it/s] 33%|███▎      | 94/283 [00:21<00:41,  4.58it/s] 34%|███▎      | 95/283 [00:21<00:44,  4.27it/s] 34%|███▍      | 96/283 [00:21<00:37,  4.95it/s] 34%|███▍      | 97/283 [00:22<00:47,  3.90it/s] 35%|███▍      | 99/283 [00:22<00:48,  3.81it/s] 35%|███▌      | 100/283 [00:22<00:47,  3.88it/s] 36%|███▌      | 101/283 [00:23<00:45,  4.04it/s] 36%|███▌      | 102/283 [00:23<00:55,  3.26it/s] 36%|███▋      | 103/283 [00:23<00:53,  3.34it/s] 37%|███▋      | 104/283 [00:24<00:52,  3.43it/s] 37%|███▋      | 105/283 [00:24<00:45,  3.95it/s] 37%|███▋      | 106/283 [00:24<00:38,  4.57it/s] 38%|███▊      | 107/283 [00:24<00:41,  4.20it/s] 38%|███▊      | 108/283 [00:24<00:38,  4.54it/s] 39%|███▊      | 109/283 [00:25<00:41,  4.19it/s] 39%|███▉      | 110/283 [00:25<00:45,  3.83it/s] 39%|███▉      | 111/283 [00:25<00:41,  4.11it/s] 40%|███▉      | 112/283 [00:25<00:36,  4.64it/s] 40%|███▉      | 113/283 [00:26<00:44,  3.85it/s] 40%|████      | 114/283 [00:26<00:46,  3.63it/s] 41%|████      | 115/283 [00:26<00:53,  3.15it/s] 41%|████      | 116/283 [00:27<00:46,  3.58it/s] 41%|████▏     | 117/283 [00:27<00:42,  3.93it/s] 42%|████▏     | 118/283 [00:27<00:36,  4.57it/s] 42%|████▏     | 119/283 [00:27<00:36,  4.47it/s] 42%|████▏     | 120/283 [00:27<00:33,  4.88it/s] 43%|████▎     | 121/283 [00:28<00:30,  5.27it/s] 43%|████▎     | 123/283 [00:28<00:25,  6.34it/s] 44%|████▍     | 124/283 [00:28<00:33,  4.70it/s] 44%|████▍     | 125/283 [00:28<00:35,  4.44it/s] 45%|████▍     | 126/283 [00:29<00:41,  3.82it/s] 45%|████▍     | 127/283 [00:29<00:40,  3.81it/s] 45%|████▌     | 128/283 [00:29<00:40,  3.82it/s] 46%|████▌     | 130/283 [00:30<00:31,  4.86it/s] 46%|████▋     | 131/283 [00:30<00:34,  4.35it/s] 47%|████▋     | 132/283 [00:30<00:32,  4.71it/s] 47%|████▋     | 133/283 [00:30<00:32,  4.59it/s] 47%|████▋     | 134/283 [00:31<00:37,  3.95it/s] 48%|████▊     | 135/283 [00:31<00:35,  4.22it/s] 48%|████▊     | 136/283 [00:31<00:33,  4.37it/s] 48%|████▊     | 137/283 [00:31<00:34,  4.18it/s] 49%|████▉     | 138/283 [00:32<00:39,  3.71it/s] 49%|████▉     | 139/283 [00:32<00:40,  3.55it/s] 49%|████▉     | 140/283 [00:32<00:36,  3.90it/s] 50%|████▉     | 141/283 [00:32<00:38,  3.69it/s] 50%|█████     | 142/283 [00:33<00:34,  4.07it/s] 51%|█████     | 143/283 [00:33<00:31,  4.45it/s] 51%|█████     | 144/283 [00:33<00:42,  3.30it/s] 51%|█████     | 145/283 [00:33<00:37,  3.67it/s] 52%|█████▏    | 146/283 [00:34<00:31,  4.29it/s] 52%|█████▏    | 147/283 [00:34<00:36,  3.74it/s] 52%|█████▏    | 148/283 [00:34<00:34,  3.89it/s] 53%|█████▎    | 149/283 [00:35<00:36,  3.72it/s] 53%|█████▎    | 150/283 [00:35<00:36,  3.61it/s] 53%|█████▎    | 151/283 [00:35<00:37,  3.49it/s] 54%|█████▎    | 152/283 [00:36<00:46,  2.82it/s] 54%|█████▍    | 153/283 [00:36<00:49,  2.64it/s] 54%|█████▍    | 154/283 [00:36<00:38,  3.36it/s] 55%|█████▍    | 155/283 [00:36<00:35,  3.62it/s] 55%|█████▌    | 156/283 [00:37<00:34,  3.71it/s] 55%|█████▌    | 157/283 [00:37<00:29,  4.20it/s] 56%|█████▌    | 158/283 [00:37<00:33,  3.77it/s] 56%|█████▌    | 159/283 [00:37<00:29,  4.15it/s] 57%|█████▋    | 160/283 [00:38<00:29,  4.21it/s] 57%|█████▋    | 161/283 [00:38<00:33,  3.69it/s] 57%|█████▋    | 162/283 [00:38<00:32,  3.68it/s] 58%|█████▊    | 163/283 [00:38<00:29,  4.08it/s] 58%|█████▊    | 164/283 [00:39<00:37,  3.14it/s] 58%|█████▊    | 165/283 [00:39<00:34,  3.40it/s] 59%|█████▊    | 166/283 [00:39<00:30,  3.78it/s] 59%|█████▉    | 167/283 [00:39<00:25,  4.51it/s] 59%|█████▉    | 168/283 [00:40<00:31,  3.68it/s] 60%|█████▉    | 169/283 [00:40<00:30,  3.69it/s] 60%|██████    | 170/283 [00:40<00:28,  4.01it/s] 60%|██████    | 171/283 [00:40<00:24,  4.64it/s] 61%|██████    | 172/283 [00:41<00:29,  3.77it/s] 61%|██████    | 173/283 [00:41<00:25,  4.32it/s] 62%|██████▏   | 175/283 [00:41<00:27,  3.96it/s] 62%|██████▏   | 176/283 [00:42<00:31,  3.34it/s] 63%|██████▎   | 177/283 [00:42<00:27,  3.88it/s] 63%|██████▎   | 179/283 [00:43<00:28,  3.64it/s] 64%|██████▎   | 180/283 [00:43<00:29,  3.49it/s] 64%|██████▍   | 181/283 [00:43<00:31,  3.26it/s] 64%|██████▍   | 182/283 [00:44<00:27,  3.64it/s] 65%|██████▍   | 183/283 [00:44<00:25,  3.97it/s] 65%|██████▌   | 184/283 [00:44<00:21,  4.64it/s] 65%|██████▌   | 185/283 [00:44<00:18,  5.17it/s] 66%|██████▌   | 186/283 [00:44<00:20,  4.64it/s] 66%|██████▌   | 187/283 [00:44<00:19,  4.80it/s] 66%|██████▋   | 188/283 [00:45<00:24,  3.83it/s] 67%|██████▋   | 189/283 [00:45<00:22,  4.15it/s] 67%|██████▋   | 190/283 [00:45<00:23,  3.95it/s] 67%|██████▋   | 191/283 [00:45<00:20,  4.58it/s] 68%|██████▊   | 192/283 [00:46<00:18,  4.85it/s] 68%|██████▊   | 193/283 [00:46<00:21,  4.21it/s] 69%|██████▊   | 194/283 [00:46<00:18,  4.68it/s] 69%|██████▉   | 195/283 [00:46<00:18,  4.75it/s] 69%|██████▉   | 196/283 [00:46<00:17,  5.11it/s] 70%|██████▉   | 197/283 [00:47<00:23,  3.72it/s] 70%|██████▉   | 198/283 [00:47<00:23,  3.60it/s] 70%|███████   | 199/283 [00:48<00:27,  3.03it/s] 71%|███████   | 200/283 [00:48<00:22,  3.66it/s] 71%|███████   | 201/283 [00:48<00:21,  3.79it/s] 71%|███████▏  | 202/283 [00:48<00:19,  4.08it/s] 72%|███████▏  | 203/283 [00:48<00:18,  4.43it/s] 72%|███████▏  | 204/283 [00:49<00:20,  3.90it/s] 72%|███████▏  | 205/283 [00:49<00:22,  3.53it/s] 73%|███████▎  | 206/283 [00:49<00:23,  3.30it/s] 73%|███████▎  | 207/283 [00:50<00:19,  3.81it/s] 73%|███████▎  | 208/283 [00:50<00:20,  3.63it/s] 74%|███████▍  | 209/283 [00:50<00:20,  3.55it/s] 74%|███████▍  | 210/283 [00:50<00:17,  4.25it/s] 75%|███████▍  | 211/283 [00:51<00:16,  4.27it/s] 75%|███████▍  | 212/283 [00:51<00:14,  4.86it/s] 75%|███████▌  | 213/283 [00:51<00:16,  4.29it/s] 76%|███████▌  | 214/283 [00:51<00:13,  5.09it/s] 76%|███████▌  | 215/283 [00:51<00:13,  5.05it/s] 76%|███████▋  | 216/283 [00:52<00:14,  4.49it/s] 77%|███████▋  | 217/283 [00:52<00:18,  3.64it/s] 77%|███████▋  | 218/283 [00:52<00:17,  3.81it/s] 77%|███████▋  | 219/283 [00:53<00:16,  3.82it/s] 78%|███████▊  | 220/283 [00:53<00:18,  3.42it/s] 78%|███████▊  | 221/283 [00:53<00:19,  3.12it/s] 78%|███████▊  | 222/283 [00:53<00:17,  3.56it/s] 79%|███████▉  | 223/283 [00:54<00:13,  4.30it/s] 79%|███████▉  | 224/283 [00:54<00:14,  4.17it/s] 80%|███████▉  | 225/283 [00:54<00:18,  3.16it/s] 80%|███████▉  | 226/283 [00:55<00:16,  3.39it/s] 80%|████████  | 227/283 [00:55<00:14,  3.92it/s] 81%|████████  | 228/283 [00:55<00:12,  4.38it/s] 81%|████████  | 229/283 [00:55<00:12,  4.25it/s] 81%|████████▏ | 230/283 [00:55<00:12,  4.23it/s] 82%|████████▏ | 231/283 [00:56<00:10,  4.89it/s] 82%|████████▏ | 232/283 [00:56<00:10,  4.73it/s] 82%|████████▏ | 233/283 [00:56<00:13,  3.85it/s] 83%|████████▎ | 234/283 [00:56<00:11,  4.30it/s] 83%|████████▎ | 235/283 [00:57<00:12,  4.00it/s] 83%|████████▎ | 236/283 [00:57<00:13,  3.49it/s] 84%|████████▎ | 237/283 [00:57<00:12,  3.71it/s] 84%|████████▍ | 238/283 [00:58<00:13,  3.35it/s] 84%|████████▍ | 239/283 [00:58<00:12,  3.48it/s] 85%|████████▍ | 240/283 [00:58<00:10,  3.99it/s] 85%|████████▌ | 241/283 [00:58<00:12,  3.40it/s] 86%|████████▌ | 242/283 [00:59<00:10,  3.99it/s] 86%|████████▌ | 243/283 [00:59<00:09,  4.11it/s] 87%|████████▋ | 245/283 [00:59<00:09,  3.96it/s] 87%|████████▋ | 246/283 [01:00<00:09,  3.98it/s] 87%|████████▋ | 247/283 [01:00<00:09,  3.82it/s] 88%|████████▊ | 249/283 [01:00<00:07,  4.53it/s] 88%|████████▊ | 250/283 [01:01<00:08,  3.71it/s] 89%|████████▊ | 251/283 [01:01<00:07,  4.15it/s] 89%|████████▉ | 252/283 [01:01<00:07,  3.92it/s] 89%|████████▉ | 253/283 [01:01<00:08,  3.71it/s] 90%|████████▉ | 254/283 [01:01<00:06,  4.29it/s] 90%|█████████ | 255/283 [01:02<00:08,  3.40it/s] 90%|█████████ | 256/283 [01:02<00:07,  3.71it/s] 91%|█████████ | 257/283 [01:02<00:07,  3.52it/s] 91%|█████████ | 258/283 [01:03<00:06,  4.13it/s] 92%|█████████▏| 259/283 [01:03<00:05,  4.69it/s] 92%|█████████▏| 260/283 [01:03<00:05,  4.55it/s] 93%|█████████▎| 262/283 [01:03<00:04,  4.32it/s] 93%|█████████▎| 263/283 [01:04<00:03,  5.02it/s] 93%|█████████▎| 264/283 [01:04<00:04,  4.73it/s] 94%|█████████▎| 265/283 [01:04<00:03,  4.94it/s] 94%|█████████▍| 266/283 [01:04<00:03,  5.49it/s] 94%|█████████▍| 267/283 [01:04<00:03,  4.64it/s] 95%|█████████▍| 268/283 [01:05<00:03,  4.72it/s] 95%|█████████▌| 269/283 [01:05<00:03,  4.40it/s] 95%|█████████▌| 270/283 [01:05<00:02,  4.41it/s] 96%|█████████▌| 271/283 [01:05<00:02,  4.99it/s] 96%|█████████▌| 272/283 [01:06<00:02,  4.14it/s] 96%|█████████▋| 273/283 [01:06<00:02,  3.38it/s] 97%|█████████▋| 274/283 [01:06<00:02,  3.26it/s] 98%|█████████▊| 276/283 [01:07<00:01,  4.11it/s] 98%|█████████▊| 277/283 [01:07<00:01,  4.55it/s] 98%|█████████▊| 278/283 [01:07<00:01,  4.41it/s] 99%|█████████▊| 279/283 [01:07<00:00,  4.26it/s] 99%|█████████▉| 280/283 [01:08<00:00,  4.25it/s] 99%|█████████▉| 281/283 [01:08<00:00,  4.21it/s]100%|█████████▉| 282/283 [01:08<00:00,  4.87it/s]100%|██████████| 283/283 [01:08<00:00,  4.32it/s]100%|██████████| 283/283 [01:08<00:00,  4.11it/s]
***** eval metrics *****
  epoch                   =     0.9995
  eval_loss               =     2.9306
  eval_rewards/accuracies =     0.5318
  eval_rewards/chosen     =    -8.3125
  eval_rewards/margins    =     0.3164
  eval_rewards/rejected   =     -8.625
  eval_runtime            = 0:01:09.10
  eval_samples            =       1130
  eval_samples_per_second =     16.351
  eval_steps_per_second   =      4.095
2025-03-28 17:22:18 - INFO - __main__ - *** Training complete! ***
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mgemma-2-2b-it-simpo[0m at: [34mhttps://wandb.ai/yggu/huggingface/runs/h6efpdf4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250328_134219-h6efpdf4/logs[0m
[rank0]:[W328 17:24:57.851303758 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
